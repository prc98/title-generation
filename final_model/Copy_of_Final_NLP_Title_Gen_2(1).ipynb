{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final_NLP_Title_Gen_2(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJx8HaEbhoxG"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import timeit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy import data\n",
        "import random\n",
        "## For reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJbEoKRgLLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f4a5cc-a725-4bf9-9547-b3343734044f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iryvSLmxh1vw"
      },
      "source": [
        "# Create Preprocessing pipeline for summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBy0Wh1zidtB"
      },
      "source": [
        "tokenize =  lambda s: s.split()\n",
        "import re  \n",
        "def cleanup_text(texts):\n",
        "    cleaned_text = []\n",
        "    for text in texts:\n",
        "        # remove punctuation\n",
        "        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
        "        # remove multiple spaces\n",
        "        text = re.sub(r' +', ' ', text)\n",
        "        # remove newline\n",
        "        text = re.sub(r'\\n', ' ', text)\n",
        "        #replace digits with '# symbol\n",
        "        text = re.sub('[0-9]', '#', text)\n",
        "        cleaned_text.append(text)\n",
        "    return cleaned_text"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0g0XtXnjdW0",
        "outputId": "2b040278-593e-4f98-8440-b069e6b56547"
      },
      "source": [
        "text = \"Hi\\n ko, \\t hs,  8998,  66jshs. hshs\"\n",
        "print(text.split())\n",
        "cleanup_text(text.split())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'ko,', 'hs,', '8998,', '66jshs.', 'hshs']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', 'ko ', 'hs ', '#### ', '##jshs ', 'hshs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2MHOhPtklHS"
      },
      "source": [
        "## Create torchtext fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CVDphMZkWaP"
      },
      "source": [
        "#Field for summaries\n",
        "SUM = data.Field(tokenize = tokenize,init_token='<sos>',eos_token='<eos>',pad_first=True,lower = True,preprocessing=cleanup_text)\n",
        "#Field for title\n",
        "TITLE = data.Field(tokenize = tokenize,init_token='<sos>',eos_token='<eos>',lower = True,preprocessing=cleanup_text)\n",
        "#Field for Id\n",
        "#ID = data.Field(use_vocab=False,sequential=False,dtype=torch.LongTensor,postprocessing=data.Pipeline(lambda x: int(x)))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r-2ePKbnx62"
      },
      "source": [
        "fields = [('Id',None),('Abstract',None),('Title',TITLE),('sum1',SUM),('sum2',SUM),('sum3',SUM),('sum4',SUM),('sum5',SUM),('sum6',SUM),('sum7',SUM)]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3EKi0ooi6f"
      },
      "source": [
        "## Read data into tabular dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgf0hafhomaE"
      },
      "source": [
        "dataset = data.TabularDataset(path='./drive/MyDrive/data_summaries.csv',format='csv', fields=fields,skip_header=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tleM8xWxpMmf",
        "outputId": "8af0e234-fac3-4e86-d5a7-e786dc706bbc"
      },
      "source": [
        "print(vars(dataset[0]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Title': ['dual', 'recurrent', 'attention', 'units', 'for', 'visual', 'question', 'answering'], 'sum1': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question '], 'sum2': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum3': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model '], 'sum4': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model '], 'sum5': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum6': ['our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum7': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKlMN3jMqmJm"
      },
      "source": [
        "## Create training data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vlRSnYiqjIk"
      },
      "source": [
        "import random\n",
        "train_data, valid_data = dataset.split(split_ratio=0.9, random_state=random.seed(0))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwPMSsKN6r05",
        "outputId": "c222883a-cb81-476c-dc32-6fcdf3ae1850"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36900\n",
            "4100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhhG460cyQVW",
        "outputId": "5d5b3b24-b72f-4a13-8ad2-de17f9de2d54"
      },
      "source": [
        "print(vars(train_data[5]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Title': ['adaptively', 'learning', 'the', 'crowd', 'kernel'], 'sum1': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone the', 'algorithm', 'samples', 'responses', 'to', 'adaptively', 'chosen', 'triplet based', 'relative similarity', 'queries '], 'sum2': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum3': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum4': ['the', 'output', 'is', 'an', 'embedding', 'of', 'the', 'objects', 'into', 'euclidean', 'space', ' like', 'mds ', 'we', 'refer', 'to', 'this', 'as', 'the', ' crowd', 'kernel svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum5': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone and', 'is', 'chosen', 'to', 'be', 'maximally', 'informative', 'given', 'the', 'preceding', 'responses '], 'sum6': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone the', 'algorithm', 'samples', 'responses', 'to', 'adaptively', 'chosen', 'triplet based', 'relative similarity', 'queries '], 'sum7': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzsrWel-rwik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8307652d-6c68-4005-b912-1b63016ea882"
      },
      "source": [
        "SUM.build_vocab(train_data.sum1,train_data.sum2,train_data.sum3,train_data.sum4,train_data.sum5,\\\n",
        "                train_data.sum6,train_data.sum7,train_data.Title,max_size=40000,vectors='glove.6B.100d')\n",
        "TITLE.vocab= SUM.vocab\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 398687/400000 [00:14<00:00, 26900.68it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMTZoMzTwj9-",
        "outputId": "65173eae-4c8e-495a-caf8-549da40a4008"
      },
      "source": [
        "print(len(SUM.vocab))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJVr2ehqinaq"
      },
      "source": [
        "### Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKMevUd74r4"
      },
      "source": [
        "from torchtext import data, datasets, vocab\n",
        "glove = vocab.GloVe(name=\"6B\", dim=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuYlbCkT7-vi",
        "outputId": "30e51a7a-eada-420e-83ad-0def248ad4df"
      },
      "source": [
        "glove.vectors.size() # => torch.Size([400000, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqsSPdIk8IA1",
        "outputId": "7f299990-a72f-412c-a092-367be5834d52"
      },
      "source": [
        "SUM.vocab.vectors.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40004, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXV96BXC8as5",
        "outputId": "c84e277c-c4e9-4664-bed8-ee677d183ceb"
      },
      "source": [
        "SUM.vocab.stoi['<unk>'] #<unk> is not present in glove vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfNaYADP8Ke0",
        "outputId": "9e832b73-7bfe-4f81-c5ad-004f072cfa62"
      },
      "source": [
        "SUM.vocab.vectors[0]#check the initialisation of oov words for glove. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r4e40BW-57F"
      },
      "source": [
        "assert(TITLE.vocab.stoi ==  SUM.vocab.stoi) #check if both share the same vocab or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_vnztTkRmcV",
        "outputId": "1582e8e3-fec8-4430-f43d-bd594de49bad"
      },
      "source": [
        "type(SUM.vocab.vectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzSRh6biSLra",
        "outputId": "ae270bcc-f6b0-4851-c641-d473b8a60d18"
      },
      "source": [
        "type(SUM.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.defaultdict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6nlVqB_Rw79"
      },
      "source": [
        "torch.save(SUM.vocab.vectors, './drive/MyDrive/vocab_embeddings.pt')\n",
        "torch.save(SUM.vocab.stoi,'./drive/MyDrive/vocab_stoi.pt')\n",
        "torch.save(SUM.vocab.itos,'./drive/MyDrive/vocab_itos.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVRF9UM7oc_z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtAkYj7KmvAF"
      },
      "source": [
        "vars(train_data.examples[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFg4ayhMmh3p"
      },
      "source": [
        "torch.save(SUM.vocab.itos,'./drive/MyDrive/vocab_itos.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeyegTA6p-gB"
      },
      "source": [
        "torch.save(train_data.examples,'train_data.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEWb9cbXtq06",
        "outputId": "bf92ec7f-4e98-4423-b454-11b8f7ec4e56"
      },
      "source": [
        "train_data.examples[0].Title"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsupervised', 'semantic', 'parsing', 'of', 'video', 'collections']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodGaMxD-zFL"
      },
      "source": [
        "## Create Bucket iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5V0C7iZ_E5N"
      },
      "source": [
        "def cal_length(x):\n",
        "  return len(x.sum1)+len(x.sum2)+len(x.sum3)+len(x.sum4)+len(x.sum5)+len(x.sum6)+len(x.sum7)+len(x.Title)\n",
        "from torchtext.legacy import data\n",
        "BATCH_SIZE =64\n",
        "train_iterator, valid_iterator =data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE, sort_key = lambda x: cal_length(x), sort_within_batch = True,shuffle=True,sort=False,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfycZDI6cche"
      },
      "source": [
        "###Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDAjb0gwuu4u",
        "outputId": "05dec04a-c62b-4184-e607-b91386e8ccfa"
      },
      "source": [
        "bt = next(iter(train_iterator))\n",
        "bt.sum2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [  160,    67,     0,  ...,     7,   303,     0],\n",
              "        [10665,   881,  2246,  ..., 20638,  3045,   261],\n",
              "        [    3,     3,     3,  ...,     3,     3,     3]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "x6NXHVuSkwKi",
        "outputId": "fc3e6144-2d26-492d-ab77-abb89610af9d"
      },
      "source": [
        "bt.name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-7123f9a12b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMUTzw0tiJQ-"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU4Ix8W6iNpn"
      },
      "source": [
        "## Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qOs589nrh8p"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers, dropout): \n",
        "        super().__init__()   \n",
        "        self.hid_dim = hid_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)  \n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, dropout = dropout)    \n",
        "        self.dropout = nn.Dropout(dropout)       \n",
        "    def forward(self, input_idx):\n",
        "        #print(input_idx)\n",
        "        input_idx=input_idx.to(device)\n",
        "        embedded = self.dropout(self.embedding(input_idx))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = seq_len,batch_size,embed_dim\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        #outputs are always from the top hidden layer\n",
        "        return outputs,hidden"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyQTGPUVYD-K"
      },
      "source": [
        "## Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN82JkyFYGKl",
        "outputId": "42a61432-9caf-4444-89c6-c4f34583752b"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0 \n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "enc.apply(init_weights)\n",
        "enc.embedding.weight.data.copy_(pretrained_embeddings)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight\n",
            "weight_ih_l0\n",
            "weight_hh_l0\n",
            "bias_ih_l0\n",
            "bias_hh_l0\n",
            "weight_ih_l1\n",
            "weight_hh_l1\n",
            "bias_ih_l1\n",
            "bias_hh_l1\n",
            "weight_ih_l2\n",
            "weight_hh_l2\n",
            "bias_ih_l2\n",
            "bias_hh_l2\n",
            "embedding.weight\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l2\n",
            "lstm.weight_hh_l2\n",
            "lstm.bias_ih_l2\n",
            "lstm.bias_hh_l2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KdYw-yEZX9I",
        "outputId": "5530fe2a-0501-4c99-a8d9-670410197576"
      },
      "source": [
        "enc.embedding.weight[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1445, -0.0528, -0.0545,  1.1310,  0.4758, -1.0285,  0.2467, -0.0737,\n",
              "        -0.0886,  0.3821,  0.5470, -0.2648,  0.3177, -0.1480, -0.2948, -0.7081,\n",
              "        -0.1925,  0.2585, -0.2926,  0.1868,  0.3139, -0.0207, -0.1016, -0.2646,\n",
              "        -0.0816, -0.1146,  0.0933, -0.5261,  0.3618, -0.8518, -0.3467,  0.4525,\n",
              "        -0.2537,  0.2612,  0.7651, -0.2433, -0.0700,  0.3619, -1.2979, -0.0151,\n",
              "        -0.1497,  0.3810,  0.3105,  0.1845,  0.2202, -0.4393,  1.0478, -0.3870,\n",
              "        -0.1594, -1.2090, -0.2850, -0.4175, -0.1810,  1.0614,  0.3273, -1.8847,\n",
              "         0.0398,  0.1253,  0.4937,  0.1528, -0.1738,  0.1407, -1.0588,  0.1461,\n",
              "         0.3045, -0.0489, -0.2328, -0.3068,  0.6500, -0.1928,  0.4154,  0.3495,\n",
              "         0.1158,  0.2605,  0.5483,  0.0817, -0.4587, -0.7336, -0.5350, -0.3111,\n",
              "         0.1220,  0.4506, -0.0988, -0.0154, -0.7591,  0.2336,  0.5476, -0.8831,\n",
              "        -0.3143,  0.1056, -0.4707,  0.2288, -0.4611,  0.7963, -0.5427, -0.0820,\n",
              "        -0.3374, -0.0419,  0.1561,  0.4494], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koMFwUdMZvxZ",
        "outputId": "2b1ff2b3-4701-4c5e-94df-a06ed7014ccc"
      },
      "source": [
        "SUM.vocab.vectors[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1445, -0.0528, -0.0545,  1.1310,  0.4758, -1.0285,  0.2467, -0.0737,\n",
              "        -0.0886,  0.3821,  0.5470, -0.2648,  0.3177, -0.1480, -0.2948, -0.7081,\n",
              "        -0.1925,  0.2585, -0.2926,  0.1868,  0.3139, -0.0207, -0.1016, -0.2646,\n",
              "        -0.0816, -0.1146,  0.0933, -0.5261,  0.3618, -0.8518, -0.3467,  0.4525,\n",
              "        -0.2537,  0.2612,  0.7651, -0.2433, -0.0700,  0.3619, -1.2979, -0.0151,\n",
              "        -0.1497,  0.3810,  0.3105,  0.1845,  0.2202, -0.4393,  1.0478, -0.3870,\n",
              "        -0.1594, -1.2090, -0.2850, -0.4175, -0.1810,  1.0614,  0.3273, -1.8847,\n",
              "         0.0398,  0.1253,  0.4937,  0.1528, -0.1738,  0.1407, -1.0588,  0.1461,\n",
              "         0.3045, -0.0489, -0.2328, -0.3068,  0.6500, -0.1928,  0.4154,  0.3495,\n",
              "         0.1158,  0.2605,  0.5483,  0.0817, -0.4587, -0.7336, -0.5350, -0.3111,\n",
              "         0.1220,  0.4506, -0.0988, -0.0154, -0.7591,  0.2336,  0.5476, -0.8831,\n",
              "        -0.3143,  0.1056, -0.4707,  0.2288, -0.4611,  0.7963, -0.5427, -0.0820,\n",
              "        -0.3374, -0.0419,  0.1561,  0.4494])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMmtgXjlaBEl",
        "outputId": "725f9181-768b-4285-9284-f802c0aca5fb"
      },
      "source": [
        "#To be used to pass inputs to control layer\n",
        "enc.eval()\n",
        "sum = train_data.fields\n",
        "for i,batch in enumerate(train_iterator):\n",
        "  sum1=batch.sum1\n",
        "  sum2=batch.sum2\n",
        "  sum3=batch.sum3\n",
        "  sum4=batch.sum4\n",
        "  sum5=batch.sum5\n",
        "  sum6=batch.sum6\n",
        "  sum7=batch.sum7\n",
        "  sum=[sum1,sum2,sum3,sum4,sum5,sum6,sum7]\n",
        "  control_input=torch.zeros((7,64,512))\n",
        "  for s in range(7):\n",
        "    o,h,c=enc(sum[s])\n",
        "    print(h[-1].size())\n",
        "    control_input[s]=h[-1]\n",
        "  break;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfUoW0YOmGI9",
        "outputId": "98807675-2327-4754-f3ad-1b568db54330"
      },
      "source": [
        "print(control_input[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0834,  0.0189,  0.0765,  ..., -0.0174,  0.0009, -0.0084],\n",
            "        [-0.0895,  0.0514,  0.0244,  ..., -0.0415,  0.0057,  0.0272],\n",
            "        [-0.0050,  0.1141,  0.0455,  ..., -0.0509,  0.0232, -0.0133],\n",
            "        ...,\n",
            "        [-0.0277,  0.0447,  0.0456,  ..., -0.0098,  0.0120, -0.0170],\n",
            "        [-0.1194,  0.0710,  0.0903,  ..., -0.0478,  0.0130, -0.0159],\n",
            "        [-0.0394,  0.0713,  0.0786,  ..., -0.0637,  0.0046,  0.0357]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEOlyNZxiQEF"
      },
      "source": [
        "## Control layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjdf2BQ6rjSM"
      },
      "source": [
        "class ControlLayer(nn.Module):\n",
        "    def __init__(self, input_dim,hid_dim): \n",
        "        super().__init__()   \n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        #self.embedding = nn.Embedding(input_dim, emb_dim)  \n",
        "        self.lstm = nn.LSTM(input_dim, hid_dim)    \n",
        "             \n",
        "    def forward(self, sum_hidden):\n",
        "        #print(input_idx)\n",
        "        #sum_hidden = seq_len(=7),batch_size,embed_dim(=encoder_hidden_dimension)\n",
        "        outputs, (hidden, cell) = self.lstm(sum_hidden)\n",
        "        #embedded = seq_len,batch_size,embed_dim\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        #outputs are always from the top hidden layer\n",
        "        return outputs,hidden, cell"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYiU10INtO1g"
      },
      "source": [
        "##checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbotSIuQZ5tW"
      },
      "source": [
        "cl = ControlLayer(512,512)\n",
        "i=torch.randn(7,64,512)\n",
        "o,h,c = cl(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvxUPqUfabPw",
        "outputId": "1a2675f6-4c05-4261-cead-f0689643d64d"
      },
      "source": [
        "h.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4b7-0diabA"
      },
      "source": [
        "##Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPmC8aGtaOu"
      },
      "source": [
        "class ComplexAttention(nn.Module):\n",
        "   def __init__(self,dec_hid_dim,cnt_hid_dim,enc_hid_dim):\n",
        "    super().__init__() \n",
        "    self.cnt_hid_dim=cnt_hid_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "   def forward(self,cnt_hid_states,enc_hid_states,dec_hid_states):\n",
        "     #cnt_hid_states = [7,batch_size,cnt_hid_dim]\n",
        "     #enc_hid_states = [7,seq_len*,batch_size,enc_hid_dim], list of hidden states for every summary\n",
        "     #dec_hid_states = [1,batch_size,dec_hid_dim]\n",
        "     '''Calculate summary level attention'''\n",
        "     cnt_hid_states=cnt_hid_states.permute(1,0,2)\n",
        "     dec_hid_states=dec_hid_states.permute(1,2,0)\n",
        "     #dec_hid_states=[batch_size,dec_hid_dim,1]\n",
        "     alpha = torch.bmm(cnt_hid_states,dec_hid_states)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     #alpha=alpha.squeeze(2)\n",
        "     alpha=F.softmax(alpha,dim=1)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     '''Calculate word level attention'''\n",
        "     batch_size = alpha.size()[0]\n",
        "     context_vec=torch.zeros(batch_size,1,self.enc_hid_dim).to(device)\n",
        "     context_vec_k=torch.zeros(7,batch_size,self.enc_hid_dim).to(device)\n",
        "     for k,sum_hid_states in enumerate(enc_hid_states):\n",
        "       #sum_hid_states = [seq_len_k,batch_size,enc_hid_dim]\n",
        "       sum_hid_states=sum_hid_states.permute(1,0,2)\n",
        "       beta = torch.bmm(sum_hid_states,dec_hid_states)\n",
        "       #beta = [batch_size,seq_len_1,1]\n",
        "       #beta=beta.squeeze(2)\n",
        "       beta=F.softmax(beta,dim=1)\n",
        "       beta=beta.permute(0,2,1)\n",
        "       #beta = [batch_size,1,seq_len]\n",
        "       #sum_hid_states = [batch_size,seq_len_size,enc_hid_dim]\n",
        "       context_vec_k[k] = torch.bmm(beta,sum_hid_states).squeeze(1)\n",
        "       #context_vec_k = [batch_size,1,enc_hid_dim].squeeze(1)\n",
        "     '''Combining both and returning context_vector'''\n",
        "     context_vec_k=context_vec_k.permute(1,0,2)\n",
        "     alpha=alpha.permute(0,2,1)\n",
        "     context_vec = torch.bmm(alpha,context_vec_k)\n",
        "     del context_vec_k\n",
        "     torch.cuda.empty_cache()\n",
        "     return alpha,beta,context_vec\n",
        "\n",
        "       "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0JC9VKMQ79t"
      },
      "source": [
        "class SimpleAttention(nn.Module):\n",
        "   def __init__(self,dec_hid_dim,cnt_hid_dim,enc_hid_dim,split):\n",
        "    super().__init__() \n",
        "    self.cnt_hid_dim=cnt_hid_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.split = split\n",
        "   def forward(self,cnt_hid_states,enc_hid_states,dec_hid_states):\n",
        "     #cnt_hid_states = [7,batch_size,cnt_hid_dim]\n",
        "     #enc_hid_states = [7,seq_len*,batch_size,enc_hid_dim], list of hidden states for every summary\n",
        "     #dec_hid_states = [num_layers(=1),batch_size,dec_hid_dim]\n",
        "     '''Calculate summary level attention'''\n",
        "     cnt_hid_states_context=cnt_hid_states.permute(1,0,2)[:,:,:self.split]\n",
        "     dec_hid_states_context=dec_hid_states.permute(1,2,0)[:,:self.split,:]\n",
        "     cnt_hid_states_wgt=cnt_hid_states.permute(1,0,2)[:,:,self.split:]\n",
        "     dec_hid_states_wgt=dec_hid_states.permute(1,2,0)[:,self.split:,:]\n",
        "     #dec_hid_states=[batch_size,dec_hid_dim,1]\n",
        "     alpha = torch.bmm(cnt_hid_states_wgt,dec_hid_states_wgt)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     #alpha=alpha.squeeze(2)\n",
        "     alpha=F.softmax(alpha,dim=1)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     '''Calculate word level attention'''\n",
        "     batch_size = alpha.size()[0]\n",
        "     context_vec=torch.zeros(batch_size,1,self.split).to(device)\n",
        "     context_vec_k=torch.zeros(7,batch_size,self.split).to(device)\n",
        "     for k,sum_hid_states in enumerate(enc_hid_states):\n",
        "       #sum_hid_states = [seq_len_k,batch_size,enc_hid_dim]\n",
        "       sum_hid_states_wgt=sum_hid_states.permute(1,0,2)[:,:,self.split:]\n",
        "       sum_hid_states_context=sum_hid_states.permute(1,0,2)[:,:,:self.split]\n",
        "       beta = torch.bmm(sum_hid_states_wgt,dec_hid_states_wgt)\n",
        "       #beta = [batch_size,seq_len_1,1]\n",
        "       #beta=beta.squeeze(2)\n",
        "       beta=F.softmax(beta,dim=1)\n",
        "       beta=beta.permute(0,2,1)\n",
        "       #beta = [batch_size,1,seq_len]\n",
        "       #sum_hid_states = [batch_size,seq_len_size,enc_hid_dim]\n",
        "       context_vec_k[k] = torch.bmm(beta,sum_hid_states_context).squeeze(1)\n",
        "       #context_vec_k = [batch_size,1,enc_hid_dim].squeeze(1)\n",
        "     '''Combining both and returning context_vector'''\n",
        "     context_vec_k=context_vec_k.permute(1,0,2)\n",
        "     alpha=alpha.permute(0,2,1)\n",
        "     context_vec = torch.bmm(alpha,context_vec_k)\n",
        "     del context_vec_k\n",
        "     torch.cuda.empty_cache()\n",
        "     return alpha,beta,context_vec\n",
        "\n",
        "       "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGicM78iI2Yc"
      },
      "source": [
        "#### Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hOm805PI4Bm"
      },
      "source": [
        "at = ComplexAttention(512,512,512)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512) \n",
        "alpha,beta,con=at(cnt_hid_states,enc_hid_states,dec_hid_states)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELoNPTC8Kqmz"
      },
      "source": [
        "assert(con.size()==torch.Size([64, 1, 512])) #checking if correct size is returned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNAZHtTMK9OO"
      },
      "source": [
        "assert(beta[45][0].sum().item()==1) ##Checking if attention wgts have calculated succesfully"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS_ElS94UHCL"
      },
      "source": [
        "at = SimpleAttention(512,512,512,472)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512) \n",
        "alpha,beta,con=at(cnt_hid_states,enc_hid_states,dec_hid_states)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_n5d_fDUMav"
      },
      "source": [
        "assert(con.size()==torch.Size([64, 1,472])) #checking if correct size is returned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_cQkhzksUPX"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F             # importing functions -Functional interface\n",
        "a = torch.randn(5,2,3)\n",
        "b=torch.randn(5,2,3)\n",
        "c= a+b\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxI-sfXuV2Nf",
        "outputId": "427ea76a-8144-4093-f302-59a3ff3fe980"
      },
      "source": [
        "con.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 472])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unRcNmAoV4eX",
        "outputId": "b90fc5e0-4b79-446d-99f7-4597204a7024"
      },
      "source": [
        "con=con.permute(1,0,2)\n",
        "print(con.size())\n",
        "input = torch.randn(1,64,100)\n",
        "c = torch.cat((input, con), dim = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 472])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju9hl7nDWykk",
        "outputId": "9ae74a03-31c3-443c-8056-5561224ae7ba"
      },
      "source": [
        "c.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 572])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3fLV-xHVtKr"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbbagtapVxkt"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim,con_hid_dim,attention,attention_type):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.con_hid_dim = con_hid_dim\n",
        "        self.attention = attention      \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        if attention_type=='complex':      \n",
        "          self.lstm = nn.LSTM(input_size=(enc_hid_dim + emb_dim),hidden_size= dec_hid_dim)\n",
        "          self.fc_out = nn.Linear( enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n",
        "        else:\n",
        "          self.lstm = nn.LSTM((attention.split+emb_dim), dec_hid_dim)\n",
        "          self.fc_out = nn.Linear( (2*attention.split)  + emb_dim, output_dim)    \n",
        "        #self.dropout = nn.Dropout(dropout)\n",
        "        self.attention_type=attention_type\n",
        "    def forward(self, input_idx,cnt_hid_states,enc_hid_states,dec_hid_states,cell_state):\n",
        "      #input = [batch_size]\n",
        "      input_idx = input_idx.unsqueeze(0)#Adding a dimenstion at the the first = 1 = seq_len as we are sending word by word\n",
        "      #input = [1,batch_size] \n",
        "      embedded = self.embedding(input_idx)\n",
        "      #embedded = [1,batch_size,embed_size]\n",
        "      '''Getting the context vector'''\n",
        "      _,_,context_vector=self.attention(cnt_hid_states,enc_hid_states,dec_hid_states)\n",
        "      #context_vector=[batch_size,1,hid_state]\n",
        "      context_vector=context_vector.permute(1,0,2)\n",
        "      #context_vector=[1,batch_size,hid_state]\n",
        "      lstm_in = torch.cat((embedded,context_vector),dim=2)\n",
        "      #lstm_in = [1,batch_size,context_vector_size+embed_size]\n",
        "      #print(lstm_in.size())\n",
        "      outputs, (hidden, cell) = self.lstm(lstm_in,(dec_hid_states,cell_state))\n",
        "      #output=[seq_len(=1),batch_size,hid_dim]\n",
        "      #hidden=[num_layers(=1),batch_size,hid_dim]\n",
        "      assert(outputs==hidden).all()\n",
        "\n",
        "      embedded=embedded.squeeze(0)\n",
        "      context_vector=context_vector.squeeze(0)\n",
        "      outputs = outputs.squeeze(0)\n",
        "      if self.attention_type=='complex':\n",
        "        prediction = self.fc_out(torch.cat((outputs,context_vector,embedded),dim=1))\n",
        "      else:\n",
        "        prediction = self.fc_out(torch.cat((outputs[:,:self.attention.split],context_vector,embedded),dim=1))\n",
        "      #prediction_size = (batch_size,out_dim)\n",
        "      return prediction,hidden,cell\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8HFRmdgv2r"
      },
      "source": [
        "### checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtvNlSJ2jpCF",
        "outputId": "20c24fe5-ef8c-4e8a-b0ce-d0edc4374b11"
      },
      "source": [
        "at = SimpleAttention(512,512,512,472)\n",
        "\n",
        "dec =  Decoder(40000,100,512,512,512,at,'simple')\n",
        "input = random.sample(range(10, 1000), 64)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512)\n",
        "cell_state=torch.randn(1,64,512)\n",
        "pred,hid,cell = dec(torch.LongTensor(input),cnt_hid_states,enc_hid_states,dec_hid_states,cell_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 572])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXZecrcEMa6z",
        "outputId": "0c060b44-522e-4342-c073-c1edb56daa48"
      },
      "source": [
        "pred.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 40000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7w-CoTWgqMo"
      },
      "source": [
        "##Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OidIY-BVW4OB"
      },
      "source": [
        "class Seq2Seq(nn.Module): #Combining the encoder,control_layer & decoder\n",
        "  def __init__(self,encoder,control_layer,decoder,device):\n",
        "    super().__init__()\n",
        "    self.encoder=encoder\n",
        "    self.control_layer = control_layer\n",
        "    self.decoder=decoder\n",
        "    self.device =  device\n",
        "  def forward(self,input_batches,output_batches,tfr=0.5):\n",
        "    #input_batches dimension - NOT A TENSOR. ENTIRE BATCH OBJECT IS SENT. \n",
        "    #output_batches_dimension - (seq_len,batch_size)\n",
        "    \n",
        "    batch_size = output_batches.shape[1]\n",
        "    title_len = output_batches.shape[0]\n",
        "    title_vocab_size = self.decoder.output_dim\n",
        "    predictions = torch.zeros(title_len, batch_size, title_vocab_size).to(device)\n",
        "    #print(input_batches.size())\n",
        "    '''Pass each summary through the encoder'''\n",
        "    sum1=input_batches.sum1\n",
        "    sum2=input_batches.sum2\n",
        "    sum3=input_batches.sum3\n",
        "    sum4=input_batches.sum4\n",
        "    sum5=input_batches.sum5\n",
        "    sum6=input_batches.sum6\n",
        "    sum7=input_batches.sum7\n",
        "    sum=[sum1,sum2,sum3,sum4,sum5,sum6,sum7]\n",
        "    control_input=torch.zeros((7,batch_size,self.control_layer.hid_dim)).to(device)\n",
        "    encoder_hidden_states = []\n",
        "    for s in range(7):\n",
        "      output,hidden=self.encoder(sum[s])\n",
        "      #output = [s.length,batch_size,hid_dim]\n",
        "      #hidden=[num_layers,batch_size,hid_dim]\n",
        "      #print(\"enc_output device\",output.device)\n",
        "      encoder_hidden_states.append(output)\n",
        "      control_input[s]=hidden[-1]\n",
        "    \n",
        "    '''Pass the last hidden state to control layer for each summary'''\n",
        "    output,hidden_state,cell_state = self.control_layer(control_input)\n",
        "    control_hidden_states = output\n",
        "    #prprint(\"S_c\")\n",
        "    '''Pass the merged representation to decoder along with encoder and control layer hidden states for implementing attention'''\n",
        "    \n",
        "    \n",
        "    x = output_batches[0,:] # Trigger token <SOS>\n",
        "\n",
        "    for i in range(1, title_len):\n",
        "      pred, hidden_state, cell_state = self.decoder(x,control_hidden_states,encoder_hidden_states,hidden_state, cell_state)\n",
        "      #pred = [batch_size,output_dim(vocab_size)]\n",
        "      predictions[i] = pred\n",
        "      best_guess = pred.argmax(1) \n",
        "      x = output_batches[i,:] if random.random() < tfr else best_guess\n",
        "    return predictions  "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io0fzS1YNo_-"
      },
      "source": [
        "## Set Model hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O0ftuZEN5PK"
      },
      "source": [
        "## Initialise weights (Embeddings are initialised with glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3vYL04BOAgk"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrgYtkNKOdUR"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i,batch in enumerate(iterator):\n",
        "        \n",
        "        #abstract = batch.Abstract\n",
        "        title = batch.Title\n",
        "        #abstract,title = [seq_len,batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        #print(\"batch device \",batch.device)\n",
        "        predictions = model(batch, title,0.5)\n",
        "        \n",
        "        #predictions = [seq_len_title,batch_size,title_vocab]\n",
        "        output_dim = predictions.shape[-1]\n",
        "        \n",
        "        predictions = predictions[1:].view(-1, output_dim)#ignoring the first value is the <sos> token\n",
        "        title = title[1:].view(-1)\n",
        "        \n",
        "        loss = criterion(predictions, title)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W52SADa2OQij"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUeVTA61Odl5"
      },
      "source": [
        "def test(model, iterator, criterion):    \n",
        "    model.eval() \n",
        "    epoch_loss = 0 \n",
        "    with torch.no_grad():   \n",
        "        for i, batch in enumerate(iterator):\n",
        "          #abstract = batch.Abstract\n",
        "          title = batch.Title\n",
        "          #abstract,title = [seq_len,batch_size]\n",
        "          predictions = model(batch, title,0)\n",
        "          #predictions = [seq_len_title,batch_size,title_vocab]\n",
        "          output_dim = predictions.shape[-1]\n",
        "          predictions = predictions[1:].view(-1, output_dim)#ignoring the first value is the <sos> token\n",
        "          title = title[1:].view(-1)\n",
        "          loss = criterion(predictions, title)  \n",
        "          epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPORcxCzOZEi"
      },
      "source": [
        "##Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaIcc_hIOe_i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boOqkDtIOhPS"
      },
      "source": [
        "##Start training and testing!\n",
        "### Experiement 0 - Complex Attention, ADAM optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1U8noU9OcZ4"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = ComplexAttention(HID_DIM,HID_DIM,HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'complex')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpq0dBD1Ocrh",
        "outputId": "e9d487fc-7bbf-40d3-e378-2bce628baa75"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-fJZPAwfNVF"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1vltVXHj2Oz"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiO38agbOn-k",
        "outputId": "bfe836e0-0bd3-4cf1-e7cc-260158f395ca"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 6.402\n",
            "\tTest Loss: 6.523\n",
            "Time taken : 7.524mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.931\n",
            "\tTest Loss: 6.506\n",
            "Time taken : 7.692mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.748\n",
            "\tTest Loss: 6.520\n",
            "Time taken : 7.695mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.573\n",
            "\tTest Loss: 6.534\n",
            "Time taken : 7.702mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.455\n",
            "\tTest Loss: 6.547\n",
            "Time taken : 7.697mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.370\n",
            "\tTest Loss: 6.550\n",
            "Time taken : 7.683mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.274\n",
            "\tTest Loss: 6.594\n",
            "Time taken : 7.713mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.164\n",
            "\tTest Loss: 6.586\n",
            "Time taken : 7.722mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.100\n",
            "\tTest Loss: 6.594\n",
            "Time taken : 7.707mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.023\n",
            "\tTest Loss: 6.603\n",
            "Time taken : 7.705mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.964\n",
            "\tTest Loss: 6.613\n",
            "Time taken : 7.759mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.868\n",
            "\tTest Loss: 6.607\n",
            "Time taken : 7.721mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.807\n",
            "\tTest Loss: 6.611\n",
            "Time taken : 7.710mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.700\n",
            "\tTest Loss: 6.680\n",
            "Time taken : 7.735mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.602\n",
            "\tTest Loss: 6.513\n",
            "Time taken : 7.749mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.509\n",
            "\tTest Loss: 6.483\n",
            "Time taken : 7.751mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.356\n",
            "\tTest Loss: 6.472\n",
            "Time taken : 7.750mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.189\n",
            "\tTest Loss: 6.462\n",
            "Time taken : 7.759mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.059\n",
            "\tTest Loss: 6.404\n",
            "Time taken : 7.760mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 3.915\n",
            "\tTest Loss: 6.480\n",
            "Time taken : 7.769mins\n",
            "Saving the new checkpoint....\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Dbh7P-OyMN"
      },
      "source": [
        "## Train & test loss graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YTimOXk_iYV"
      },
      "source": [
        "##Start training and testing!\n",
        "### Experiement 1 - Complex Attention, RMSprop optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSl4tWb_wFc"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = ComplexAttention(HID_DIM,HID_DIM,HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'complex')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJUEKhOW_wFh",
        "outputId": "2df4cf03-41e0-4284-af3b-5a6fb0209581"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Yy1Hmx_wFv"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net_1.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKC_9iAJ_wFx"
      },
      "source": [
        "optimizer = optim.RMSprop(model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.9)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "q3dAlHWWAhCQ",
        "outputId": "224c8cac-6345-4314-9fa1-188d07367daf"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.581\n",
            "Time taken : 7.652mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.579\n",
            "Time taken : 7.694mins\n",
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.579\n",
            "Time taken : 7.691mins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3e9da7c55bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tTrain Loss: {train_loss:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-534606c595b7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(\"batch device \",batch.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#predictions = [seq_len_title,batch_size,title_vocab]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5efeac973e11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batches, output_batches, tfr)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontrol_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0;31m#pred = [batch_size,output_dim(vocab_size)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-abe71fbcb43c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_idx, cnt_hid_states, enc_hid_states, dec_hid_states, cell_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#embedded = [1,batch_size,embed_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;34m'''Getting the context vector'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_hid_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_hid_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdec_hid_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m#context_vector=[batch_size,1,hid_state]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mcontext_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-6cc33b888c50>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cnt_hid_states, enc_hid_states, dec_hid_states)\u001b[0m\n\u001b[1;32m     20\u001b[0m      \u001b[0;34m'''Calculate word level attention'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m      \u001b[0mcontext_vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m      \u001b[0mcontext_vec_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum_hid_states\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_hid_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFEtwItAmcH"
      },
      "source": [
        "### Start training and testing!\n",
        "### Experiement 2 - Simple Attention,Adam optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBs4tvMcA53a"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "SPLIT = 472\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = SimpleAttention(HID_DIM,HID_DIM,HID_DIM,SPLIT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'simple')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0U2HVi5A53c",
        "outputId": "ed4214f6-72ee-4276-a3d2-7155afa96bdf"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0eBrsz2A53f"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net_2.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kdefe9PA53h"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkBlstVXA53i"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF03zOQmdanb"
      },
      "source": [
        "## Translate\n",
        "<Br> Randomly select some abstracts from the dataset and generate the title using the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNCfWCW2sv7D"
      },
      "source": [
        "ID = data.Field(use_vocab=False,sequential=False,preprocessing=int)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MsAxQBtspoO"
      },
      "source": [
        "fields = [('Id',ID),('Abstract',None),('Title',TITLE),('sum1',SUM),('sum2',SUM),('sum3',SUM),('sum4',SUM),('sum5',SUM),('sum6',SUM),('sum7',SUM)]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOBwWBpd8Fm"
      },
      "source": [
        "df = pd.read_csv('./drive/MyDrive/data_summaries.csv')\n",
        "idx = np.random.randint(0,df.shape[0],100)\n",
        "df1 = df.loc[idx]\n",
        "df1.to_csv('./drive/MyDrive/test_data.csv')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D66kuesVeZnv"
      },
      "source": [
        "ran_dataset = data.TabularDataset(path='./drive/MyDrive/test_data.csv',format='csv', fields=fields,skip_header=True)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejQT-RMcprit",
        "outputId": "326a6397-8ca7-448c-ce46-2ea515475a71"
      },
      "source": [
        "print(vars(ran_dataset[0]))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Id': 2732, 'Title': ['in', 'this', 'paper ', 'a', 'sparse', 'markov', 'decision', 'process', ' mdp ', 'with', 'novel', 'causal', 'sparse', 'tsallis', 'entropy', 'regularization', 'is', 'proposed the', 'proposed', 'policy', 'regularization', 'induces', 'a', 'sparse', 'and', 'multi modal', 'optimal', 'policy', 'distribution', 'of', 'a', 'sparse', 'mdp ', 'the', 'full', 'mathematical', 'analysis', 'of', 'the', 'proposed', 'sparse', 'mdp', 'is', 'provided we', 'first', 'analyze', 'the', 'optimality', 'condition', 'of', 'a', 'sparse', 'mdp ', 'then ', 'we', 'propose', 'a', 'sparse', 'value', 'iteration', 'method', 'which', 'solves', 'a', 'sparse', 'mdp', 'and', 'then', 'prove', 'the', 'convergence', 'and', 'optimality', 'of', 'sparse', 'value', 'iteration', 'using', 'the', 'banach', 'fixed', 'point', 'theorem ', 'the', 'proposed', 'sparse', 'mdp', 'is', 'compared', 'to', 'soft', 'mdps', 'which', 'utilize', 'causal', 'entropy', 'regularization ', 'we', 'show', 'that', 'the', 'performance', 'error', 'of', 'a', 'sparse', 'mdp', 'has', 'a', 'constant', 'bound ', 'while', 'the', 'error', 'of', 'a', 'soft', 'mdp', 'increases', 'logarithmically', 'with', 'respect', 'to', 'the', 'number', 'of', 'actions ', 'where', 'this', 'performance', 'error', 'is', 'caused', 'by', 'the', 'introduced', 'regularization', 'term ', 'in', 'experiments ', 'we', 'apply', 'sparse', 'mdps', 'to', 'reinforcement', 'learning', 'problems ', 'the', 'proposed', 'method', 'outperforms', 'existing', 'methods', 'in', 'terms', 'of', 'the', 'convergence', 'speed', 'and', 'performance '], 'sum1': ['sparse', 'markov', 'decision', 'processes', 'with', 'causal', 'sparse', 'tsallis', 'entropy', 'regularization', 'for', 'reinforcement', 'learning'], 'sum2': ['the', 'full', 'mathematical', 'analysis', 'of', 'the', 'proposed', 'sparse', 'mdp', 'is', 'provided we', 'first', 'analyze', 'the', 'optimality', 'condition', 'of', 'a', 'sparse', 'mdp the', 'proposed', 'sparse', 'mdp', 'is', 'compared', 'to', 'soft', 'mdps', 'which', 'utilize', 'causal', 'entropy', 'regularization '], 'sum3': ['the', 'proposed', 'sparse', 'mdp', 'is', 'compared', 'to', 'soft', 'mdps', 'which', 'utilize', 'causal', 'entropy', 'regularization in', 'experiments ', 'we', 'apply', 'sparse', 'mdps', 'to', 'reinforcement', 'learning', 'problems '], 'sum4': ['then ', 'we', 'propose', 'a', 'sparse', 'value', 'iteration', 'method', 'which', 'solves', 'a', 'sparse', 'mdp', 'and', 'then', 'prove', 'the', 'convergence', 'and', 'optimality', 'of', 'sparse', 'value', 'iteration', 'using', 'the', 'banach', 'fixed', 'point', 'theorem we', 'show', 'that', 'the', 'performance', 'error', 'of', 'a', 'sparse', 'mdp', 'has', 'a', 'constant', 'bound ', 'while', 'the', 'error', 'of', 'a', 'soft', 'mdp', 'increases', 'logarithmically', 'with', 'respect', 'to', 'the', 'number', 'of', 'actions ', 'where', 'this', 'performance', 'error', 'is', 'caused', 'by', 'the', 'introduced', 'regularization', 'term '], 'sum5': ['in', 'this', 'paper ', 'a', 'sparse', 'markov', 'decision', 'process', ' mdp ', 'with', 'novel', 'causal', 'sparse', 'tsallis', 'entropy', 'regularization', 'is', 'proposed the', 'proposed', 'policy', 'regularization', 'induces', 'a', 'sparse', 'and', 'multi modal', 'optimal', 'policy', 'distribution', 'of', 'a', 'sparse', 'mdp we', 'show', 'that', 'the', 'performance', 'error', 'of', 'a', 'sparse', 'mdp', 'has', 'a', 'constant', 'bound ', 'while', 'the', 'error', 'of', 'a', 'soft', 'mdp', 'increases', 'logarithmically', 'with', 'respect', 'to', 'the', 'number', 'of', 'actions ', 'where', 'this', 'performance', 'error', 'is', 'caused', 'by', 'the', 'introduced', 'regularization', 'term '], 'sum6': ['the', 'full', 'mathematical', 'analysis', 'of', 'the', 'proposed', 'sparse', 'mdp', 'is', 'provided we', 'first', 'analyze', 'the', 'optimality', 'condition', 'of', 'a', 'sparse', 'mdp in', 'experiments ', 'we', 'apply', 'sparse', 'mdps', 'to', 'reinforcement', 'learning', 'problems '], 'sum7': ['the', 'full', 'mathematical', 'analysis', 'of', 'the', 'proposed', 'sparse', 'mdp', 'is', 'provided we', 'first', 'analyze', 'the', 'optimality', 'condition', 'of', 'a', 'sparse', 'mdp the', 'proposed', 'method', 'outperforms', 'existing', 'methods', 'in', 'terms', 'of', 'the', 'convergence', 'speed', 'and', 'performance ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI6rLEhhefgR"
      },
      "source": [
        "def cal_length(x):\n",
        "  return len(x.sum1)+len(x.sum2)+len(x.sum3)+len(x.sum4)+len(x.sum5)+len(x.sum6)+len(x.sum7)+len(x.Title)\n",
        "from torchtext.legacy import data\n",
        "BATCH_SIZE =1\n",
        "iterator=data.Iterator(\n",
        "    ran_dataset,\n",
        "    batch_size = BATCH_SIZE,device=device)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frqJWyOOh9HJ",
        "outputId": "77fc1c01-4810-4db9-fbe7-cc1bfe398fa6"
      },
      "source": [
        "bt = next(iter(iterator))\n",
        "bt"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 1]\n",
              "\t[.Id]:[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
              "\t[.Title]:[torch.cuda.LongTensor of size 162x1 (GPU 0)]\n",
              "\t[.sum1]:[torch.cuda.LongTensor of size 12x1 (GPU 0)]\n",
              "\t[.sum2]:[torch.cuda.LongTensor of size 40x1 (GPU 0)]\n",
              "\t[.sum3]:[torch.cuda.LongTensor of size 83x1 (GPU 0)]\n",
              "\t[.sum4]:[torch.cuda.LongTensor of size 61x1 (GPU 0)]\n",
              "\t[.sum5]:[torch.cuda.LongTensor of size 83x1 (GPU 0)]\n",
              "\t[.sum6]:[torch.cuda.LongTensor of size 61x1 (GPU 0)]\n",
              "\t[.sum7]:[torch.cuda.LongTensor of size 40x1 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b15KOjGbpAIl",
        "outputId": "35e5390f-ea60-4615-94ba-e8c9bf153a4b"
      },
      "source": [
        "bt.Id"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10215], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o68vutrpMLp"
      },
      "source": [
        "id1 = bt.Id.item()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAVOyMlyp261",
        "outputId": "0a1a3f9a-d78f-434c-9396-64f3296ca74a"
      },
      "source": [
        "id1"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUltYBSbpPSl"
      },
      "source": [
        "a = \"\".join(list(df.loc[df['Id'] == id1]['Abstract']))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "INUIL64GqYKp",
        "outputId": "a96339cb-1ca0-4ff5-f771-2f9aefb4cf61"
      },
      "source": [
        "a"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\\nthat leads to a false sense of security in defenses against adversarial\\nexamples. While defenses that cause obfuscated gradients appear to defeat\\niterative optimization-based attacks, we find defenses relying on this effect\\ncan be circumvented. For each of the three types of obfuscated gradients we\\ndiscover, we describe characteristic behaviors of defenses exhibiting this\\neffect and develop attack techniques to overcome it. In a case study, examining\\nnon-certified white-box-secure defenses at ICLR 2018, we find obfuscated\\ngradients are a common occurrence, with 7 of 8 defenses relying on obfuscated\\ngradients. Our new attacks successfully circumvent 6 completely and 1\\npartially.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVgbpP61eNVR"
      },
      "source": [
        "path =  './drive/MyDrive/Colab Notebooks/final_net_2.pt'\n",
        "checkpoint = torch.load(path)\n",
        "#print(checkpoint)\n",
        "model1 = checkpoint['model']\n",
        "model1.load_state_dict( checkpoint['model_state_dict'])\n",
        "min_loss = checkpoint['min_loss']\n",
        "epoch = checkpoint['epoch']\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y5bIAXoidmh",
        "outputId": "181fb7e0-0d50-458b-939d-2ea32b767d94"
      },
      "source": [
        "len(iterator)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6FUVPuspSXk",
        "outputId": "fd3a20dd-7d89-4530-993a-6fbc6a8ad799"
      },
      "source": [
        "bt = next(iter(iterator))\n",
        "bt"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 1]\n",
              "\t[.Id]:[torch.cuda.LongTensor of size 1 (GPU 0)]\n",
              "\t[.Title]:[torch.cuda.LongTensor of size 114x1 (GPU 0)]\n",
              "\t[.sum1]:[torch.cuda.LongTensor of size 15x1 (GPU 0)]\n",
              "\t[.sum2]:[torch.cuda.LongTensor of size 48x1 (GPU 0)]\n",
              "\t[.sum3]:[torch.cuda.LongTensor of size 51x1 (GPU 0)]\n",
              "\t[.sum4]:[torch.cuda.LongTensor of size 51x1 (GPU 0)]\n",
              "\t[.sum5]:[torch.cuda.LongTensor of size 56x1 (GPU 0)]\n",
              "\t[.sum6]:[torch.cuda.LongTensor of size 39x1 (GPU 0)]\n",
              "\t[.sum7]:[torch.cuda.LongTensor of size 33x1 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB_sluDWeSGh"
      },
      "source": [
        "#to generate title for one abstract\n",
        "def translate(model,batch,max_len):\n",
        "  predictions=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():   \n",
        "    batch_size = 1\n",
        "    title_vocab_size = model.decoder.output_dim\n",
        "   # predictions = torch.zeros(title_len, batch_size, title_vocab_size).to(device)\n",
        "    #print(input_batches.size())\n",
        "    '''Pass each summary through the encoder'''\n",
        "    sum1=batch.sum1\n",
        "    sum2=batch.sum2\n",
        "    sum3=batch.sum3\n",
        "    sum4=batch.sum4\n",
        "    sum5=batch.sum5\n",
        "    sum6=batch.sum6\n",
        "    sum7=batch.sum7\n",
        "    sum=[sum1,sum2,sum3,sum4,sum5,sum6,sum7]\n",
        "    control_input=torch.zeros((7,batch_size,model.control_layer.hid_dim)).to(device)\n",
        "    encoder_hidden_states = []\n",
        "    for s in range(7):\n",
        "      output,hidden=model.encoder(sum[s])\n",
        "      #output = [s.length,batch_size,hid_dim]\n",
        "      #hidden=[num_layers,batch_size,hid_dim]\n",
        "      #print(\"enc_output device\",output.device)\n",
        "      encoder_hidden_states.append(output)\n",
        "      control_input[s]=hidden[-1]\n",
        "    \n",
        "    '''Pass the last hidden state to control layer for each summary'''\n",
        "    output,hidden_state,cell_state = model.control_layer(control_input)\n",
        "    control_hidden_states = output\n",
        "    #prprint(\"S_c\")\n",
        "    '''Pass the merged representation to decoder along with encoder and control layer hidden states for implementing attention'''\n",
        "    \n",
        "    \n",
        "    x =  torch.LongTensor([SUM.vocab.stoi['<sos>']]).to(device)\n",
        "\n",
        "    for i in range(1, max_len):\n",
        "      pred, hidden_state, cell_state = model.decoder(x,control_hidden_states,encoder_hidden_states,hidden_state, cell_state)\n",
        "      #pred = [1,output_dim(vocab_size)]\n",
        "      best_guess = pred.argmax(1)\n",
        "      predictions.append(best_guess.item())\n",
        "      x = best_guess\n",
        "      # Model predicts it's the end of the sentence\n",
        "      if predictions[-1] == SUM.vocab.stoi[\"<eos>\"]:\n",
        "        break\n",
        "\n",
        "      translated_sentence = [SUM.vocab.itos[idx] for idx in predictions]\n",
        "  return translated_sentence[1:]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "slyPCi6esMvo",
        "outputId": "b1ccc3b1-f697-44e5-ad08-d273e2f66359"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Title</th>\n",
              "      <th>sum1</th>\n",
              "      <th>sum2</th>\n",
              "      <th>sum3</th>\n",
              "      <th>sum4</th>\n",
              "      <th>sum5</th>\n",
              "      <th>sum6</th>\n",
              "      <th>sum7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>2732</td>\n",
              "      <td>In this paper, a sparse Markov decision proces...</td>\n",
              "      <td>Sparse Markov Decision Processes with Causal S...</td>\n",
              "      <td>The full mathematical analysis of the proposed...</td>\n",
              "      <td>The proposed sparse MDP is compared to soft MD...</td>\n",
              "      <td>Then, we propose a sparse value iteration meth...</td>\n",
              "      <td>In this paper, a sparse Markov decision proces...</td>\n",
              "      <td>The full mathematical analysis of the proposed...</td>\n",
              "      <td>The full mathematical analysis of the proposed...</td>\n",
              "      <td>In this paper, a sparse Markov decision proces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21243</th>\n",
              "      <td>21243</td>\n",
              "      <td>Roguelike games generally feature exploration ...</td>\n",
              "      <td>Exploration in NetHack with Secret Discovery</td>\n",
              "      <td>Roguelike games generally feature exploration ...</td>\n",
              "      <td>Our design aims to minimize exploration time, ...</td>\n",
              "      <td>Automated approaches, however, face challenges...</td>\n",
              "      <td>Automated approaches, however, face challenges...</td>\n",
              "      <td>Automated approaches, however, face challenges...</td>\n",
              "      <td>This paper presents an algorithmic approach to...</td>\n",
              "      <td>Roguelike games generally feature exploration ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30403</th>\n",
              "      <td>30403</td>\n",
              "      <td>Deep learning has achieved substantial success...</td>\n",
              "      <td>AI Oriented Large-Scale Video Management for S...</td>\n",
              "      <td>To practically facilitate deep neural network ...</td>\n",
              "      <td>To enable interoperability in the context of d...</td>\n",
              "      <td>Deep feature coding, instead of video coding, ...</td>\n",
              "      <td>However, due to the explosion of deep learning...</td>\n",
              "      <td>Deep learning has achieved substantial success...</td>\n",
              "      <td>Deep learning has achieved substantial success...</td>\n",
              "      <td>Deep learning has achieved substantial success...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32103</th>\n",
              "      <td>32103</td>\n",
              "      <td>Quorum sensing is a decentralized biological p...</td>\n",
              "      <td>A Quorum Sensing Inspired Algorithm for Dynami...</td>\n",
              "      <td>The algorithm treats each data as a single cel...</td>\n",
              "      <td>The algorithm treats each data as a single cel...</td>\n",
              "      <td>This paper draws inspirations from quorum sens...</td>\n",
              "      <td>The algorithm treats each data as a single cel...</td>\n",
              "      <td>Quorum sensing is a decentralized biological p...</td>\n",
              "      <td>Quorum sensing is a decentralized biological p...</td>\n",
              "      <td>Quorum sensing is a decentralized biological p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20757</th>\n",
              "      <td>20757</td>\n",
              "      <td>A compact information-rich representation of t...</td>\n",
              "      <td>Intrinsically Motivated Acquisition of Modular...</td>\n",
              "      <td>A recently proposed algorithm called Curious D...</td>\n",
              "      <td>However, in environments that are non-stationa...</td>\n",
              "      <td>A compact information-rich representation of t...</td>\n",
              "      <td>A compact information-rich representation of t...</td>\n",
              "      <td>A compact information-rich representation of t...</td>\n",
              "      <td>Therefore, learning multiple sets of spatially...</td>\n",
              "      <td>A compact information-rich representation of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22626</th>\n",
              "      <td>22626</td>\n",
              "      <td>Deep generative models have been wildly succes...</td>\n",
              "      <td>Grammar Variational Autoencoder</td>\n",
              "      <td>Crucially, state-of-the-art methods often prod...</td>\n",
              "      <td>Deep generative models have been wildly succes...</td>\n",
              "      <td>We propose a variational autoencoder which enc...</td>\n",
              "      <td>We propose a variational autoencoder which enc...</td>\n",
              "      <td>However, generative modeling of discrete data ...</td>\n",
              "      <td>Crucially, state-of-the-art methods often prod...</td>\n",
              "      <td>Deep generative models have been wildly succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9123</th>\n",
              "      <td>9123</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "      <td>Scalable and Robust Construction of Topical Hi...</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "      <td>We solve a critical challenge to perform scala...</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "      <td>In this paper a scalable and robust algorithm ...</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "      <td>Automated generation of high-quality topical h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31454</th>\n",
              "      <td>31454</td>\n",
              "      <td>Radiomics is a term which refers to the analys...</td>\n",
              "      <td>Dissimilarity-based representation for radiomi...</td>\n",
              "      <td>Radiomics is a term which refers to the analys...</td>\n",
              "      <td>Radiomics is a term which refers to the analys...</td>\n",
              "      <td>Many recent studies have proved that radiomics...</td>\n",
              "      <td>However, most of the classification studies in...</td>\n",
              "      <td>Many recent studies have proved that radiomics...</td>\n",
              "      <td>Radiomics is a term which refers to the analys...</td>\n",
              "      <td>Radiomics is a term which refers to the analys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14254</th>\n",
              "      <td>14254</td>\n",
              "      <td>A novel unified Bayesian framework for network...</td>\n",
              "      <td>Bayesian Discovery of Threat Networks</td>\n",
              "      <td>The algorithm is defined by a graph, at least ...</td>\n",
              "      <td>A general diffusion model is introduced that u...</td>\n",
              "      <td>A link to well-known spectral detection method...</td>\n",
              "      <td>A link to well-known spectral detection method...</td>\n",
              "      <td>A link to well-known spectral detection method...</td>\n",
              "      <td>A novel unified Bayesian framework for network...</td>\n",
              "      <td>A novel unified Bayesian framework for network...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23700</th>\n",
              "      <td>23700</td>\n",
              "      <td>Accumulating evidence has shown that iron is i...</td>\n",
              "      <td>Binary and nonbinary description of hypointens...</td>\n",
              "      <td>Accumulating evidence has shown that iron is i...</td>\n",
              "      <td>Accordingly, tissues with high iron concentrat...</td>\n",
              "      <td>Abnormal (higher) iron accumulation has been d...</td>\n",
              "      <td>Abnormal (higher) iron accumulation has been d...</td>\n",
              "      <td>Abnormal (higher) iron accumulation has been d...</td>\n",
              "      <td>Abnormal (higher) iron accumulation has been d...</td>\n",
              "      <td>Accumulating evidence has shown that iron is i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Id  ...                                               sum7\n",
              "2732    2732  ...  In this paper, a sparse Markov decision proces...\n",
              "21243  21243  ...  Roguelike games generally feature exploration ...\n",
              "30403  30403  ...  Deep learning has achieved substantial success...\n",
              "32103  32103  ...  Quorum sensing is a decentralized biological p...\n",
              "20757  20757  ...  A compact information-rich representation of t...\n",
              "...      ...  ...                                                ...\n",
              "22626  22626  ...  Deep generative models have been wildly succes...\n",
              "9123    9123  ...  Automated generation of high-quality topical h...\n",
              "31454  31454  ...  Radiomics is a term which refers to the analys...\n",
              "14254  14254  ...  A novel unified Bayesian framework for network...\n",
              "23700  23700  ...  Accumulating evidence has shown that iron is i...\n",
              "\n",
              "[100 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5dMFSefD6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9def1f7-245e-4468-8d49-e13aad641bbe"
      },
      "source": [
        "for i,batch in enumerate(iterator):\n",
        "  id1 = batch.Id.item()\n",
        "  print(\"Abstract : \")\n",
        "  print(\"\".join(list(df.loc[df['Id'] == id1]['Abstract'])))\n",
        "  print(\"Actual Title : \")\n",
        "  print(\"\".join(list(df.loc[df['Id'] == id1]['Title'])))\n",
        "  print(\"Generated Title : \")\n",
        "  print(\" \".join(translate(model1,batch,10)))\n",
        "\n",
        "  "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abstract : \n",
            "A standard objective in partially-observable Markov decision processes\n",
            "(POMDPs) is to find a policy that maximizes the expected discounted-sum payoff.\n",
            "However, such policies may still permit unlikely but highly undesirable\n",
            "outcomes, which is problematic especially in safety-critical applications.\n",
            "Recently, there has been a surge of interest in POMDPs where the goal is to\n",
            "maximize the probability to ensure that the payoff is at least a given\n",
            "threshold, but these approaches do not consider any optimization beyond\n",
            "satisfying this threshold constraint. In this work we go beyond both the\n",
            "\"expectation\" and \"threshold\" approaches and consider a \"guaranteed payoff\n",
            "optimization (GPO)\" problem for POMDPs, where we are given a threshold $t$ and\n",
            "the objective is to find a policy $\\sigma$ such that a) each possible outcome\n",
            "of $\\sigma$ yields a discounted-sum payoff of at least $t$, and b) the expected\n",
            "discounted-sum payoff of $\\sigma$ is optimal (or near-optimal) among all\n",
            "policies satisfying a). We present a practical approach to tackle the GPO\n",
            "problem and evaluate it on standard POMDP benchmarks.\n",
            "Actual Title : \n",
            "Optimizing Expectation with Guarantees in POMDPs (Technical Report)\n",
            "Generated Title : \n",
            "change detection approximation\n",
            "Abstract : \n",
            "We consider probabilistic topic models and more recent word embedding\n",
            "techniques from a perspective of learning hidden semantic representations.\n",
            "Inspired by a striking similarity of the two approaches, we merge them and\n",
            "learn probabilistic embeddings with online EM-algorithm on word co-occurrence\n",
            "data. The resulting embeddings perform on par with Skip-Gram Negative Sampling\n",
            "(SGNS) on word similarity tasks and benefit in the interpretability of the\n",
            "components. Next, we learn probabilistic document embeddings that outperform\n",
            "paragraph2vec on a document similarity task and require less memory and time\n",
            "for training. Finally, we employ multimodal Additive Regularization of Topic\n",
            "Models (ARTM) to obtain a high sparsity and learn embeddings for other\n",
            "modalities, such as timestamps and categories. We observe further improvement\n",
            "of word similarity performance and meaningful inter-modality similarities.\n",
            "Actual Title : \n",
            "Interpretable probabilistic embeddings: bridging the gap between topic\n",
            "  models and neural networks\n",
            "Generated Title : \n",
            "probabilistic latent attributed attributed\n",
            "Abstract : \n",
            "Recent progress in synthetic aperture sonar (SAS) technology and processing\n",
            "has led to significant advances in underwater imaging, outperforming previously\n",
            "common approaches in both accuracy and efficiency. There are, however, inherent\n",
            "limitations to current SAS reconstruction methodology. In particular, popular\n",
            "and efficient Fourier domain SAS methods require a 2D interpolation which is\n",
            "often ill conditioned and inaccurate, inevitably reducing robustness with\n",
            "regard to speckle and inaccurate sound-speed estimation. To overcome these\n",
            "issues, we propose using the frame theoretic convolution gridding (FTCG)\n",
            "algorithm to handle the non-uniform Fourier data. FTCG extends upon non-uniform\n",
            "fast Fourier transform (NUFFT) algorithms by casting the NUFFT as an\n",
            "approximation problem given Fourier frame data. The FTCG has been show to yield\n",
            "improved accuracy at little more computational cost. Using simulated data, we\n",
            "outline how the FTCG can be used to enhance current SAS processing.\n",
            "Actual Title : \n",
            "Using Frame Theoretic Convolutional Gridding for Robust Synthetic\n",
            "  Aperture Sonar Imaging\n",
            "Generated Title : \n",
            "residual quantization\n",
            "Abstract : \n",
            "BP3TKI Palembang is the government agencies that coordinate, execute and\n",
            "selection of prospective migrants registration and placement. To simplify the\n",
            "existing procedures and improve decision-making is necessary to build a\n",
            "decision support system (DSS) to determine eligibility for employment abroad by\n",
            "applying Fuzzy Multiple Attribute Decision Making (FMADM), using the linear\n",
            "sequential systems development methods. The system is built using Microsoft\n",
            "Visual Basic. Net 2010 and SQL Server 2008 database. The design of the system\n",
            "using use case diagrams and class diagrams to identify the needs of users and\n",
            "systems as well as systems implementation guidelines. This Decision Support\n",
            "System able to rank and produce the prospective migrants, making it easier for\n",
            "parties to take decision BP3TKI the workers who will be working out of the\n",
            "country.\n",
            "Actual Title : \n",
            "Sistem pendukung keputusan kelayakan TKI ke luar negeri menggunakan\n",
            "  FMADM\n",
            "Generated Title : \n",
            "thesaurus  <unk> su doku\n",
            "Abstract : \n",
            "Automated generation of high-quality topical hierarchies for a text\n",
            "collection is a dream problem in knowledge engineering with many valuable\n",
            "applications. In this paper a scalable and robust algorithm is proposed for\n",
            "constructing a hierarchy of topics from a text collection. We divide and\n",
            "conquer the problem using a top-down recursive framework, based on a tensor\n",
            "orthogonal decomposition technique. We solve a critical challenge to perform\n",
            "scalable inference for our newly designed hierarchical topic model. Experiments\n",
            "with various real-world datasets illustrate its ability to generate robust,\n",
            "high-quality hierarchies efficiently. Our method reduces the time of\n",
            "construction by several orders of magnitude, and its robust feature renders it\n",
            "possible for users to interactively revise the hierarchy.\n",
            "Actual Title : \n",
            "Scalable and Robust Construction of Topical Hierarchies\n",
            "Generated Title : \n",
            "a of typographic font\n",
            "Abstract : \n",
            "Video classification is productive in many practical applications, and the\n",
            "recent deep learning has greatly improved its accuracy. However, existing works\n",
            "often model video frames indiscriminately, but from the view of motion, video\n",
            "frames can be decomposed into salient and non-salient areas naturally. Salient\n",
            "and non-salient areas should be modeled with different networks, for the former\n",
            "present both appearance and motion information, and the latter present static\n",
            "background information. To address this problem, in this paper, video saliency\n",
            "is predicted by optical flow without supervision firstly. Then two streams of\n",
            "3D CNN are trained individually for raw frames and optical flow on salient\n",
            "areas, and another 2D CNN is trained for raw frames on non-salient areas. For\n",
            "the reason that these three streams play different roles for each class, the\n",
            "weights of each stream are adaptively learned for each class. Experimental\n",
            "results show that saliency-guided modeling and adaptively weighted learning can\n",
            "reinforce each other, and we achieve the state-of-the-art results.\n",
            "Actual Title : \n",
            "Saliency-guided video classification via adaptively weighted learning\n",
            "Generated Title : \n",
            "instrument for video object\n",
            "Abstract : \n",
            "A novel unified Bayesian framework for network detection is developed, under\n",
            "which a detection algorithm is derived based on random walks on graphs. The\n",
            "algorithm detects threat networks using partial observations of their activity,\n",
            "and is proved to be optimum in the Neyman-Pearson sense. The algorithm is\n",
            "defined by a graph, at least one observation, and a diffusion model for threat.\n",
            "A link to well-known spectral detection methods is provided, and the\n",
            "equivalence of the random walk and harmonic solutions to the Bayesian\n",
            "formulation is proven. A general diffusion model is introduced that utilizes\n",
            "spatio-temporal relationships between vertices, and is used for a specific\n",
            "space-time formulation that leads to significant performance improvements on\n",
            "coordinated covert networks. This performance is demonstrated using a new\n",
            "hybrid mixed-membership blockmodel introduced to simulate random covert\n",
            "networks with realistic properties.\n",
            "Actual Title : \n",
            "Bayesian Discovery of Threat Networks\n",
            "Generated Title : \n",
            "bayesian networks\n",
            "Abstract : \n",
            "This paper challenges a cross-genre document retrieval task, where the\n",
            "queries are in formal writing and the target documents are in conversational\n",
            "writing. In this task, a query, is a sentence extracted from either a summary\n",
            "or a plot of an episode in a TV show, and the target document consists of\n",
            "transcripts from the corresponding episode. To establish a strong baseline, we\n",
            "employ the current state-of-the-art search engine to perform document retrieval\n",
            "on the dataset collected for this work. We then introduce a structure reranking\n",
            "approach to improve the initial ranking by utilizing syntactic and semantic\n",
            "structures generated by NLP tools. Our evaluation shows an improvement of more\n",
            "than 4% when the structure reranking is applied, which is very promising.\n",
            "Actual Title : \n",
            "Cross-genre Document Retrieval: Matching between Conversational and\n",
            "  Formal Writings\n",
            "Generated Title : \n",
            "typographic messaging\n",
            "Abstract : \n",
            "In this paper, we consider a fitness-level model of a non-elitist\n",
            "mutation-only evolutionary algorithm (EA) with tournament selection. The model\n",
            "provides upper and lower bounds for the expected proportion of the individuals\n",
            "with fitness above given thresholds. In the case of so-called monotone\n",
            "mutation, the obtained bounds imply that increasing the tournament size\n",
            "improves the EA performance. As corollaries, we obtain an exponentially\n",
            "vanishing tail bound for the Randomized Local Search on unimodal functions and\n",
            "polynomial upper bounds on the runtime of EAs on 2-SAT problem and on a family\n",
            "of Set Cover problems proposed by E. Balas.\n",
            "Actual Title : \n",
            "On Proportions of Fit Individuals in Population of Evolutionary\n",
            "  Algorithm with Tournament Selection\n",
            "Generated Title : \n",
            "optimization of su doku\n",
            "Abstract : \n",
            "This work aims to make it easier for a specialist in one field to find and\n",
            "explore ideas from another field which may be useful in solving a new problem\n",
            "arising in his practice. It presents a methodology which serves to represent\n",
            "the relationships that exist between concepts, problems, and solution patterns\n",
            "from different fields of human activity in the form of a graph. Our approach is\n",
            "based upon generalization and specialization relationships and problem solving.\n",
            "It is simple enough to be understood quite easily, and general enough to enable\n",
            "coherent integration of concepts and problems from virtually any field. We have\n",
            "built an implementation which uses the World Wide Web as a support to allow\n",
            "navigation between graph nodes and collaborative development of the graph.\n",
            "Actual Title : \n",
            "Towards Solving the Interdisciplinary Language Barrier Problem\n",
            "Generated Title : \n",
            "<unk>\n",
            "Abstract : \n",
            "The generation of meaningless \"words\" matching certain statistical and/or\n",
            "linguistic criteria is frequently needed for experimental purposes in\n",
            "Psycholinguistics. Such stimuli receive the name of pseudowords or nonwords in\n",
            "the Cognitive Neuroscience literatue. The process for building nonwords\n",
            "sometimes has to be based on linguistic units such as syllables or morphemes,\n",
            "resulting in a numerical explosion of combinations when the size of the\n",
            "nonwords is increased. In this paper, a reactive tabu search scheme is proposed\n",
            "to generate nonwords of variables size. The approach builds pseudowords by\n",
            "using a modified Metaheuristic algorithm based on a local search procedure\n",
            "enhanced by a feedback-based scheme. Experimental results show that the new\n",
            "algorithm is a practical and effective tool for nonword generation.\n",
            "Actual Title : \n",
            "A Reactive Tabu Search Algorithm for Stimuli Generation in\n",
            "  Psycholinguistics\n",
            "Generated Title : \n",
            "<unk> messaging\n",
            "Abstract : \n",
            "A compact information-rich representation of the environment, also called a\n",
            "feature abstraction, can simplify a robot's task of mapping its raw sensory\n",
            "inputs to useful action sequences. However, in environments that are\n",
            "non-stationary and only partially observable, a single abstraction is probably\n",
            "not sufficient to encode most variations. Therefore, learning multiple sets of\n",
            "spatially or temporally local, modular abstractions of the inputs would be\n",
            "beneficial. How can a robot learn these local abstractions without a teacher?\n",
            "More specifically, how can it decide from where and when to start learning a\n",
            "new abstraction? A recently proposed algorithm called Curious Dr. MISFA\n",
            "addresses this problem. The algorithm is based on two underlying learning\n",
            "principles called artificial curiosity and slowness. The former is used to make\n",
            "the robot self-motivated to explore by rewarding itself whenever it makes\n",
            "progress learning an abstraction; the later is used to update the abstraction\n",
            "by extracting slowly varying components from raw sensory inputs. Curious Dr.\n",
            "MISFA's application is, however, limited to discrete domains constrained by a\n",
            "pre-defined state space and has design limitations that make it unstable in\n",
            "certain situations. This paper presents a significant improvement that is\n",
            "applicable to continuous environments, is computationally less expensive,\n",
            "simpler to use with fewer hyper parameters, and stable in certain\n",
            "non-stationary environments. We demonstrate the efficacy and stability of our\n",
            "method in a vision-based robot simulator.\n",
            "Actual Title : \n",
            "Intrinsically Motivated Acquisition of Modular Slow Features for\n",
            "  Humanoids in Continuous and Non-Stationary Environments\n",
            "Generated Title : \n",
            "<unk> attributed attributed graphs\n",
            "Abstract : \n",
            "Understanding how users navigate in a network is of high interest in many\n",
            "applications. We consider a setting where only aggregate node-level traffic is\n",
            "observed and tackle the task of learning edge transition probabilities. We cast\n",
            "it as a preference learning problem, and we study a model where choices follow\n",
            "Luce's axiom. In this case, the $O(n)$ marginal counts of node visits are a\n",
            "sufficient statistic for the $O(n^2)$ transition probabilities. We show how to\n",
            "make the inference problem well-posed regardless of the network's structure,\n",
            "and we present ChoiceRank, an iterative algorithm that scales to networks that\n",
            "contains billions of nodes and edges. We apply the model to two clickstream\n",
            "datasets and show that it successfully recovers the transition probabilities\n",
            "using only the network structure and marginal (node-level) traffic data.\n",
            "Finally, we also consider an application to mobility networks and apply the\n",
            "model to one year of rides on New York City's bicycle-sharing system.\n",
            "Actual Title : \n",
            "ChoiceRank: Identifying Preferences from Node Traffic in Networks\n",
            "Generated Title : \n",
            "distinguishability fully convolutional networks\n",
            "Abstract : \n",
            "Although many successful ensemble clustering approaches have been developed\n",
            "in recent years, there are still two limitations to most of the existing\n",
            "approaches. First, they mostly overlook the issue of uncertain links, which may\n",
            "mislead the overall consensus process. Second, they generally lack the ability\n",
            "to incorporate global information to refine the local links. To address these\n",
            "two limitations, in this paper, we propose a novel ensemble clustering approach\n",
            "based on sparse graph representation and probability trajectory analysis. In\n",
            "particular, we present the elite neighbor selection strategy to identify the\n",
            "uncertain links by locally adaptive thresholds and build a sparse graph with a\n",
            "small number of probably reliable links. We argue that a small number of\n",
            "probably reliable links can lead to significantly better consensus results than\n",
            "using all graph links regardless of their reliability. The random walk process\n",
            "driven by a new transition probability matrix is utilized to explore the global\n",
            "information in the graph. We derive a novel and dense similarity measure from\n",
            "the sparse graph by analyzing the probability trajectories of the random\n",
            "walkers, based on which two consensus functions are further proposed.\n",
            "Experimental results on multiple real-world datasets demonstrate the\n",
            "effectiveness and efficiency of our approach.\n",
            "Actual Title : \n",
            "Robust Ensemble Clustering Using Probability Trajectories\n",
            "Generated Title : \n",
            "clustering clustering\n",
            "Abstract : \n",
            "At the core of interpretable machine learning is the question of whether\n",
            "humans are able to make accurate predictions about a model's behavior. Assumed\n",
            "in this question are three properties of the interpretable output: coverage,\n",
            "precision, and effort. Coverage refers to how often humans think they can\n",
            "predict the model's behavior, precision to how accurate humans are in those\n",
            "predictions, and effort is either the up-front effort required in interpreting\n",
            "the model, or the effort required to make predictions about a model's behavior.\n",
            "  In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that\n",
            "produces high-precision rule-based explanations for which the coverage\n",
            "boundaries are very clear. We compare aLIME to linear LIME with simulated\n",
            "experiments, and demonstrate the flexibility of aLIME with qualitative examples\n",
            "from a variety of domains and tasks.\n",
            "Actual Title : \n",
            "Nothing Else Matters: Model-Agnostic Explanations By Identifying\n",
            "  Prediction Invariance\n",
            "Generated Title : \n",
            "<unk>\n",
            "Abstract : \n",
            "Building machines that learn and think like humans is essential not only for\n",
            "cognitive science, but also for computational neuroscience, whose ultimate goal\n",
            "is to understand how cognition is implemented in biological brains. A new\n",
            "cognitive computational neuroscience should build cognitive-level and neural-\n",
            "level models, understand their relationships, and test both types of models\n",
            "with both brain and behavioral data.\n",
            "Actual Title : \n",
            "Building machines that adapt and compute like brains\n",
            "Generated Title : \n",
            "<unk> <unk> <unk> <unk> <unk>\n",
            "Abstract : \n",
            "In this paper, we present a novel low rank representation (LRR) algorithm for\n",
            "data lying on the manifold of square root densities. Unlike traditional LRR\n",
            "methods which rely on the assumption that the data points are vectors in the\n",
            "Euclidean space, our new algorithm is designed to incorporate the intrinsic\n",
            "geometric structure and geodesic distance of the manifold. Experiments on\n",
            "several computer vision datasets showcase its noise robustness and superior\n",
            "performance on classification and subspace clustering compared to other\n",
            "state-of-the-art approaches.\n",
            "Actual Title : \n",
            "Low Rank Representation on Riemannian Manifold of Square Root Densities\n",
            "Generated Title : \n",
            "low complexity principal component analysis\n",
            "Abstract : \n",
            "This paper explores the use of the standard approach for proving runtime\n",
            "bounds in discrete domains---often referred to as drift analysis---in the\n",
            "context of optimization on a continuous domain. Using this framework we analyze\n",
            "the (1+1) Evolution Strategy with one-fifth success rule on the sphere\n",
            "function. To deal with potential functions that are not lower-bounded, we\n",
            "formulate novel drift theorems. We then use the theorems to prove bounds on the\n",
            "expected hitting time to reach a certain target fitness in finite dimension\n",
            "$d$. The bounds are akin to linear convergence. We then study the dependency of\n",
            "the different terms on $d$ proving a convergence rate dependency of\n",
            "$\\Theta(1/d)$. Our results constitute the first non-asymptotic analysis for the\n",
            "algorithm considered as well as the first explicit application of drift\n",
            "analysis to a randomized search heuristic with continuous domain.\n",
            "Actual Title : \n",
            "Drift Theory in Continuous Search Spaces: Expected Hitting Time of the\n",
            "  (1+1)-ES with 1/5 Success Rule\n",
            "Generated Title : \n",
            "optimization problems su doku\n",
            "Abstract : \n",
            "Many robotic planning applications involve continuous actions with highly\n",
            "non-linear constraints, which cannot be modeled using modern planners that\n",
            "construct a propositional representation. We introduce STRIPStream: an\n",
            "extension of the STRIPS language which can model these domains by supporting\n",
            "the specification of blackbox generators to handle complex constraints. The\n",
            "outputs of these generators interact with actions through possibly infinite\n",
            "streams of objects and static predicates. We provide two algorithms which both\n",
            "reduce STRIPStream problems to a sequence of finite-domain planning problems.\n",
            "The representation and algorithms are entirely domain independent. We\n",
            "demonstrate our framework on simple illustrative domains, and then on a\n",
            "high-dimensional, continuous robotic task and motion planning domain.\n",
            "Actual Title : \n",
            "STRIPS Planning in Infinite Domains\n",
            "Generated Title : \n",
            "rewriting rewriting systems\n",
            "Abstract : \n",
            "The main prospective aim of modern research related to Artificial\n",
            "Intelligence is the creation of technical systems that implement the idea of\n",
            "Strong Intelligence. According our point of view the path to the development of\n",
            "such systems comes through the research in the field related to perceptions.\n",
            "Here we formulate the model of the perception of external world which may be\n",
            "used for the description of perceptual activity of intelligent beings. We\n",
            "consider a number of issues related to the development of the set of patterns\n",
            "which will be used by the intelligent system when interacting with environment.\n",
            "The key idea of the presented perception model is the idea of subjective\n",
            "reality. The principle of the relativity of perceived world is formulated. It\n",
            "is shown that this principle is the immediate consequence of the idea of\n",
            "subjective reality. In this paper we show how the methodology of subjective\n",
            "reality may be used for the creation of different types of Strong AI systems.\n",
            "Actual Title : \n",
            "Subjective Reality and Strong Artificial Intelligence\n",
            "Generated Title : \n",
            "perception of su doku\n",
            "Abstract : \n",
            "Proof nets are a graph theoretical representation of proofs in various\n",
            "fragments of type-logical grammar. In spite of this basis in graph theory,\n",
            "there has been relatively little attention to the use of graph theoretic\n",
            "algorithms for type-logical proof search. In this paper we will look at several\n",
            "ways in which standard graph theoretic algorithms can be used to restrict the\n",
            "search space. In particular, we will provide an O(n4) algorithm for selecting\n",
            "an optimal axiom link at any stage in the proof search as well as a O(kn3)\n",
            "algorithm for selecting the k best proof candidates.\n",
            "Actual Title : \n",
            "Graph Algorithms for Improving Type-Logical Proof Search\n",
            "Generated Title : \n",
            "coloring\n",
            "Abstract : \n",
            "Representation learning and unsupervised learning are two central topics of\n",
            "machine learning and signal processing. Deep learning is one of the most\n",
            "effective unsupervised representation learning approach. The main contributions\n",
            "of this paper to the topics are as follows. (i) We propose to view the\n",
            "representative deep learning approaches as special cases of the knowledge reuse\n",
            "framework of clustering ensemble. (ii) We propose to view sparse coding when\n",
            "used as a feature encoder as the consensus function of clustering ensemble, and\n",
            "view dictionary learning as the training process of the base clusterings of\n",
            "clustering ensemble. (ii) Based on the above two views, we propose a very\n",
            "simple deep learning algorithm, named deep random model ensemble (DRME). It is\n",
            "a stack of random model ensembles. Each random model ensemble is a special\n",
            "k-means ensemble that discards the expectation-maximization optimization of\n",
            "each base k-means but only preserves the default initialization method of the\n",
            "base k-means. (iv) We propose to select the most powerful representation among\n",
            "the layers by applying DRME to clustering where the single-linkage is used as\n",
            "the clustering algorithm. Moreover, the DRME based clustering can also detect\n",
            "the number of the natural clusters accurately. Extensive experimental\n",
            "comparisons with 5 representation learning methods on 19 benchmark data sets\n",
            "demonstrate the effectiveness of DRME.\n",
            "Actual Title : \n",
            "Simple Deep Random Model Ensemble\n",
            "Generated Title : \n",
            "clustering\n",
            "Abstract : \n",
            "GANs excel at learning high dimensional distributions, but they can update\n",
            "generator parameters in directions that do not correspond to the steepest\n",
            "descent direction of the objective. Prominent examples of problematic update\n",
            "directions include those used in both Goodfellow's original GAN and the\n",
            "WGAN-GP. To formally describe an optimal update direction, we introduce a\n",
            "theoretical framework which allows the derivation of requirements on both the\n",
            "divergence and corresponding method for determining an update direction. These\n",
            "requirements guarantee unbiased mini-batch updates in the direction of steepest\n",
            "descent. We propose a novel divergence which approximates the Wasserstein\n",
            "distance while regularizing the critic's first order information. Together with\n",
            "an accompanying update direction, this divergence fulfills the requirements for\n",
            "unbiased steepest descent updates. We verify our method, the First Order GAN,\n",
            "with CelebA image generation and set a new state of the art on the One Billion\n",
            "Word language generation task.\n",
            "Actual Title : \n",
            "First Order Generative Adversarial Networks\n",
            "Generated Title : \n",
            "adversarial networks\n",
            "Abstract : \n",
            "This paper investigates energy efficiency for two-tier femtocell networks\n",
            "through combining game theory and stochastic learning. With the Stackelberg\n",
            "game formulation, a hierarchical reinforcement learning framework is applied to\n",
            "study the joint average utility maximization of macrocells and femtocells\n",
            "subject to the minimum signal-to-interference-plus-noise-ratio requirements.\n",
            "The macrocells behave as the leaders and the femtocells are followers during\n",
            "the learning procedure. At each time step, the leaders commit to dynamic\n",
            "strategies based on the best responses of the followers, while the followers\n",
            "compete against each other with no further information but the leaders'\n",
            "strategy information. In this paper, we propose two learning algorithms to\n",
            "schedule each cell's stochastic power levels, leading by the macrocells.\n",
            "Numerical experiments are presented to validate the proposed studies and show\n",
            "that the two learning algorithms substantially improve the energy efficiency of\n",
            "the femtocell networks.\n",
            "Actual Title : \n",
            "Improving Energy Efficiency in Femtocell Networks: A Hierarchical\n",
            "  Reinforcement Learning Framework\n",
            "Generated Title : \n",
            "reinforcement learning with hierarchical reinforcement learning\n",
            "Abstract : \n",
            "Obstacle Detection is a central problem for any robotic system, and critical\n",
            "for autonomous systems that travel at high speeds in unpredictable environment.\n",
            "This is often achieved through scene depth estimation, by various means. When\n",
            "fast motion is considered, the detection range must be longer enough to allow\n",
            "for safe avoidance and path planning. Current solutions often make assumption\n",
            "on the motion of the vehicle that limit their applicability, or work at very\n",
            "limited ranges due to intrinsic constraints. We propose a novel\n",
            "appearance-based Object Detection system that is able to detect obstacles at\n",
            "very long range and at a very high speed (~300Hz), without making assumptions\n",
            "on the type of motion. We achieve these results using a Deep Neural Network\n",
            "approach trained on real and synthetic images and trading some depth accuracy\n",
            "for fast, robust and consistent operation. We show how photo-realistic\n",
            "synthetic images are able to solve the problem of training set dimension and\n",
            "variety typical of machine learning approaches, and how our system is robust to\n",
            "massive blurring of test images.\n",
            "Actual Title : \n",
            "Fast Robust Monocular Depth Estimation for Obstacle Detection with Fully\n",
            "  Convolutional Networks\n",
            "Generated Title : \n",
            "instrument detection using deep learning\n",
            "Abstract : \n",
            "Hyperspectral cameras can provide unique spectral signatures for consistently\n",
            "distinguishing materials that can be used to solve surveillance tasks. In this\n",
            "paper, we propose a novel real-time hyperspectral likelihood maps-aided\n",
            "tracking method (HLT) inspired by an adaptive hyperspectral sensor. A moving\n",
            "object tracking system generally consists of registration, object detection,\n",
            "and tracking modules. We focus on the target detection part and remove the\n",
            "necessity to build any offline classifiers and tune a large amount of\n",
            "hyperparameters, instead learning a generative target model in an online manner\n",
            "for hyperspectral channels ranging from visible to infrared wavelengths. The\n",
            "key idea is that, our adaptive fusion method can combine likelihood maps from\n",
            "multiple bands of hyperspectral imagery into one single more distinctive\n",
            "representation increasing the margin between mean value of foreground and\n",
            "background pixels in the fused map. Experimental results show that the HLT not\n",
            "only outperforms all established fusion methods but is on par with the current\n",
            "state-of-the-art hyperspectral target tracking frameworks.\n",
            "Actual Title : \n",
            "Aerial Vehicle Tracking by Adaptive Fusion of Hyperspectral Likelihood\n",
            "  Maps\n",
            "Generated Title : \n",
            "depth based tracking of spatio temporally\n",
            "Abstract : \n",
            "Roguelike games generally feature exploration problems as a critical, yet\n",
            "often repetitive element of gameplay. Automated approaches, however, face\n",
            "challenges in terms of optimality, as well as due to incomplete information,\n",
            "such as from the presence of secret doors. This paper presents an algorithmic\n",
            "approach to exploration of roguelike dungeon environments. Our design aims to\n",
            "minimize exploration time, balancing coverage and discovery of secret areas\n",
            "with resource cost. Our algorithm is based on the concept of occupancy maps\n",
            "popular in robotics, adapted to encourage efficient discovery of secret access\n",
            "points. Through extensive experimentation on NetHack maps we show that this\n",
            "technique is significantly more efficient than simpler greedy approaches. We\n",
            "further investigate optimized parameterization for the algorithm through a\n",
            "comprehensive data analysis. These results point towards better automation for\n",
            "players as well as heuristics applicable to fully automated gameplay.\n",
            "Actual Title : \n",
            "Exploration in NetHack with Secret Discovery\n",
            "Generated Title : \n",
            "<unk> <unk> su doku\n",
            "Abstract : \n",
            "Automatic detection of pulmonary nodules in thoracic computed tomography (CT)\n",
            "scans has been an active area of research for the last two decades. However,\n",
            "there have only been few studies that provide a comparative performance\n",
            "evaluation of different systems on a common database. We have therefore set up\n",
            "the LUNA16 challenge, an objective evaluation framework for automatic nodule\n",
            "detection algorithms using the largest publicly available reference database of\n",
            "chest CT scans, the LIDC-IDRI data set. In LUNA16, participants develop their\n",
            "algorithm and upload their predictions on 888 CT scans in one of the two\n",
            "tracks: 1) the complete nodule detection track where a complete CAD system\n",
            "should be developed, or 2) the false positive reduction track where a provided\n",
            "set of nodule candidates should be classified. This paper describes the setup\n",
            "of LUNA16 and presents the results of the challenge so far. Moreover, the\n",
            "impact of combining individual systems on the detection performance was also\n",
            "investigated. It was observed that the leading solutions employed convolutional\n",
            "networks and used the provided set of nodule candidates. The combination of\n",
            "these solutions achieved an excellent sensitivity of over 95% at fewer than 1.0\n",
            "false positives per scan. This highlights the potential of combining algorithms\n",
            "to improve the detection performance. Our observer study with four expert\n",
            "readers has shown that the best system detects nodules that were missed by\n",
            "expert readers who originally annotated the LIDC-IDRI data. We released this\n",
            "set of additional nodules for further development of CAD systems.\n",
            "Actual Title : \n",
            "Validation, comparison, and combination of algorithms for automatic\n",
            "  detection of pulmonary nodules in computed tomography images: the LUNA16\n",
            "  challenge\n",
            "Generated Title : \n",
            "<unk> detection alarm detection in <unk>\n",
            "Abstract : \n",
            "A perturbative approach is used to quantify the effect of noise in data\n",
            "points on fitted parameters in a general homogeneous linear model, and the\n",
            "results applied to the case of conic sections. There is an optimal choice of\n",
            "normalisation that minimises bias, and iteration with the correct reweighting\n",
            "significantly improves statistical reliability. By conditioning on an\n",
            "appropriate prior, an unbiased type-specific fit can be obtained. Error\n",
            "estimates for the conic coefficients may also be used to obtain both bias\n",
            "corrections and confidence intervals for other curve parameters.\n",
            "Actual Title : \n",
            "A Bayesian approach to type-specific conic fitting\n",
            "Generated Title : \n",
            "consistency of epipolar correlations  matrices\n",
            "Abstract : \n",
            "An approach to robotics called layered evolution and merging features from\n",
            "the subsumption architecture into evolutionary robotics is presented, and its\n",
            "advantages are discussed. This approach is used to construct a layered\n",
            "controller for a simulated robot that learns which light source to approach in\n",
            "an environment with obstacles. The evolvability and performance of layered\n",
            "evolution on this task is compared to (standard) monolithic evolution,\n",
            "incremental and modularised evolution. To corroborate the hypothesis that a\n",
            "layered controller performs at least as well as an integrated one, the evolved\n",
            "layers are merged back into a single network. On the grounds of the test\n",
            "results, it is argued that layered evolution provides a superior approach for\n",
            "many tasks, and it is suggested that this approach may be the key to scaling up\n",
            "evolutionary robotics.\n",
            "Actual Title : \n",
            "Evolution of a Subsumption Architecture Neurocontroller\n",
            "Generated Title : \n",
            "high level <unk>\n",
            "Abstract : \n",
            "Retinal vessel information is helpful in retinal disease screening and\n",
            "diagnosis. Retinal vessel segmentation provides useful information about\n",
            "vessels and can be used by physicians during intraocular surgery and retinal\n",
            "diagnostic operations. Convolutional neural networks (CNNs) are powerful tools\n",
            "for classification and segmentation of medical images. Complexity of CNNs makes\n",
            "it difficult to implement them in portable devices such as binocular indirect\n",
            "ophthalmoscopes. In this paper a simplification approach is proposed for CNNs\n",
            "based on combination of quantization and pruning. Fully connected layers are\n",
            "quantized and convolutional layers are pruned to have a simple and efficient\n",
            "network structure. Experiments on images of the STARE dataset show that our\n",
            "simplified network is able to segment retinal vessels with acceptable accuracy\n",
            "and low complexity.\n",
            "Actual Title : \n",
            "Low complexity convolutional neural network for vessel segmentation in\n",
            "  portable retinal diagnostic devices\n",
            "Generated Title : \n",
            "brain tumor segmentation using cascaded neural networks\n",
            "Abstract : \n",
            "Automatically recognized terminology is widely used for various\n",
            "domain-specific texts processing tasks, such as machine translation,\n",
            "information retrieval or sentiment analysis. However, there is still no\n",
            "agreement on which methods are best suited for particular settings and,\n",
            "moreover, there is no reliable comparison of already developed methods. We\n",
            "believe that one of the main reasons is the lack of state-of-the-art methods\n",
            "implementations, which are usually non-trivial to recreate. In order to address\n",
            "these issues, we present ATR4S, an open-source software written in Scala that\n",
            "comprises more than 15 methods for automatic terminology recognition (ATR) and\n",
            "implements the whole pipeline from text document preprocessing, to term\n",
            "candidates collection, term candidates scoring, and finally, term candidates\n",
            "ranking. It is highly scalable, modular and configurable tool with support of\n",
            "automatic caching. We also compare 10 state-of-the-art methods on 7 open\n",
            "datasets by average precision and processing time. Experimental comparison\n",
            "reveals that no single method demonstrates best average precision for all\n",
            "datasets and that other available tools for ATR do not contain the best\n",
            "methods.\n",
            "Actual Title : \n",
            "ATR4S: Toolkit with State-of-the-art Automatic Terms Recognition Methods\n",
            "  in Scala\n",
            "Generated Title : \n",
            "  <unk> x <unk>\n",
            "Abstract : \n",
            "We present results from the first geological field tests of the `Cyborg\n",
            "Astrobiologist', which is a wearable computer and video camcorder system that\n",
            "we are using to test and train a computer-vision system towards having some of\n",
            "the autonomous decision-making capabilities of a field-geologist and\n",
            "field-astrobiologist. The Cyborg Astrobiologist platform has thus far been used\n",
            "for testing and development of these algorithms and systems: robotic\n",
            "acquisition of quasi-mosaics of images, real-time image segmentation, and\n",
            "real-time determination of interesting points in the image mosaics. The\n",
            "hardware and software systems function reliably, and the computer-vision\n",
            "algorithms are adequate for the first field tests. In addition to the\n",
            "proof-of-concept aspect of these field tests, the main result of these field\n",
            "tests is the enumeration of those issues that we can improve in the future,\n",
            "including: first, detection and accounting for shadows caused by 3D jagged\n",
            "edges in the outcrop; second, reincorporation of more sophisticated\n",
            "texture-analysis algorithms into the system; third, creation of hardware and\n",
            "software capabilities to control the camera's zoom lens in an intelligent\n",
            "manner; and fourth, development of algorithms for interpretation of complex\n",
            "geological scenery. Nonetheless, despite these technical inadequacies, this\n",
            "Cyborg Astrobiologist system, consisting of a camera-equipped wearable-computer\n",
            "and its computer-vision algorithms, has demonstrated its ability of finding\n",
            "genuinely interesting points in real-time in the geological scenery, and then\n",
            "gathering more information about these interest points in an automated manner.\n",
            "Actual Title : \n",
            "The Cyborg Astrobiologist: First Field Experience\n",
            "Generated Title : \n",
            "<unk> artwork flat  flight flight flight\n",
            "Abstract : \n",
            "Providing security for webservers against unwanted and automated\n",
            "registrations has become a big concern. To prevent these kinds of false\n",
            "registrations many websites use CAPTCHAs. Among all kinds of CAPTCHAs OCR-Based\n",
            "or visual CAPTCHAs are very common. Actually visual CAPTCHA is an image\n",
            "containing a sequence of characters. So far most of visual CAPTCHAs, in order\n",
            "to resist against OCR programs, use some common implementations such as\n",
            "wrapping the characters, random placement and rotations of characters, etc. In\n",
            "this paper we applied Gaussian Blur filter, which is an image transformation,\n",
            "to visual CAPTCHAs to reduce their readability by OCR programs. We concluded\n",
            "that this technique made CAPTCHAs almost unreadable for OCR programs but, their\n",
            "readability by human users still remained high.\n",
            "Actual Title : \n",
            "Improve CAPTCHA's Security Using Gaussian Blur Filter\n",
            "Generated Title : \n",
            "ihs image processing  a feature \n",
            "Abstract : \n",
            "Deep networks trained on demonstrations of human driving have learned to\n",
            "follow roads and avoid obstacles. However, driving policies trained via\n",
            "imitation learning cannot be controlled at test time. A vehicle trained\n",
            "end-to-end to imitate an expert cannot be guided to take a specific turn at an\n",
            "upcoming intersection. This limits the utility of such systems. We propose to\n",
            "condition imitation learning on high-level command input. At test time, the\n",
            "learned driving policy functions as a chauffeur that handles sensorimotor\n",
            "coordination but continues to respond to navigational commands. We evaluate\n",
            "different architectures for conditional imitation learning in vision-based\n",
            "driving. We conduct experiments in realistic three-dimensional simulations of\n",
            "urban driving and on a 1/5 scale robotic truck that is trained to drive in a\n",
            "residential area. Both systems drive based on visual input yet remain\n",
            "responsive to high-level navigational commands. The supplementary video can be\n",
            "viewed at https://youtu.be/cFtnflNe5fM\n",
            "Actual Title : \n",
            "End-to-end Driving via Conditional Imitation Learning\n",
            "Generated Title : \n",
            "imitation learning\n",
            "Abstract : \n",
            "In this paper, we consider the problem of automatically segmenting neuronal\n",
            "cells in dual-color confocal microscopy images. This problem is a key task in\n",
            "various quantitative analysis applications in neuroscience, such as tracing\n",
            "cell genesis in Danio rerio (zebrafish) brains. Deep learning, especially using\n",
            "fully convolutional networks (FCN), has profoundly changed segmentation\n",
            "research in biomedical imaging. We face two major challenges in this problem.\n",
            "First, neuronal cells may form dense clusters, making it difficult to correctly\n",
            "identify all individual cells (even to human experts). Consequently,\n",
            "segmentation results of the known FCN-type models are not accurate enough.\n",
            "Second, pixel-wise ground truth is difficult to obtain. Only a limited amount\n",
            "of approximate instance-wise annotation can be collected, which makes the\n",
            "training of FCN models quite cumbersome. We propose a new FCN-type deep\n",
            "learning model, called deep complete bipartite networks (CB-Net), and a new\n",
            "scheme for leveraging approximate instance-wise annotation to train our\n",
            "pixel-wise prediction model. Evaluated using seven real datasets, our proposed\n",
            "new CB-Net model outperforms the state-of-the-art FCN models and produces\n",
            "neuron segmentation results of remarkable quality\n",
            "Actual Title : \n",
            "Neuron Segmentation Using Deep Complete Bipartite Networks\n",
            "Generated Title : \n",
            "residual networks for for deep residual networks\n",
            "Abstract : \n",
            "While the philosophical literature has extensively studied how decisions\n",
            "relate to arguments, reasons and justifications, decision theory almost\n",
            "entirely ignores the latter notions and rather focuses on preference and\n",
            "belief. In this article, we argue that decision theory can largely benefit from\n",
            "explicitly taking into account the stance that decision-makers take towards\n",
            "arguments and counter-arguments. To that end, we elaborate a formal framework\n",
            "aiming to integrate the role of arguments and argumentation in decision theory\n",
            "and decision aid. We start from a decision situation, where an individual\n",
            "requests decision support. In this context, we formally define, as a\n",
            "commendable basis for decision-aid, this individual's deliberated judgment,\n",
            "popularized by Rawls. We explain how models of deliberated judgment can be\n",
            "validated empirically. We then identify conditions upon which the existence of\n",
            "a valid model can be taken for granted, and analyze how these conditions can be\n",
            "relaxed. We then explore the significance of our proposed framework for\n",
            "decision aiding practice. We argue that our concept of deliberated judgment\n",
            "owes its normative credentials both to its normative foundations (the idea of\n",
            "rationality based on arguments) and to its reference to empirical reality (the\n",
            "stance that real, empirical individuals hold towards arguments and\n",
            "counter-arguments, on due reflection). We then highlight that our framework\n",
            "opens promising avenues for future research involving both philosophical and\n",
            "decision theoretic approaches, as well as empirical implementations.\n",
            "Actual Title : \n",
            "A formal framework for deliberated judgment\n",
            "Generated Title : \n",
            "negotiation\n",
            "Abstract : \n",
            "We introduce a novel evolutionary formulation of the problem of finding a\n",
            "maximum independent set of a graph. The new formulation is based on the\n",
            "relationship that exists between a graph's independence number and its acyclic\n",
            "orientations. It views such orientations as individuals and evolves them with\n",
            "the aid of evolutionary operators that are very heavily based on the structure\n",
            "of the graph and its acyclic orientations. The resulting heuristic has been\n",
            "tested on some of the Second DIMACS Implementation Challenge benchmark graphs,\n",
            "and has been found to be competitive when compared to several of the other\n",
            "heuristics that have also been tested on those graphs.\n",
            "Actual Title : \n",
            "A novel evolutionary formulation of the maximum independent set problem\n",
            "Generated Title : \n",
            "<unk> of su doku\n",
            "Abstract : \n",
            "We present a new image inpainting algorithm, the Averaging and Hypoelliptic\n",
            "Evolution (AHE) algorithm, inspired by the one presented in [SIAM J. Imaging\n",
            "Sci., vol. 7, no. 2, pp. 669--695, 2014] and based upon a semi-discrete\n",
            "variation of the Citti-Petitot-Sarti model of the primary visual cortex V1. The\n",
            "AHE algorithm is based on a suitable combination of sub-Riemannian hypoelliptic\n",
            "diffusion and ad-hoc local averaging techniques. In particular, we focus on\n",
            "reconstructing highly corrupted images (i.e. where more than the 80% of the\n",
            "image is missing), for which we obtain reconstructions comparable with the\n",
            "state-of-the-art.\n",
            "Actual Title : \n",
            "Highly corrupted image inpainting through hypoelliptic diffusion\n",
            "Generated Title : \n",
            "image image\n",
            "Abstract : \n",
            "This paper presents a scalable method for integrating compositional\n",
            "morphological representations into a vector-based probabilistic language model.\n",
            "Our approach is evaluated in the context of log-bilinear language models,\n",
            "rendered suitably efficient for implementation inside a machine translation\n",
            "decoder by factoring the vocabulary. We perform both intrinsic and extrinsic\n",
            "evaluations, presenting results on a range of languages which demonstrate that\n",
            "our model learns morphological representations that both perform well on word\n",
            "similarity tasks and lead to substantial reductions in perplexity. When used\n",
            "for translation into morphologically rich languages with large vocabularies,\n",
            "our models obtain improvements of up to 1.2 BLEU points relative to a baseline\n",
            "system using back-off n-gram models.\n",
            "Actual Title : \n",
            "Compositional Morphology for Word Representations and Language Modelling\n",
            "Generated Title : \n",
            "language parsing with fully convolutional\n",
            "Abstract : \n",
            "Transformation-based learning has been successfully employed to solve many\n",
            "natural language processing problems. It achieves state-of-the-art performance\n",
            "on many natural language processing tasks and does not overtrain easily.\n",
            "However, it does have a serious drawback: the training time is often\n",
            "intorelably long, especially on the large corpora which are often used in NLP.\n",
            "In this paper, we present a novel and realistic method for speeding up the\n",
            "training time of a transformation-based learner without sacrificing\n",
            "performance. The paper compares and contrasts the training time needed and\n",
            "performance achieved by our modified learner with two other systems: a standard\n",
            "transformation-based learner, and the ICA system \\cite{hepple00:tbl}. The\n",
            "results of these experiments show that our system is able to achieve a\n",
            "significant improvement in training time while still achieving the same\n",
            "performance as a standard transformation-based learner. This is a valuable\n",
            "contribution to systems and algorithms which utilize transformation-based\n",
            "learning at any part of the execution.\n",
            "Actual Title : \n",
            "Transformation-Based Learning in the Fast Lane\n",
            "Generated Title : \n",
            "learning naive bayes\n",
            "Abstract : \n",
            "Similarity-based clustering and semi-supervised learning methods separate the\n",
            "data into clusters or classes according to the pairwise similarity between the\n",
            "data, and the pairwise similarity is crucial for their performance. In this\n",
            "paper, we propose a novel discriminative similarity learning framework which\n",
            "learns discriminative similarity for either data clustering or semi-supervised\n",
            "learning. The proposed framework learns classifier from each hypothetical\n",
            "labeling, and searches for the optimal labeling by minimizing the\n",
            "generalization error of the learned classifiers associated with the\n",
            "hypothetical labeling. Kernel classifier is employed in our framework. By\n",
            "generalization analysis via Rademacher complexity, the generalization error\n",
            "bound for the kernel classifier learned from hypothetical labeling is expressed\n",
            "as the sum of pairwise similarity between the data from different classes,\n",
            "parameterized by the weights of the kernel classifier. Such pairwise similarity\n",
            "serves as the discriminative similarity for the purpose of clustering and\n",
            "semi-supervised learning, and discriminative similarity with similar form can\n",
            "also be induced by the integrated squared error bound for kernel density\n",
            "classification. Based on the discriminative similarity induced by the kernel\n",
            "classifier, we propose new clustering and semi-supervised learning methods.\n",
            "Actual Title : \n",
            "Discriminative Similarity for Clustering and Semi-Supervised Learning\n",
            "Generated Title : \n",
            "distance metric learning\n",
            "Abstract : \n",
            "Realistic mobility models can demonstrate more precise evaluation results\n",
            "because their parameters are closer to the reality. In this paper a realistic\n",
            "Fuzzy Mobility Model has been proposed. This model has rules which is\n",
            "changeable depending on nodes and environment conditions. This model is more\n",
            "complete and precise than the other mobility models and this is the advantage\n",
            "of this model. After simulation, it was found out that not only considering\n",
            "nodes movement as being imprecise (fuzzy) has a positive effects on most of ad\n",
            "hoc network parameters, but also, more importantly as they are closer to the\n",
            "real world condition, they can have a more positive effect on the\n",
            "implementation of ad hoc network protocols.\n",
            "Actual Title : \n",
            "A Fuzzy Realistic Mobility Model For Ad hoc Networks\n",
            "Generated Title : \n",
            "memory networks\n",
            "Abstract : \n",
            "Today, we can find many search engines which provide us with information\n",
            "which is more operational in nature. None of the search engines provide domain\n",
            "specific information. This becomes very troublesome to a novice user who wishes\n",
            "to have information in a particular domain. In this paper, we have developed an\n",
            "ontology which can be used by a domain specific search engine. We have\n",
            "developed an ontology on human anatomy, which captures information regarding\n",
            "cardiovascular system, digestive system, skeleton and nervous system. This\n",
            "information can be used by people working in medical and health care domain.\n",
            "Actual Title : \n",
            "OntoAna: Domain Ontology for Human Anatomy\n",
            "Generated Title : \n",
            "thesaurus  <unk> su doku\n",
            "Abstract : \n",
            "We present an efficient learning algorithm for the problem of training neural\n",
            "networks with discrete synapses, a well-known hard (NP-complete) discrete\n",
            "optimization problem. The algorithm is a variant of the so-called Max-Sum (MS)\n",
            "algorithm. In particular, we show how, for bounded integer weights with $q$\n",
            "distinct states and independent concave a priori distribution (e.g. $l_{1}$\n",
            "regularization), the algorithm's time complexity can be made to scale as\n",
            "$O\\left(N\\log N\\right)$ per node update, thus putting it on par with\n",
            "alternative schemes, such as Belief Propagation (BP), without resorting to\n",
            "approximations. Two special cases are of particular interest: binary synapses\n",
            "$W\\in\\{-1,1\\}$ and ternary synapses $W\\in\\{-1,0,1\\}$ with $l_{0}$\n",
            "regularization. The algorithm we present performs as well as BP on binary\n",
            "perceptron learning problems, and may be better suited to address the problem\n",
            "on fully-connected two-layer networks, since inherent symmetries in two layer\n",
            "networks are naturally broken using the MS approach.\n",
            "Actual Title : \n",
            "A Max-Sum algorithm for training discrete neural networks\n",
            "Generated Title : \n",
            "neural networks\n",
            "Abstract : \n",
            "Sparse coding is an unsupervised learning algorithm that learns a succinct\n",
            "high-level representation of the inputs given only unlabeled data; it\n",
            "represents each input as a sparse linear combination of a set of basis\n",
            "functions. Originally applied to modeling the human visual cortex, sparse\n",
            "coding has also been shown to be useful for self-taught learning, in which the\n",
            "goal is to solve a supervised classification task given access to additional\n",
            "unlabeled data drawn from different classes than that in the supervised\n",
            "learning problem. Shift-invariant sparse coding (SISC) is an extension of\n",
            "sparse coding which reconstructs a (usually time-series) input using all of the\n",
            "basis functions in all possible shifts. In this paper, we present an efficient\n",
            "algorithm for learning SISC bases. Our method is based on iteratively solving\n",
            "two large convex optimization problems: The first, which computes the linear\n",
            "coefficients, is an L1-regularized linear least squares problem with\n",
            "potentially hundreds of thousands of variables. Existing methods typically use\n",
            "a heuristic to select a small subset of the variables to optimize, but we\n",
            "present a way to efficiently compute the exact solution. The second, which\n",
            "solves for bases, is a constrained linear least squares problem. By optimizing\n",
            "over complex-valued variables in the Fourier domain, we reduce the coupling\n",
            "between the different variables, allowing the problem to be solved efficiently.\n",
            "We show that SISC's learned high-level representations of speech and music\n",
            "provide useful features for classification tasks within those domains. When\n",
            "applied to classification, under certain conditions the learned features\n",
            "outperform state of the art spectral and cepstral features.\n",
            "Actual Title : \n",
            "Shift-Invariance Sparse Coding for Audio Classification\n",
            "Generated Title : \n",
            "learning naive bayes  ell infty  representations\n",
            "Abstract : \n",
            "Fine-grained classification is challenging because categories can only be\n",
            "discriminated by subtle and local differences. Variances in the pose, scale or\n",
            "rotation usually make the problem more difficult. Most fine-grained\n",
            "classification systems follow the pipeline of finding foreground object or\n",
            "object parts (where) to extract discriminative features (what).\n",
            "  In this paper, we propose to apply visual attention to fine-grained\n",
            "classification task using deep neural network. Our pipeline integrates three\n",
            "types of attention: the bottom-up attention that propose candidate patches, the\n",
            "object-level top-down attention that selects relevant patches to a certain\n",
            "object, and the part-level top-down attention that localizes discriminative\n",
            "parts. We combine these attentions to train domain-specific deep nets, then use\n",
            "it to improve both the what and where aspects. Importantly, we avoid using\n",
            "expensive annotations like bounding box or part information from end-to-end.\n",
            "The weak supervision constraint makes our work easier to generalize.\n",
            "  We have verified the effectiveness of the method on the subsets of ILSVRC2012\n",
            "dataset and CUB200_2011 dataset. Our pipeline delivered significant\n",
            "improvements and achieved the best accuracy under the weakest supervision\n",
            "condition. The performance is competitive against other methods that rely on\n",
            "additional annotations.\n",
            "Actual Title : \n",
            "The Application of Two-level Attention Models in Deep Convolutional\n",
            "  Neural Network for Fine-grained Image Classification\n",
            "Generated Title : \n",
            "attention attention model for visual attention\n",
            "Abstract : \n",
            "The machine learning community has become increasingly concerned with the\n",
            "potential for bias and discrimination in predictive models. This has motivated\n",
            "a growing line of work on what it means for a classification procedure to be\n",
            "\"fair.\" In this paper, we investigate the tension between minimizing error\n",
            "disparity across different population groups while maintaining calibrated\n",
            "probability estimates. We show that calibration is compatible only with a\n",
            "single error constraint (i.e. equal false-negatives rates across groups), and\n",
            "show that any algorithm that satisfies this relaxation is no better than\n",
            "randomizing a percentage of predictions for an existing classifier. These\n",
            "unsettling findings, which extend and generalize existing results, are\n",
            "empirically confirmed on several datasets.\n",
            "Actual Title : \n",
            "On Fairness and Calibration\n",
            "Generated Title : \n",
            "ferns for su doku\n",
            "Abstract : \n",
            "Conventional decision trees have a number of favorable properties, including\n",
            "interpretability, a small computational footprint and the ability to learn from\n",
            "little training data. However, they lack a key quality that has helped fuel the\n",
            "deep learning revolution: that of being end-to-end trainable, and to learn from\n",
            "scratch those features that best allow to solve a given supervised learning\n",
            "problem. Recent work (Kontschieder 2015) has addressed this deficit, but at the\n",
            "cost of losing a main attractive trait of decision trees: the fact that each\n",
            "sample is routed along a small subset of tree nodes only. We here propose a\n",
            "model and Expectation-Maximization training scheme for decision trees that are\n",
            "fully probabilistic at train time, but after a deterministic annealing process\n",
            "become deterministic at test time. We also analyze the learned oblique split\n",
            "parameters on image datasets and show that Neural Networks can be trained at\n",
            "each split node. In summary, we present the first end-to-end learning scheme\n",
            "for deterministic decision trees and present results on par with or superior to\n",
            "published standard oblique decision tree algorithms.\n",
            "Actual Title : \n",
            "End-to-end Learning of Deterministic Decision Trees\n",
            "Generated Title : \n",
            "learning naive bayes\n",
            "Abstract : \n",
            "We propose a convolutional network with hierarchical classifiers for\n",
            "per-pixel semantic segmentation, which is able to be trained on multiple,\n",
            "heterogeneous datasets and exploit their semantic hierarchy. Our network is the\n",
            "first to be simultaneously trained on three different datasets from the\n",
            "intelligent vehicles domain, i.e. Cityscapes, GTSDB and Mapillary Vistas, and\n",
            "is able to handle different semantic level-of-detail, class imbalances, and\n",
            "different annotation types, i.e. dense per-pixel and sparse bounding-box\n",
            "labels. We assess our hierarchical approach, by comparing against flat,\n",
            "non-hierarchical classifiers and we show improvements in mean pixel accuracy of\n",
            "13.0% for Cityscapes classes and 2.4% for Vistas classes and 32.3% for GTSDB\n",
            "classes. Our implementation achieves inference rates of 17 fps at a resolution\n",
            "of 520 x 706 for 108 classes running on a GPU.\n",
            "Actual Title : \n",
            "Training of Convolutional Networks on Multiple Heterogeneous Datasets\n",
            "  for Street Scene Semantic Segmentation\n",
            "Generated Title : \n",
            "semantic image segmentation\n",
            "Abstract : \n",
            "In this paper a deterministic preprocessing algorithm is presented, whose\n",
            "output can be given as input to most state-of-the-art epipolar geometry\n",
            "estimation algorithms, improving their results considerably. They are now able\n",
            "to succeed on hard cases for which they failed before. The algorithm consists\n",
            "of three steps, whose scope changes from local to global. In the local step it\n",
            "extracts from a pair of images local features (e.g. SIFT). Similar features\n",
            "from each image are clustered and the clusters are matched yielding a large\n",
            "number of putative matches. In the second step pairs of spatially close\n",
            "features (called 2keypoints) are matched and ranked by a classifier. The\n",
            "2keypoint matches with the highest ranks are selected. In the global step, from\n",
            "each two 2keypoint matches a fundamental matrix is computed. As quite a few of\n",
            "the matrices are generated from correct matches they are used to rank the\n",
            "putative matches found in the first step. For each match the number of\n",
            "fundamental matrices, for which it approximately satisfies the epipolar\n",
            "constraint, is calculated. This set of matches is combined with the putative\n",
            "matches generated by standard methods and their probabilities to be correct are\n",
            "estimated by a classifier. These are then given as input to state-of-the-art\n",
            "epipolar geometry estimation algorithms such as BEEM, BLOGS and USAC yielding\n",
            "much better results than the original algorithms. This was shown in extensive\n",
            "testing performed on almost 900 image pairs from six publicly available\n",
            "data-sets.\n",
            "Actual Title : \n",
            "A General Preprocessing Method for Improved Performance of Epipolar\n",
            "  Geometry Estimation Algorithms\n",
            "Generated Title : \n",
            "ferns\n",
            "Abstract : \n",
            "In the paper, region based stereo matching algorithms are developed for\n",
            "extraction depth information from two color stereo image pair. A filter\n",
            "eliminating unreliable disparity estimation was used for increasing reliability\n",
            "of the disparity map. Obtained results by algorithms were represented and\n",
            "compared.\n",
            "Actual Title : \n",
            "Obtaining Depth Maps From Color Images By Region Based Stereo Matching\n",
            "  Algorithms\n",
            "Generated Title : \n",
            "distortion rectification using distortion rectification\n",
            "Abstract : \n",
            "Deep generative models have been wildly successful at learning coherent\n",
            "latent representations for continuous data such as video and audio. However,\n",
            "generative modeling of discrete data such as arithmetic expressions and\n",
            "molecular structures still poses significant challenges. Crucially,\n",
            "state-of-the-art methods often produce outputs that are not valid. We make the\n",
            "key observation that frequently, discrete data can be represented as a parse\n",
            "tree from a context-free grammar. We propose a variational autoencoder which\n",
            "encodes and decodes directly to and from these parse trees, ensuring the\n",
            "generated outputs are always valid. Surprisingly, we show that not only does\n",
            "our model more often generate valid outputs, it also learns a more coherent\n",
            "latent space in which nearby points decode to similar discrete outputs. We\n",
            "demonstrate the effectiveness of our learned models by showing their improved\n",
            "performance in Bayesian optimization for symbolic regression and molecular\n",
            "synthesis.\n",
            "Actual Title : \n",
            "Grammar Variational Autoencoder\n",
            "Generated Title : \n",
            "variational autoencoders\n",
            "Abstract : \n",
            "360$^{\\circ}$ video requires human viewers to actively control \"where\" to\n",
            "look while watching the video. Although it provides a more immersive experience\n",
            "of the visual content, it also introduces additional burden for viewers;\n",
            "awkward interfaces to navigate the video lead to suboptimal viewing\n",
            "experiences. Virtual cinematography is an appealing direction to remedy these\n",
            "problems, but conventional methods are limited to virtual environments or rely\n",
            "on hand-crafted heuristics. We propose a new algorithm for virtual\n",
            "cinematography that automatically controls a virtual camera within a\n",
            "360$^{\\circ}$ video. Compared to the state of the art, our algorithm allows\n",
            "more general camera control, avoids redundant outputs, and extracts its output\n",
            "videos substantially more efficiently. Experimental results on over 7 hours of\n",
            "real \"in the wild\" video show that our generalized camera control is crucial\n",
            "for viewing 360$^{\\circ}$ video, while the proposed efficient algorithm is\n",
            "essential for making the generalized control computationally tractable.\n",
            "Actual Title : \n",
            "Making 360$^{\\circ}$ Video Watchable in 2D: Learning Videography for\n",
            "  Click Free Viewing\n",
            "Generated Title : \n",
            "video video\n",
            "Abstract : \n",
            "We consider the problem of identifying the causal direction between two\n",
            "discrete random variables using observational data. Unlike previous work, we\n",
            "keep the most general functional model but make an assumption on the unobserved\n",
            "exogenous variable: Inspired by Occam's razor, we assume that the exogenous\n",
            "variable is simple in the true causal direction. We quantify simplicity using\n",
            "R\\'enyi entropy. Our main result is that, under natural assumptions, if the\n",
            "exogenous variable has low $H_0$ entropy (cardinality) in the true direction,\n",
            "it must have high $H_0$ entropy in the wrong direction. We establish several\n",
            "algorithmic hardness results about estimating the minimum entropy exogenous\n",
            "variable. We show that the problem of finding the exogenous variable with\n",
            "minimum entropy is equivalent to the problem of finding minimum joint entropy\n",
            "given $n$ marginal distributions, also known as minimum entropy coupling\n",
            "problem. We propose an efficient greedy algorithm for the minimum entropy\n",
            "coupling problem, that for $n=2$ provably finds a local optimum. This gives a\n",
            "greedy algorithm for finding the exogenous variable with minimum $H_1$ (Shannon\n",
            "Entropy). Our greedy entropy-based causal inference algorithm has similar\n",
            "performance to the state of the art additive noise models in real datasets. One\n",
            "advantage of our approach is that we make no use of the values of random\n",
            "variables but only their distributions. Our method can therefore be used for\n",
            "causal inference for both ordinal and also categorical data, unlike additive\n",
            "noise models.\n",
            "Actual Title : \n",
            "Entropic Causal Inference\n",
            "Generated Title : \n",
            "prediction\n",
            "Abstract : \n",
            "Multi-label classification has attracted an increasing amount of attention in\n",
            "recent years. To this end, many algorithms have been developed to classify\n",
            "multi-label data in an effective manner. However, they usually do not consider\n",
            "the pairwise relations indicated by sample labels, which actually play\n",
            "important roles in multi-label classification. Inspired by this, we naturally\n",
            "extend the traditional pairwise constraints to the multi-label scenario via a\n",
            "flexible thresholding scheme. Moreover, to improve the generalization ability\n",
            "of the classifier, we adopt a boosting-like strategy to construct a multi-label\n",
            "ensemble from a group of base classifiers. To achieve these goals, this paper\n",
            "presents a novel multi-label classification framework named Variable Pairwise\n",
            "Constraint projection for Multi-label Ensemble (VPCME). Specifically, we take\n",
            "advantage of the variable pairwise constraint projection to learn a\n",
            "lower-dimensional data representation, which preserves the correlations between\n",
            "samples and labels. Thereafter, the base classifiers are trained in the new\n",
            "data space. For the boosting-like strategy, we employ both the variable\n",
            "pairwise constraints and the bootstrap steps to diversify the base classifiers.\n",
            "Empirical studies have shown the superiority of the proposed method in\n",
            "comparison with other approaches.\n",
            "Actual Title : \n",
            "Multi-label ensemble based on variable pairwise constraint projection\n",
            "Generated Title : \n",
            "predictors\n",
            "Abstract : \n",
            "Radar sensors can be used for analyzing the induced frequency shifts due to\n",
            "micro-motions in both range and velocity dimensions identified as micro-Doppler\n",
            "($\\boldsymbol{\\mu}$-D) and micro-Range ($\\boldsymbol{\\mu}$-R), respectively.\n",
            "Different moving targets will have unique $\\boldsymbol{\\mu}$-D and\n",
            "$\\boldsymbol{\\mu}$-R signatures that can be used for target classification.\n",
            "Such classification can be used in numerous fields, such as gait recognition,\n",
            "safety and surveillance. In this paper, a 25 GHz FMCW Single-Input\n",
            "Single-Output (SISO) radar is used in industrial safety for real-time\n",
            "human-robot identification. Due to the real-time constraint, joint\n",
            "Range-Doppler (R-D) maps are directly analyzed for our classification problem.\n",
            "Furthermore, a comparison between the conventional classical learning\n",
            "approaches with handcrafted extracted features, ensemble classifiers and deep\n",
            "learning approaches is presented. For ensemble classifiers, restructured range\n",
            "and velocity profiles are passed directly to ensemble trees, such as gradient\n",
            "boosting and random forest without feature extraction. Finally, a Deep\n",
            "Convolutional Neural Network (DCNN) is used and raw R-D images are directly fed\n",
            "into the constructed network. DCNN shows a superior performance of 99\\%\n",
            "accuracy in identifying humans from robots on a single R-D map.\n",
            "Actual Title : \n",
            "Micro-Doppler Based Human-Robot Classification Using Ensemble and Deep\n",
            "  Learning Approaches\n",
            "Generated Title : \n",
            "based feature extraction for for dietary function\n",
            "Abstract : \n",
            "The paper introduces a new modular action language, ALM, and illustrates the\n",
            "methodology of its use. It is based on the approach of Gelfond and Lifschitz\n",
            "(1993; 1998) in which a high-level action language is used as a front end for a\n",
            "logic programming system description. The resulting logic programming\n",
            "representation is used to perform various computational tasks. The methodology\n",
            "based on existing action languages works well for small and even medium size\n",
            "systems, but is not meant to deal with larger systems that require structuring\n",
            "of knowledge. ALM is meant to remedy this problem. Structuring of knowledge in\n",
            "ALM is supported by the concepts of module (a formal description of a specific\n",
            "piece of knowledge packaged as a unit), module hierarchy, and library, and by\n",
            "the division of a system description of ALM into two parts: theory and\n",
            "structure. A theory consists of one or more modules with a common theme,\n",
            "possibly organized into a module hierarchy based on a dependency relation. It\n",
            "contains declarations of sorts, attributes, and properties of the domain\n",
            "together with axioms describing them. Structures are used to describe the\n",
            "domain's objects. These features, together with the means for defining classes\n",
            "of a domain as special cases of previously defined ones, facilitate the\n",
            "stepwise development, testing, and readability of a knowledge base, as well as\n",
            "the creation of knowledge representation libraries. To appear in Theory and\n",
            "Practice of Logic Programming (TPLP).\n",
            "Actual Title : \n",
            "Modular Action Language ALM\n",
            "Generated Title : \n",
            "well typed <unk>\n",
            "Abstract : \n",
            "The rigorous theoretical analyses of algorithms for exact 3-satisfiability\n",
            "(X3SAT) have been proposed in the literature. As we know, previous algorithms\n",
            "for solving X3SAT have been analyzed only regarding the number of variables as\n",
            "the parameter. However, the time complexity for solving X3SAT instances depends\n",
            "not only on the number of variables, but also on the number of clauses.\n",
            "Therefore, it is significant to exploit the time complexity from the other\n",
            "point of view, i.e. the number of clauses. In this paper, we present algorithms\n",
            "for solving X3SAT with rigorous complexity analyses using the number of clauses\n",
            "as the parameter. By analyzing the algorithms, we obtain the new worst-case\n",
            "upper bounds O(1.15855m), where m is the number of clauses.\n",
            "Actual Title : \n",
            "New Worst-Case Upper Bound for X3SAT\n",
            "Generated Title : \n",
            "heuristics\n",
            "Abstract : \n",
            "Deep learning has achieved substantial success in a series of tasks in\n",
            "computer vision. Intelligent video analysis, which can be broadly applied to\n",
            "video surveillance in various smart city applications, can also be driven by\n",
            "such powerful deep learning engines. To practically facilitate deep neural\n",
            "network models in the large-scale video analysis, there are still unprecedented\n",
            "challenges for the large-scale video data management. Deep feature coding,\n",
            "instead of video coding, provides a practical solution for handling the\n",
            "large-scale video surveillance data. To enable interoperability in the context\n",
            "of deep feature coding, standardization is urgent and important. However, due\n",
            "to the explosion of deep learning algorithms and the particularity of feature\n",
            "coding, there are numerous remaining problems in the standardization process.\n",
            "This paper envisions the future deep feature coding standard for the AI\n",
            "oriented large-scale video management, and discusses existing techniques,\n",
            "standards and possible solutions for these open problems.\n",
            "Actual Title : \n",
            "AI Oriented Large-Scale Video Management for Smart City: Technologies,\n",
            "  Standards and Beyond\n",
            "Generated Title : \n",
            "instrument recognition using deep deep residual networks\n",
            "Abstract : \n",
            "This paper reviews Kunchenko's polynomials using as template matching method\n",
            "to recognize template in one-dimensional input signal. Kunchenko's polynomials\n",
            "method is compared with classical methods - cross-correlation and sum of\n",
            "squared differences according to numerical statistical example.\n",
            "Actual Title : \n",
            "Kunchenko's Polynomials for Template Matching\n",
            "Generated Title : \n",
            "owa\n",
            "Abstract : \n",
            "We create and release the first publicly available commercial customer\n",
            "service corpus with annotated relational segments. Human-computer data from\n",
            "three live customer service Intelligent Virtual Agents (IVAs) in the domains of\n",
            "travel and telecommunications were collected, and reviewers marked all text\n",
            "that was deemed unnecessary to the determination of user intention. After\n",
            "merging the selections of multiple reviewers to create highlighted texts, a\n",
            "second round of annotation was done to determine the classes of language\n",
            "present in the highlighted sections such as the presence of Greetings,\n",
            "Backstory, Justification, Gratitude, Rants, or Emotions. This resulting corpus\n",
            "is a valuable resource for improving the quality and relational abilities of\n",
            "IVAs. As well as discussing the corpus itself, we compare the usage of such\n",
            "language in human-human interactions on TripAdvisor forums. We show that\n",
            "removal of this language from task-based inputs has a positive effect on IVA\n",
            "understanding by both an increase in confidence and improvement in responses,\n",
            "demonstrating the need for automated methods of its discovery.\n",
            "Actual Title : \n",
            "An Annotated Corpus of Relational Strategies in Customer Service\n",
            "Generated Title : \n",
            "a messaging tool messaging messaging\n",
            "Abstract : \n",
            "Reordering is a challenge to machine translation (MT) systems. In MT, the\n",
            "widely used approach is to apply word based language model (LM) which considers\n",
            "the constituent units of a sentence as words. In speech recognition (SR), some\n",
            "phrase based LM have been proposed. However, those LMs are not necessarily\n",
            "suitable or optimal for reordering. We propose two phrase based LMs which\n",
            "considers the constituent units of a sentence as phrases. Experiments show that\n",
            "our phrase based LMs outperform the word based LM with the respect of\n",
            "perplexity and n-best list re-ranking.\n",
            "Actual Title : \n",
            "Phrase Based Language Model for Statistical Machine Translation:\n",
            "  Empirical Study\n",
            "Generated Title : \n",
            "of english hindi speech repairs\n",
            "Abstract : \n",
            "In this paper, we present a co-designed petascale high-density GPU cluster to\n",
            "expedite distributed deep learning training with synchronous Stochastic\n",
            "Gradient Descent~(SSGD). This architecture of our heterogeneous cluster is\n",
            "inspired by Harvard architecture. Regarding to different roles in the system,\n",
            "nodes are configured as different specifications. Based on the topology of the\n",
            "whole system's network and properties of different types of nodes, we develop\n",
            "and implement a novel job server parallel software framework, named by\n",
            "\"\\textit{MiMatrix}\", for distributed deep learning training. Compared to the\n",
            "parameter server framework, in which parameter server is a bottleneck of data\n",
            "transfer in AllReduce algorithm of SSGD, the job server undertakes all of\n",
            "controlling, scheduling and monitoring tasks without model data transfer. In\n",
            "MiMatrix, we propose a novel GPUDirect Remote direct memory access~(RDMA)-aware\n",
            "parallel algorithm of AllReucde executed by computing servers, which both\n",
            "computation and handshake message are $O(1)$ at each epoch\n",
            "Actual Title : \n",
            "MiMatrix: A Massively Distributed Deep Learning Framework on a Petascale\n",
            "  High-density Heterogeneous Cluster\n",
            "Generated Title : \n",
            "distributed deep learning  a survey\n",
            "Abstract : \n",
            "Neural spikes in the brain form stochastic sequences, i.e., belong to the\n",
            "class of pulse noises. This stochasticity is a counterintuitive feature because\n",
            "extracting information - such as the commonly supposed neural information of\n",
            "mean spike frequency - requires long times for reasonably low error\n",
            "probability. The mystery could be solved by noise-based logic, wherein\n",
            "randomness has an important function and allows large speed enhancements for\n",
            "special-purpose tasks, and the same mechanism is at work for the brain logic\n",
            "version of this concept.\n",
            "Actual Title : \n",
            "Brain: Biological noise-based logic\n",
            "Generated Title : \n",
            "a <unk> of <unk>\n",
            "Abstract : \n",
            "Transfer learning has revolutionized computer vision, but existing approaches\n",
            "in NLP still require task-specific modifications and training from scratch. We\n",
            "propose Fine-tuned Language Models (FitLaM), an effective transfer learning\n",
            "method that can be applied to any task in NLP, and introduce techniques that\n",
            "are key for fine-tuning a state-of-the-art language model. Our method\n",
            "significantly outperforms the state-of-the-art on five text classification\n",
            "tasks, reducing the error by 18-24% on the majority of datasets. We open-source\n",
            "our pretrained models and code to enable adoption by the community.\n",
            "Actual Title : \n",
            "Fine-tuned Language Models for Text Classification\n",
            "Generated Title : \n",
            "idiomatic database interfacing\n",
            "Abstract : \n",
            "Ontologies usually suffer from the semantic heterogeneity when simultaneously\n",
            "used in information sharing, merging, integrating and querying processes.\n",
            "Therefore, the similarity identification between ontologies being used becomes\n",
            "a mandatory task for all these processes to handle the problem of semantic\n",
            "heterogeneity. In this paper, we propose an efficient technique for similarity\n",
            "measurement between two ontologies. The proposed technique identifies all\n",
            "candidate pairs of similar concepts without omitting any similar pair. The\n",
            "proposed technique can be used in different types of operations on ontologies\n",
            "such as merging, mapping and aligning. By analyzing its results a reasonable\n",
            "improvement in terms of completeness, correctness and overall quality of the\n",
            "results has been found.\n",
            "Actual Title : \n",
            "An Efficient Technique for Similarity Identification between Ontologies\n",
            "Generated Title : \n",
            "reduplication in typographic similarity\n",
            "Abstract : \n",
            "We propose a new method for robust PCA -- the task of recovering a low-rank\n",
            "matrix from sparse corruptions that are of unknown value and support. Our\n",
            "method involves alternating between projecting appropriate residuals onto the\n",
            "set of low-rank matrices, and the set of sparse matrices; each projection is\n",
            "{\\em non-convex} but easy to compute. In spite of this non-convexity, we\n",
            "establish exact recovery of the low-rank matrix, under the same conditions that\n",
            "are required by existing methods (which are based on convex optimization). For\n",
            "an $m \\times n$ input matrix ($m \\leq n)$, our method has a running time of\n",
            "$O(r^2mn)$ per iteration, and needs $O(\\log(1/\\epsilon))$ iterations to reach\n",
            "an accuracy of $\\epsilon$. This is close to the running time of simple PCA via\n",
            "the power method, which requires $O(rmn)$ per iteration, and\n",
            "$O(\\log(1/\\epsilon))$ iterations. In contrast, existing methods for robust PCA,\n",
            "which are based on convex optimization, have $O(m^2n)$ complexity per\n",
            "iteration, and take $O(1/\\epsilon)$ iterations, i.e., exponentially more\n",
            "iterations for the same accuracy.\n",
            "  Experiments on both synthetic and real data establishes the improved speed\n",
            "and accuracy of our method over existing convex implementations.\n",
            "Actual Title : \n",
            "Non-convex Robust PCA\n",
            "Generated Title : \n",
            "low complexity low rank norm norm matrices \n",
            "Abstract : \n",
            "Radiomics is a term which refers to the analysis of the large amount of\n",
            "quantitative tumor features extracted from medical images to find useful\n",
            "predictive, diagnostic or prognostic information. Many recent studies have\n",
            "proved that radiomics can offer a lot of useful information that physicians\n",
            "cannot extract from the medical images and can be associated with other\n",
            "information like gene or protein data. However, most of the classification\n",
            "studies in radiomics report the use of feature selection methods without\n",
            "identifying the machine learning challenges behind radiomics. In this paper, we\n",
            "first show that the radiomics problem should be viewed as an high dimensional,\n",
            "low sample size, multi view learning problem, then we compare different\n",
            "solutions proposed in multi view learning for classifying radiomics data. Our\n",
            "experiments, conducted on several real world multi view datasets, show that the\n",
            "intermediate integration methods work significantly better than filter and\n",
            "embedded feature selection methods commonly used in radiomics.\n",
            "Actual Title : \n",
            "Dissimilarity-based representation for radiomics applications\n",
            "Generated Title : \n",
            "ensemble of machine learning\n",
            "Abstract : \n",
            "Based on a weighted knowledge graph to represent first-order knowledge and\n",
            "combining it with a probabilistic model, we propose a methodology for the\n",
            "creation of a medical knowledge network (MKN) in medical diagnosis. When a set\n",
            "of symptoms is activated for a specific patient, we can generate a ground\n",
            "medical knowledge network composed of symptom nodes and potential disease\n",
            "nodes. By Incorporating a Boltzmann machine into the potential function of a\n",
            "Markov network, we investigated the joint probability distribution of the MKN.\n",
            "In order to deal with numerical symptoms, a multivariate inference model is\n",
            "presented that uses conditional probability. In addition, the weights for the\n",
            "knowledge graph were efficiently learned from manually annotated Chinese\n",
            "Electronic Medical Records (CEMRs). In our experiments, we found numerically\n",
            "that the optimum choice of the quality of disease node and the expression of\n",
            "symptom variable can improve the effectiveness of medical diagnosis. Our\n",
            "experimental results comparing a Markov logic network and the logistic\n",
            "regression algorithm on an actual CEMR database indicate that our method holds\n",
            "promise and that MKN can facilitate studies of intelligent diagnosis.\n",
            "Actual Title : \n",
            "Learning and inference in knowledge-based probabilistic model for\n",
            "  medical diagnosis\n",
            "Generated Title : \n",
            "knowledge graphs\n",
            "Abstract : \n",
            "Recommendation systems rely on historical user data to provide suggestions.\n",
            "We propose an explicit and simple model for the interaction between users and\n",
            "recommendations provided by a platform, and relate this model to the\n",
            "multi-armed bandit literature. First, we show that this interaction leads to a\n",
            "bias in naive estimators due to selection effects. This bias leads to\n",
            "suboptimal outcomes, which we quantify in terms of linear regret. We end the\n",
            "first part by discussing ways to obtain unbiased estimates. The second part of\n",
            "this work considers exploration of alternatives. We show that although agents\n",
            "are myopic, agents' heterogeneous preferences ensure that recommendation\n",
            "systems 'learn' about all alternatives without explicitly incentivizing this\n",
            "exploration. This work provides new and practical insights relevant to a wide\n",
            "range of systems designed to help users make better decisions.\n",
            "Actual Title : \n",
            "Human Interaction with Recommendation Systems: On Bias and Exploration\n",
            "Generated Title : \n",
            "sequential conversation models\n",
            "Abstract : \n",
            "This paper details the implementation of an algorithm for automatically\n",
            "generating a high-level knowledge network to perform commonsense reasoning,\n",
            "specifically with the application of robotic task repair. The network is\n",
            "represented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz\n",
            "2009), which combines a set of directed relations between abstract concepts,\n",
            "including IsA, AtLocation, HasProperty, and UsedFor, with a corresponding\n",
            "probability distribution that models the uncertainty inherent in these\n",
            "relations. Inference over this network enables reasoning over the abstract\n",
            "concepts in order to perform appropriate object substitution or to locate\n",
            "missing objects in the robot's environment. The structure of the network is\n",
            "generated by combining information from two existing knowledge sources:\n",
            "ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done in\n",
            "a \"situated\" manner by only including information relevant a given context.\n",
            "Results show that the generated network is able to accurately predict object\n",
            "categories, locations, properties, and affordances in three different household\n",
            "scenarios.\n",
            "Actual Title : \n",
            "Situated Structure Learning of a Bayesian Logic Network for Commonsense\n",
            "  Reasoning\n",
            "Generated Title : \n",
            "probabilistic networks\n",
            "Abstract : \n",
            "A new image denoising algorithm to deal with the Poisson noise model is\n",
            "given, which is based on the idea of Non-Local Mean. By using the \"Oracle\"\n",
            "concept, we establish a theorem to show that the Non-Local Means Filter can\n",
            "effectively deal with Poisson noise with some modification. Under the\n",
            "theoretical result, we construct our new algorithm called Non-Local Means\n",
            "Poisson Filter and demonstrate in theory that the filter converges at the usual\n",
            "optimal rate. The filter is as simple as the classic Non-Local Means and the\n",
            "simulation results show that our filter is very competitive.\n",
            "Actual Title : \n",
            "A Non-Local Means Filter for Removing the Poisson Noise\n",
            "Generated Title : \n",
            "shrinkage thresholding\n",
            "Abstract : \n",
            "In a knowledge discovery process, interpretation and evaluation of the mined\n",
            "results are indispensable in practice. In the case of data clustering, however,\n",
            "it is often difficult to see in what aspect each cluster has been formed. This\n",
            "paper proposes a method for automatic and objective characterization or\n",
            "\"verbalization\" of the clusters obtained by mixture models, in which we collect\n",
            "conjunctions of propositions (attribute-value pairs) that help us interpret or\n",
            "evaluate the clusters. The proposed method provides us with a new, in-depth and\n",
            "consistent tool for cluster interpretation/evaluation, and works for various\n",
            "types of datasets including continuous attributes and missing values.\n",
            "Experimental results with a couple of standard datasets exhibit the utility of\n",
            "the proposed method, and the importance of the feedbacks from the\n",
            "interpretation/evaluation step.\n",
            "Actual Title : \n",
            "Verbal Characterization of Probabilistic Clusters using Minimal\n",
            "  Discriminative Propositions\n",
            "Generated Title : \n",
            "clustering\n",
            "Abstract : \n",
            "Decomposition methods have been proposed in the past to approximate solutions\n",
            "to large sequential decision making problems. In contexts where an agent\n",
            "interacts with multiple entities, utility decomposition can be used where each\n",
            "individual entity is considered independently. The individual utility functions\n",
            "are then combined in real time to solve the global problem. Although these\n",
            "techniques can perform well empirically, they sacrifice optimality. This paper\n",
            "proposes an approach inspired from multi-fidelity optimization to learn a\n",
            "correction term with a neural network representation. Learning this correction\n",
            "can significantly improve performance. We demonstrate this approach on a\n",
            "pedestrian avoidance problem for autonomous driving. By leveraging strategies\n",
            "to avoid a single pedestrian, the decomposition method can scale to avoid\n",
            "multiple pedestrians. We verify empirically that the proposed correction method\n",
            "leads to a significant improvement over the decomposition method alone and\n",
            "outperforms a policy trained on the full scale problem without utility\n",
            "decomposition.\n",
            "Actual Title : \n",
            "Utility Decomposition with Deep Corrections for Scalable Planning under\n",
            "  Uncertainty\n",
            "Generated Title : \n",
            "muscles suppression\n",
            "Abstract : \n",
            "Many data mining and data analysis techniques operate on dense matrices or\n",
            "complete tables of data. Real-world data sets, however, often contain unknown\n",
            "values. Even many classification algorithms that are designed to operate with\n",
            "missing values still exhibit deteriorated accuracy. One approach to handling\n",
            "missing values is to fill in (impute) the missing values. In this paper, we\n",
            "present a technique for unsupervised learning called Unsupervised\n",
            "Backpropagation (UBP), which trains a multi-layer perceptron to fit to the\n",
            "manifold sampled by a set of observed point-vectors. We evaluate UBP with the\n",
            "task of imputing missing values in datasets, and show that UBP is able to\n",
            "predict missing values with significantly lower sum-squared error than other\n",
            "collaborative filtering and imputation techniques. We also demonstrate with 24\n",
            "datasets and 9 supervised learning algorithms that classification accuracy is\n",
            "usually higher when randomly-withheld values are imputed using UBP, rather than\n",
            "with other methods.\n",
            "Actual Title : \n",
            "Missing Value Imputation With Unsupervised Backpropagation\n",
            "Generated Title : \n",
            "prediction of online mixture models\n",
            "Abstract : \n",
            "Text processing is one of the sub-branches of natural language processing.\n",
            "Recently, the use of machine learning and neural networks methods has been\n",
            "given greater consideration. For this reason, the representation of words has\n",
            "become very important. This article is about word representation or converting\n",
            "words into vectors in Persian text. In this research GloVe, CBOW and skip-gram\n",
            "methods are updated to produce embedded vectors for Persian words. In order to\n",
            "train a neural networks, Bijankhan corpus, Hamshahri corpus and UPEC corpus\n",
            "have been compound and used. Finally, we have 342,362 words that obtained\n",
            "vectors in all three models for this words. These vectors have many usage for\n",
            "Persian natural language processing.\n",
            "Actual Title : \n",
            "word representation or word embedding in Persian text\n",
            "Generated Title : \n",
            "lol\n",
            "Abstract : \n",
            "We identify obfuscated gradients, a kind of gradient masking, as a phenomenon\n",
            "that leads to a false sense of security in defenses against adversarial\n",
            "examples. While defenses that cause obfuscated gradients appear to defeat\n",
            "iterative optimization-based attacks, we find defenses relying on this effect\n",
            "can be circumvented. For each of the three types of obfuscated gradients we\n",
            "discover, we describe characteristic behaviors of defenses exhibiting this\n",
            "effect and develop attack techniques to overcome it. In a case study, examining\n",
            "non-certified white-box-secure defenses at ICLR 2018, we find obfuscated\n",
            "gradients are a common occurrence, with 7 of 8 defenses relying on obfuscated\n",
            "gradients. Our new attacks successfully circumvent 6 completely and 1\n",
            "partially.\n",
            "Actual Title : \n",
            "Obfuscated Gradients Give a False Sense of Security: Circumventing\n",
            "  Defenses to Adversarial Examples\n",
            "Generated Title : \n",
            "crossing <unk>\n",
            "Abstract : \n",
            "In this paper the elicitation of probabilities from human experts is\n",
            "considered as a measurement process, which may be disturbed by random\n",
            "'measurement noise'. Using Bayesian concepts a second order probability\n",
            "distribution is derived reflecting the uncertainty of the input probabilities.\n",
            "The algorithm is based on an approximate sample representation of the basic\n",
            "probabilities. This sample is continuously modified by a stochastic simulation\n",
            "procedure, the Metropolis algorithm, such that the sequence of successive\n",
            "samples corresponds to the desired posterior distribution. The procedure is\n",
            "able to combine inconsistent probabilities according to their reliability and\n",
            "is applicable to general inference networks with arbitrary structure.\n",
            "Dempster-Shafer probability mass functions may be included using specific\n",
            "measurement distributions. The properties of the approach are demonstrated by\n",
            "numerical experiments.\n",
            "Actual Title : \n",
            "Second Order Probabilities for Uncertain and Conflicting Evidence\n",
            "Generated Title : \n",
            "low complexity probability\n",
            "Abstract : \n",
            "We study black-box attacks on machine learning classifiers where each query\n",
            "to the model incurs some cost or risk of detection to the adversary. We focus\n",
            "explicitly on minimizing the number of queries as a major objective.\n",
            "Specifically, we consider the problem of attacking machine learning classifiers\n",
            "subject to a budget of feature modification cost while minimizing the number of\n",
            "queries, where each query returns only a class and confidence score. We\n",
            "describe an approach that uses Bayesian optimization to minimize the number of\n",
            "queries, and find that the number of queries can be reduced to approximately\n",
            "one tenth of the number needed through a random strategy for scenarios where\n",
            "the feature modification cost budget is low.\n",
            "Actual Title : \n",
            "Query-limited Black-box Attacks to Classifiers\n",
            "Generated Title : \n",
            "nonconformity birth birth birth birth birth birth birth\n",
            "Abstract : \n",
            "In this work, we present the results of a systematic study to investigate the\n",
            "(commercial) benefits of automatic text summarization systems in a real world\n",
            "scenario. More specifically, we define a use case in the context of media\n",
            "monitoring and media response analysis and claim that even using a simple\n",
            "query-based extractive approach can dramatically save the processing time of\n",
            "the employees without significantly reducing the quality of their work.\n",
            "Actual Title : \n",
            "On (Commercial) Benefits of Automatic Text Summarization Systems in the\n",
            "  News Domain: A Case of Media Monitoring and Media Response Analysis\n",
            "Generated Title : \n",
            "messaging messaging abuse crises in crises\n",
            "Abstract : \n",
            "We present weight normalization: a reparameterization of the weight vectors\n",
            "in a neural network that decouples the length of those weight vectors from\n",
            "their direction. By reparameterizing the weights in this way we improve the\n",
            "conditioning of the optimization problem and we speed up convergence of\n",
            "stochastic gradient descent. Our reparameterization is inspired by batch\n",
            "normalization but does not introduce any dependencies between the examples in a\n",
            "minibatch. This means that our method can also be applied successfully to\n",
            "recurrent models such as LSTMs and to noise-sensitive applications such as deep\n",
            "reinforcement learning or generative models, for which batch normalization is\n",
            "less well suited. Although our method is much simpler, it still provides much\n",
            "of the speed-up of full batch normalization. In addition, the computational\n",
            "overhead of our method is lower, permitting more optimization steps to be taken\n",
            "in the same amount of time. We demonstrate the usefulness of our method on\n",
            "applications in supervised image recognition, generative modelling, and deep\n",
            "reinforcement learning.\n",
            "Actual Title : \n",
            "Weight Normalization: A Simple Reparameterization to Accelerate Training\n",
            "  of Deep Neural Networks\n",
            "Generated Title : \n",
            "distinguishability\n",
            "Abstract : \n",
            "This paper describes an interdisciplinary approach which brings together the\n",
            "fields of corpus linguistics and translation studies. It presents ongoing work\n",
            "on the creation of a corpus resource in which translation shifts are explicitly\n",
            "annotated. Translation shifts denote departures from formal correspondence\n",
            "between source and target text, i.e. deviations that have occurred during the\n",
            "translation process. A resource in which such shifts are annotated in a\n",
            "systematic way will make it possible to study those phenomena that need to be\n",
            "addressed if machine translation output is to resemble human translation. The\n",
            "resource described in this paper contains English source texts (parliamentary\n",
            "proceedings) and their German translations. The shift annotation is based on\n",
            "predicate-argument structures and proceeds in two steps: first, predicates and\n",
            "their arguments are annotated monolingually in a straightforward manner. Then,\n",
            "the corresponding English and German predicates and arguments are aligned with\n",
            "each other. Whenever a shift - mainly grammatical or semantic -has occurred,\n",
            "the alignment is tagged accordingly.\n",
            "Actual Title : \n",
            "Building a resource for studying translation shifts\n",
            "Generated Title : \n",
            "lol <unk> out of vocabulary out of vocabulary\n",
            "Abstract : \n",
            "In this paper, we present a Convolutional Neural Network (CNN) regression\n",
            "approach for real-time 2-D/3-D registration. Different from optimization-based\n",
            "methods, which iteratively optimize the transformation parameters over a\n",
            "scalar-valued metric function representing the quality of the registration, the\n",
            "proposed method exploits the information embedded in the appearances of the\n",
            "Digitally Reconstructed Radiograph and X-ray images, and employs CNN regressors\n",
            "to directly estimate the transformation parameters. The CNN regressors are\n",
            "trained for local zones and applied in a hierarchical manner to break down the\n",
            "complex regression task into simpler sub-tasks that can be learned separately.\n",
            "Our experiment results demonstrate the advantage of the proposed method in\n",
            "computational efficiency with negligible degradation of registration accuracy\n",
            "compared to intensity-based methods.\n",
            "Actual Title : \n",
            "Real-time 2D/3D Registration via CNN Regression\n",
            "Generated Title : \n",
            "#d regression with cascaded regression\n",
            "Abstract : \n",
            "In this paper, a sparse Markov decision process (MDP) with novel causal\n",
            "sparse Tsallis entropy regularization is proposed.The proposed policy\n",
            "regularization induces a sparse and multi-modal optimal policy distribution of\n",
            "a sparse MDP. The full mathematical analysis of the proposed sparse MDP is\n",
            "provided.We first analyze the optimality condition of a sparse MDP. Then, we\n",
            "propose a sparse value iteration method which solves a sparse MDP and then\n",
            "prove the convergence and optimality of sparse value iteration using the Banach\n",
            "fixed point theorem. The proposed sparse MDP is compared to soft MDPs which\n",
            "utilize causal entropy regularization. We show that the performance error of a\n",
            "sparse MDP has a constant bound, while the error of a soft MDP increases\n",
            "logarithmically with respect to the number of actions, where this performance\n",
            "error is caused by the introduced regularization term. In experiments, we apply\n",
            "sparse MDPs to reinforcement learning problems. The proposed method outperforms\n",
            "existing methods in terms of the convergence speed and performance.\n",
            "Actual Title : \n",
            "Sparse Markov Decision Processes with Causal Sparse Tsallis Entropy\n",
            "  Regularization for Reinforcement Learning\n",
            "Generated Title : \n",
            "bayesian optimization with sparse gaussian processes\n",
            "Abstract : \n",
            "Since many real-world concepts are associated with colour, for example danger\n",
            "with red, linguistic information is often complimented with the use of\n",
            "appropriate colours in information visualization and product marketing. Yet,\n",
            "there is no comprehensive resource that captures concept-colour associations.\n",
            "We present a method to create a large word-colour association lexicon by\n",
            "crowdsourcing. We focus especially on abstract concepts and emotions to show\n",
            "that even though they cannot be physically visualized, they too tend to have\n",
            "strong colour associations. Finally, we show how word-colour associations\n",
            "manifest themselves in language, and quantify usefulness of co-occurrence and\n",
            "polarity cues in automatically detecting colour associations.\n",
            "Actual Title : \n",
            "Colourful Language: Measuring Word-Colour Associations\n",
            "Generated Title : \n",
            "lol\n",
            "Abstract : \n",
            "Acoustic models based on long short-term memory recurrent neural networks\n",
            "(LSTM-RNNs) were applied to statistical parametric speech synthesis (SPSS) and\n",
            "showed significant improvements in naturalness and latency over those based on\n",
            "hidden Markov models (HMMs). This paper describes further optimizations of\n",
            "LSTM-RNN-based SPSS for deployment on mobile devices; weight quantization,\n",
            "multi-frame inference, and robust inference using an {\\epsilon}-contaminated\n",
            "Gaussian loss function. Experimental results in subjective listening tests show\n",
            "that these optimizations can make LSTM-RNN-based SPSS comparable to HMM-based\n",
            "SPSS in runtime speed while maintaining naturalness. Evaluations between\n",
            "LSTM-RNN- based SPSS and HMM-driven unit selection speech synthesis are also\n",
            "presented.\n",
            "Actual Title : \n",
            "Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric\n",
            "  Speech Synthesizers for Mobile Devices\n",
            "Generated Title : \n",
            "recurrent neural timit\n",
            "Abstract : \n",
            "Procedural terrain generation for video games has been traditionally been\n",
            "done with smartly designed but handcrafted algorithms that generate heightmaps.\n",
            "We propose a first step toward the learning and synthesis of these using recent\n",
            "advances in deep generative modelling with openly available satellite imagery\n",
            "from NASA.\n",
            "Actual Title : \n",
            "A step towards procedural terrain generation with GANs\n",
            "Generated Title : \n",
            "<unk> generative adversarial networks\n",
            "Abstract : \n",
            "We propose an original particle-based implementation of the Loopy Belief\n",
            "Propagation (LPB) algorithm for pairwise Markov Random Fields (MRF) on a\n",
            "continuous state space. The algorithm constructs adaptively efficient proposal\n",
            "distributions approximating the local beliefs at each note of the MRF. This is\n",
            "achieved by considering proposal distributions in the exponential family whose\n",
            "parameters are updated iterately in an Expectation Propagation (EP) framework.\n",
            "The proposed particle scheme provides consistent estimation of the LBP\n",
            "marginals as the number of particles increases. We demonstrate that it provides\n",
            "more accurate results than the Particle Belief Propagation (PBP) algorithm of\n",
            "Ihler and McAllester (2009) at a fraction of the computational cost and is\n",
            "additionally more robust empirically. The computational complexity of our\n",
            "algorithm at each iteration is quadratic in the number of particles. We also\n",
            "propose an accelerated implementation with sub-quadratic computational\n",
            "complexity which still provides consistent estimates of the loopy BP marginal\n",
            "distributions and performs almost as well as the original procedure.\n",
            "Actual Title : \n",
            "Expectation Particle Belief Propagation\n",
            "Generated Title : \n",
            "probabilistic tree reweighted attributed diagrams\n",
            "Abstract : \n",
            "In this paper, we consider active information acquisition when the prediction\n",
            "model is meant to be applied on a targeted subset of the population. The goal\n",
            "is to label a pre-specified fraction of customers in the target or test set by\n",
            "iteratively querying for information from the non-target or training set. The\n",
            "number of queries is limited by an overall budget. Arising in the context of\n",
            "two rather disparate applications- banking and medical diagnosis, we pose the\n",
            "active information acquisition problem as a constrained optimization problem.\n",
            "We propose two greedy iterative algorithms for solving the above problem. We\n",
            "conduct experiments with synthetic data and compare results of our proposed\n",
            "algorithms with few other baseline approaches. The experimental results show\n",
            "that our proposed approaches perform better than the baseline schemes.\n",
            "Actual Title : \n",
            "Test Set Selection using Active Information Acquisition for Predictive\n",
            "  Models\n",
            "Generated Title : \n",
            "<unk>\n",
            "Abstract : \n",
            "This paper proves that in iris recognition, the concepts of sheep, goats,\n",
            "lambs and wolves - as proposed by Doddington and Yager in the so-called\n",
            "Biometric Menagerie, are at most fuzzy and at least not quite well defined.\n",
            "They depend not only on the users or on their biometric templates, but also on\n",
            "the parameters that calibrate the iris recognition system. This paper shows\n",
            "that, in the case of iris recognition, the extensions of these concepts have\n",
            "very unsharp and unstable (non-stationary) boundaries. The membership of a user\n",
            "to these categories is more often expressed as a degree (as a fuzzy value)\n",
            "rather than as a crisp value. Moreover, they are defined by fuzzy Sugeno rules\n",
            "instead of classical (crisp) definitions. For these reasons, we said that the\n",
            "Biometric Menagerie proposed by Doddington and Yager could be at most a fuzzy\n",
            "concept of biometry, but even this status is conditioned by improving its\n",
            "definition. All of these facts are confirmed experimentally in a series of 12\n",
            "exhaustive iris recognition tests undertaken for University of Bath Iris Image\n",
            "Database while using three different iris code dimensions (256x16, 128x8 and\n",
            "64x4), two different iris texture encoders (Log-Gabor and Haar-Hilbert) and two\n",
            "different types of safety models.\n",
            "Actual Title : \n",
            "The Biometric Menagerie - A Fuzzy and Inconsistent Concept\n",
            "Generated Title : \n",
            "ihs coverings <unk>\n",
            "Abstract : \n",
            "The increasing demand of world wide web raises the need of predicting the\n",
            "user's web page request.The most widely used approach to predict the web pages\n",
            "is the pattern discovery process of Web usage mining. This process involves\n",
            "inevitability of many techniques like Markov model, association rules and\n",
            "clustering. Fuzzy theory with different techniques has been introduced for the\n",
            "better results. Our focus is on Markov models. This paper is introducing the\n",
            "vague Rules with Markov models for more accuracy using the vague set theory.\n",
            "Actual Title : \n",
            "Integrating Vague Association Mining with Markov Model\n",
            "Generated Title : \n",
            "uncertain evidence\n",
            "Abstract : \n",
            "Sparse decomposition has been widely used for different applications, such as\n",
            "source separation, image classification and image denoising. This paper\n",
            "presents a new algorithm for segmentation of an image into background and\n",
            "foreground text and graphics using sparse decomposition. First, the background\n",
            "is represented using a suitable smooth model, which is a linear combination of\n",
            "a few smoothly varying basis functions, and the foreground text and graphics\n",
            "are modeled as a sparse component overlaid on the smooth background. Then the\n",
            "background and foreground are separated using a sparse decomposition framework\n",
            "and imposing some prior information, which promote the smoothness of\n",
            "background, and the sparsity and connectivity of foreground pixels. This\n",
            "algorithm has been tested on a dataset of images extracted from HEVC standard\n",
            "test sequences for screen content coding, and is shown to outperform prior\n",
            "methods, including least absolute deviation fitting, k-means clustering based\n",
            "segmentation in DjVu, and shape primitive extraction and coding algorithm.\n",
            "Actual Title : \n",
            "Image Segmentation Using Overlapping Group Sparsity\n",
            "Generated Title : \n",
            "image unmixing\n",
            "Abstract : \n",
            "We derive high-probability finite-sample uniform rates of consistency for\n",
            "$k$-NN regression that are optimal up to logarithmic factors under mild\n",
            "assumptions. We moreover show that $k$-NN regression adapts to an unknown lower\n",
            "intrinsic dimension automatically. We then apply the $k$-NN regression rates to\n",
            "establish new results about estimating the level sets and global maxima of a\n",
            "function from noisy observations.\n",
            "Actual Title : \n",
            "Rates of Uniform Consistency for k-NN Regression\n",
            "Generated Title : \n",
            "hinge o # n  birth birth birth birth birth birth\n",
            "Abstract : \n",
            "Control Strategies for hierarchical tree-like probabilistic inference\n",
            "networks are formulated and investigated. Strategies that utilize staged\n",
            "look-ahead and temporary focus on subgoals are formalized and refined using the\n",
            "Depth Vector concept that serves as a tool for defining the 'virtual tree'\n",
            "regarded by the control strategy. The concept is illustrated by four types of\n",
            "control strategies for three-level trees that are characterized according to\n",
            "their Depth Vector, and according to the way they consider intermediate nodes\n",
            "and the role that they let these nodes play. INFERENTI is a computerized\n",
            "inference system written in Prolog, which provides tools for exercising a\n",
            "variety of control strategies. The system also provides tools for simulating\n",
            "test data and for comparing the relative average performance under different\n",
            "strategies.\n",
            "Actual Title : \n",
            "A Framework for Control Strategies in Uncertain Inference Networks\n",
            "Generated Title : \n",
            "probabilistic programming\n",
            "Abstract : \n",
            "This paper presents a challenge to the community: given a large corpus of\n",
            "written text aligned to its normalized spoken form, train an RNN to learn the\n",
            "correct normalization function. We present a data set of general text where the\n",
            "normalizations were generated using an existing text normalization component of\n",
            "a text-to-speech system. This data set will be released open-source in the near\n",
            "future.\n",
            "  We also present our own experiments with this data set with a variety of\n",
            "different RNN architectures. While some of the architectures do in fact produce\n",
            "very good results when measured in terms of overall accuracy, the errors that\n",
            "are produced are problematic, since they would convey completely the wrong\n",
            "message if such a system were deployed in a speech application. On the other\n",
            "hand, we show that a simple FST-based filter can mitigate those errors, and\n",
            "achieve a level of accuracy not achievable by the RNN alone.\n",
            "  Though our conclusions are largely negative on this point, we are actually\n",
            "not arguing that the text normalization problem is intractable using an pure\n",
            "RNN approach, merely that it is not going to be something that can be solved\n",
            "merely by having huge amounts of annotated text data and feeding that to a\n",
            "general RNN model. And when we open-source our data, we will be providing a\n",
            "novel data set for sequence-to-sequence modeling in the hopes that the the\n",
            "community can find better solutions.\n",
            "  The data used in this work have been released and are available at:\n",
            "https://github.com/rwsproat/text-normalization-data\n",
            "Actual Title : \n",
            "RNN Approaches to Text Normalization: A Challenge\n",
            "Generated Title : \n",
            "text text text reading\n",
            "Abstract : \n",
            "Accumulating evidence has shown that iron is involved in the mechanism\n",
            "underlying many neurodegenerative diseases, such as Alzheimer's disease,\n",
            "Parkinson's disease and Huntington's disease. Abnormal (higher) iron\n",
            "accumulation has been detected in the brains of most neurodegenerative\n",
            "patients, especially in the basal ganglia region. Presence of iron leads to\n",
            "changes in MR signal in both magnitude and phase. Accordingly, tissues with\n",
            "high iron concentration appear hypo-intense (darker than usual) in MR\n",
            "contrasts. In this report, we proposed an improved binary hypointensity\n",
            "description and a novel nonbinary hypointensity description based on principle\n",
            "components analysis. Moreover, Kendall's rank correlation coefficient was used\n",
            "to compare the complementary and redundant information provided by the two\n",
            "methods in order to better understand the individual descriptions of iron\n",
            "accumulation in the brain.\n",
            "Actual Title : \n",
            "Binary and nonbinary description of hypointensity in human brain MR\n",
            "  images\n",
            "Generated Title : \n",
            "brain extraction using anatomical eeg\n",
            "Abstract : \n",
            "Quorum sensing is a decentralized biological process, through which a\n",
            "community of cells with no global awareness coordinate their functional\n",
            "behaviors based solely on cell-medium interactions and local decisions. This\n",
            "paper draws inspirations from quorum sensing and colony competition to derive a\n",
            "new algorithm for data clustering. The algorithm treats each data as a single\n",
            "cell, and uses knowledge of local connectivity to cluster cells into multiple\n",
            "colonies simultaneously. It simulates auto-inducers secretion in quorum sensing\n",
            "to tune the influence radius for each cell. At the same time, sparsely\n",
            "distributed core cells spread their influences to form colonies, and\n",
            "interactions between colonies eventually determine each cell's identity. The\n",
            "algorithm has the flexibility to analyze not only static but also time-varying\n",
            "data, which surpasses the capacity of many existing algorithms. Its stability\n",
            "and convergence properties are established. The algorithm is tested on several\n",
            "applications, including both synthetic and real benchmarks data sets, alleles\n",
            "clustering, community detection, image segmentation. In particular, the\n",
            "algorithm's distinctive capability to deal with time-varying data allows us to\n",
            "experiment it on novel applications such as robotic swarms grouping and\n",
            "switching model identification. We believe that the algorithm's promising\n",
            "performance would stimulate many more exciting applications.\n",
            "Actual Title : \n",
            "A Quorum Sensing Inspired Algorithm for Dynamic Clustering\n",
            "Generated Title : \n",
            "distributed particle swarm optimization algorithm time critical wireless sensor\n",
            "Abstract : \n",
            "We consider a framework for structured prediction based on search in the\n",
            "space of complete structured outputs. Given a structured input, an output is\n",
            "produced by running a time-bounded search procedure guided by a learned cost\n",
            "function, and then returning the least cost output uncovered during the search.\n",
            "This framework can be instantiated for a wide range of search spaces and search\n",
            "procedures, and easily incorporates arbitrary structured-prediction loss\n",
            "functions. In this paper, we make two main technical contributions. First, we\n",
            "define the limited-discrepancy search space over structured outputs, which is\n",
            "able to leverage powerful classification learning algorithms to improve the\n",
            "search space quality. Second, we give a generic cost function learning\n",
            "approach, where the key idea is to learn a cost function that attempts to mimic\n",
            "the behavior of conducting searches guided by the true loss function. Our\n",
            "experiments on six benchmark domains demonstrate that using our framework with\n",
            "only a small amount of search is sufficient for significantly improving on\n",
            "state-of-the-art structured-prediction performance.\n",
            "Actual Title : \n",
            "Output Space Search for Structured Prediction\n",
            "Generated Title : \n",
            "option critic models\n",
            "Abstract : \n",
            "In this work, we describe a system that detects paraphrases in Indian\n",
            "Languages as part of our participation in the shared Task on detecting\n",
            "paraphrases in Indian Languages (DPIL) organized by Forum for Information\n",
            "Retrieval Evaluation (FIRE) in 2016. Our paraphrase detection method uses a\n",
            "multinomial logistic regression model trained with a variety of features which\n",
            "are basically lexical and semantic level similarities between two sentences in\n",
            "a pair. The performance of the system has been evaluated against the test set\n",
            "released for the FIRE 2016 shared task on DPIL. Our system achieves the highest\n",
            "f-measure of 0.95 on task1 in Punjabi language.The performance of our system on\n",
            "task1 in Hindi language is f-measure of 0.90. Out of 11 teams participated in\n",
            "the shared task, only four teams participated in all four languages, Hindi,\n",
            "Punjabi, Malayalam and Tamil, but the remaining 7 teams participated in one of\n",
            "the four languages. We also participated in task1 and task2 both for all four\n",
            "Indian Languages. The overall average performance of our system including task1\n",
            "and task2 overall four languages is F1-score of 0.81 which is the second\n",
            "highest score among the four systems that participated in all four languages.\n",
            "Actual Title : \n",
            "KS_JU@DPIL-FIRE2016:Detecting Paraphrases in Indian Languages Using\n",
            "  Multinomial Logistic Regression Model\n",
            "Generated Title : \n",
            "lol <unk> <unk> out of vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}