{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_NLP_Title_Gen_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJx8HaEbhoxG"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import timeit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy import data\n",
        "import random\n",
        "## For reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iryvSLmxh1vw"
      },
      "source": [
        "# Create Preprocessing pipeline for summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBy0Wh1zidtB"
      },
      "source": [
        "tokenize =  lambda s: s.split()\n",
        "import re  \n",
        "def cleanup_text(texts):\n",
        "    cleaned_text = []\n",
        "    for text in texts:\n",
        "        # remove punctuation\n",
        "        text = re.sub('[^a-zA-Z0-9]', ' ', text)\n",
        "        # remove multiple spaces\n",
        "        text = re.sub(r' +', ' ', text)\n",
        "        # remove newline\n",
        "        text = re.sub(r'\\n', ' ', text)\n",
        "        #replace digits with '# symbol\n",
        "        text = re.sub('[0-9]', '#', text)\n",
        "        cleaned_text.append(text)\n",
        "    return cleaned_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0g0XtXnjdW0",
        "outputId": "8b229b7b-e29e-4de4-c4b1-f50a228bd2b8"
      },
      "source": [
        "text = \"Hi\\n ko, \\t hs,  8998,  66jshs. hshs\"\n",
        "print(text.split())\n",
        "cleanup_text(text.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'ko,', 'hs,', '8998,', '66jshs.', 'hshs']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', 'ko ', 'hs ', '#### ', '##jshs ', 'hshs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2MHOhPtklHS"
      },
      "source": [
        "## Create torchtext fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CVDphMZkWaP"
      },
      "source": [
        "#Field for summaries\n",
        "SUM = data.Field(tokenize = tokenize,init_token='<sos>',eos_token='<eos>',pad_first=True,lower = True,preprocessing=cleanup_text)\n",
        "#Field for title\n",
        "TITLE = data.Field(tokenize = tokenize,init_token='<sos>',eos_token='<eos>',lower = True,preprocessing=cleanup_text)\n",
        "#Field for Id\n",
        "#ID = data.Field(use_vocab=False,sequential=False,dtype=torch.LongTensor,postprocessing=data.Pipeline(lambda x: int(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r-2ePKbnx62"
      },
      "source": [
        "fields = [('Id',None),('Abstract',None),('Title',TITLE),('sum1',SUM),('sum2',SUM),('sum3',SUM),('sum4',SUM),('sum5',SUM),('sum6',SUM),('sum7',SUM)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J3EKi0ooi6f"
      },
      "source": [
        "## Read data into tabular dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgf0hafhomaE"
      },
      "source": [
        "dataset = data.TabularDataset(path='./drive/MyDrive/data_summaries.csv',format='csv', fields=fields,skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tleM8xWxpMmf",
        "outputId": "8973c317-87ed-4e09-cdb5-56b99732c486"
      },
      "source": [
        "print(vars(dataset[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Title': ['dual', 'recurrent', 'attention', 'units', 'for', 'visual', 'question', 'answering'], 'sum1': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question '], 'sum2': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum3': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model '], 'sum4': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model '], 'sum5': ['the', 'memory', 'characteristic', 'of', 'the', 'proposed', 'recurrent', 'attention', 'units', 'offers', 'a', 'rich', 'joint', 'embedding', 'of', 'visual', 'and', 'textual', 'features', 'and', 'enables', 'the', 'model', 'to', 'reason', 'relations', 'between', 'several', 'parts', 'of', 'the', 'image', 'and', 'question in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum6': ['our', 'single', 'model', 'outperforms', 'the', 'first', 'place', 'winner', 'on', 'the', 'vqa', '# #', 'dataset ', 'performs', 'within', 'margin', 'to', 'the', 'current', 'state of the art', 'ensemble', 'model in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset '], 'sum7': ['we', 'propose', 'an', 'architecture', 'for', 'vqa', 'which', 'utilizes', 'recurrent', 'layers', 'to', 'generate', 'visual', 'and', 'textual', 'attention in', 'both', 'cases ', 'our', 'recurrent', 'attention', 'mechanism', 'improves', 'performance', 'in', 'tasks', 'requiring', 'sequential', 'or', 'relational', 'reasoning', 'on', 'the', 'vqa', 'dataset ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKlMN3jMqmJm"
      },
      "source": [
        "## Create training data and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vlRSnYiqjIk"
      },
      "source": [
        "import random\n",
        "train_data, valid_data = dataset.split(split_ratio=0.9, random_state=random.seed(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwPMSsKN6r05",
        "outputId": "f3573126-c721-410b-90e1-2c6b629f2987"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36900\n",
            "4100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhhG460cyQVW",
        "outputId": "7e297ecf-6e51-4500-a39d-01583a2e3f9a"
      },
      "source": [
        "print(vars(train_data[5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Title': ['adaptively', 'learning', 'the', 'crowd', 'kernel'], 'sum1': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone the', 'algorithm', 'samples', 'responses', 'to', 'adaptively', 'chosen', 'triplet based', 'relative similarity', 'queries '], 'sum2': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum3': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum4': ['the', 'output', 'is', 'an', 'embedding', 'of', 'the', 'objects', 'into', 'euclidean', 'space', ' like', 'mds ', 'we', 'refer', 'to', 'this', 'as', 'the', ' crowd', 'kernel svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters '], 'sum5': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone and', 'is', 'chosen', 'to', 'be', 'maximally', 'informative', 'given', 'the', 'preceding', 'responses '], 'sum6': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone the', 'algorithm', 'samples', 'responses', 'to', 'adaptively', 'chosen', 'triplet based', 'relative similarity', 'queries '], 'sum7': ['we', 'introduce', 'an', 'algorithm', 'that ', 'given', 'n', 'objects ', 'learns', 'a', 'similarity', 'matrix', 'over', 'all', 'n #', 'pairs ', 'from', 'crowdsourced', 'data', 'alone svms', 'reveal', 'that', 'the', 'crowd', 'kernel', 'captures', 'prominent', 'and', 'subtle', 'features', 'across', 'a', 'number', 'of', 'domains ', 'such', 'as', ' is', 'striped ', 'among', 'neckties', 'and', ' vowel', 'vs ', 'consonant ', 'among', 'letters ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzsrWel-rwik"
      },
      "source": [
        "SUM.build_vocab(train_data.sum1,train_data.sum2,train_data.sum3,train_data.sum4,train_data.sum5,\\\n",
        "                train_data.sum6,train_data.sum7,train_data.Title,max_size=40000,vectors='glove.6B.100d')\n",
        "TITLE.vocab= SUM.vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMTZoMzTwj9-",
        "outputId": "53b58ce7-4599-44b6-c262-e8dfa38e3c1d"
      },
      "source": [
        "print(len(SUM.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJVr2ehqinaq"
      },
      "source": [
        "### Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKMevUd74r4"
      },
      "source": [
        "from torchtext import data, datasets, vocab\n",
        "glove = vocab.GloVe(name=\"6B\", dim=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuYlbCkT7-vi",
        "outputId": "30e51a7a-eada-420e-83ad-0def248ad4df"
      },
      "source": [
        "glove.vectors.size() # => torch.Size([400000, 100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqsSPdIk8IA1",
        "outputId": "7f299990-a72f-412c-a092-367be5834d52"
      },
      "source": [
        "SUM.vocab.vectors.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40004, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXV96BXC8as5",
        "outputId": "c84e277c-c4e9-4664-bed8-ee677d183ceb"
      },
      "source": [
        "SUM.vocab.stoi['<unk>'] #<unk> is not present in glove vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfNaYADP8Ke0",
        "outputId": "9e832b73-7bfe-4f81-c5ad-004f072cfa62"
      },
      "source": [
        "SUM.vocab.vectors[0]#check the initialisation of oov words for glove. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r4e40BW-57F"
      },
      "source": [
        "assert(TITLE.vocab.stoi ==  SUM.vocab.stoi) #check if both share the same vocab or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_vnztTkRmcV",
        "outputId": "1582e8e3-fec8-4430-f43d-bd594de49bad"
      },
      "source": [
        "type(SUM.vocab.vectors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzSRh6biSLra",
        "outputId": "ae270bcc-f6b0-4851-c641-d473b8a60d18"
      },
      "source": [
        "type(SUM.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.defaultdict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6nlVqB_Rw79"
      },
      "source": [
        "torch.save(SUM.vocab.vectors, './drive/MyDrive/vocab_embeddings.pt')\n",
        "torch.save(SUM.vocab.stoi,'./drive/MyDrive/vocab_stoi.pt')\n",
        "torch.save(SUM.vocab.itos,'./drive/MyDrive/vocab_itos.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeyegTA6p-gB"
      },
      "source": [
        "torch.save(train_data.examples,'train_data.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEWb9cbXtq06",
        "outputId": "e4507ae5-cb3f-45b1-fbe7-6958b58b046c"
      },
      "source": [
        "train_data.examples[0].Title"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsupervised', 'semantic', 'parsing', 'of', 'video', 'collections']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dodGaMxD-zFL"
      },
      "source": [
        "## Create Bucket iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5V0C7iZ_E5N"
      },
      "source": [
        "def cal_length(x):\n",
        "  return len(x.sum1)+len(x.sum2)+len(x.sum3)+len(x.sum4)+len(x.sum5)+len(x.sum6)+len(x.sum7)+len(x.Title)\n",
        "from torchtext.legacy import data\n",
        "BATCH_SIZE =64\n",
        "train_iterator, valid_iterator =data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE, sort_key = lambda x: cal_length(x), sort_within_batch = True,shuffle=True,sort=False,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfycZDI6cche"
      },
      "source": [
        "###Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDAjb0gwuu4u",
        "outputId": "05dec04a-c62b-4184-e607-b91386e8ccfa"
      },
      "source": [
        "bt = next(iter(train_iterator))\n",
        "bt.sum2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        [    1,     1,     1,  ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [  160,    67,     0,  ...,     7,   303,     0],\n",
              "        [10665,   881,  2246,  ..., 20638,  3045,   261],\n",
              "        [    3,     3,     3,  ...,     3,     3,     3]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "x6NXHVuSkwKi",
        "outputId": "fc3e6144-2d26-492d-ab77-abb89610af9d"
      },
      "source": [
        "bt.name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-7123f9a12b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMUTzw0tiJQ-"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU4Ix8W6iNpn"
      },
      "source": [
        "## Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qOs589nrh8p"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, num_layers, dropout): \n",
        "        super().__init__()   \n",
        "        self.hid_dim = hid_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)  \n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers, dropout = dropout)    \n",
        "        self.dropout = nn.Dropout(dropout)       \n",
        "    def forward(self, input_idx):\n",
        "        #print(input_idx)\n",
        "        input_idx=input_idx.to(device)\n",
        "        embedded = self.dropout(self.embedding(input_idx))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = seq_len,batch_size,embed_dim\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        #outputs are always from the top hidden layer\n",
        "        return outputs,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyQTGPUVYD-K"
      },
      "source": [
        "## Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN82JkyFYGKl",
        "outputId": "42a61432-9caf-4444-89c6-c4f34583752b"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0 \n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "enc.apply(init_weights)\n",
        "enc.embedding.weight.data.copy_(pretrained_embeddings)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight\n",
            "weight_ih_l0\n",
            "weight_hh_l0\n",
            "bias_ih_l0\n",
            "bias_hh_l0\n",
            "weight_ih_l1\n",
            "weight_hh_l1\n",
            "bias_ih_l1\n",
            "bias_hh_l1\n",
            "weight_ih_l2\n",
            "weight_hh_l2\n",
            "bias_ih_l2\n",
            "bias_hh_l2\n",
            "embedding.weight\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l2\n",
            "lstm.weight_hh_l2\n",
            "lstm.bias_ih_l2\n",
            "lstm.bias_hh_l2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KdYw-yEZX9I",
        "outputId": "5530fe2a-0501-4c99-a8d9-670410197576"
      },
      "source": [
        "enc.embedding.weight[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1445, -0.0528, -0.0545,  1.1310,  0.4758, -1.0285,  0.2467, -0.0737,\n",
              "        -0.0886,  0.3821,  0.5470, -0.2648,  0.3177, -0.1480, -0.2948, -0.7081,\n",
              "        -0.1925,  0.2585, -0.2926,  0.1868,  0.3139, -0.0207, -0.1016, -0.2646,\n",
              "        -0.0816, -0.1146,  0.0933, -0.5261,  0.3618, -0.8518, -0.3467,  0.4525,\n",
              "        -0.2537,  0.2612,  0.7651, -0.2433, -0.0700,  0.3619, -1.2979, -0.0151,\n",
              "        -0.1497,  0.3810,  0.3105,  0.1845,  0.2202, -0.4393,  1.0478, -0.3870,\n",
              "        -0.1594, -1.2090, -0.2850, -0.4175, -0.1810,  1.0614,  0.3273, -1.8847,\n",
              "         0.0398,  0.1253,  0.4937,  0.1528, -0.1738,  0.1407, -1.0588,  0.1461,\n",
              "         0.3045, -0.0489, -0.2328, -0.3068,  0.6500, -0.1928,  0.4154,  0.3495,\n",
              "         0.1158,  0.2605,  0.5483,  0.0817, -0.4587, -0.7336, -0.5350, -0.3111,\n",
              "         0.1220,  0.4506, -0.0988, -0.0154, -0.7591,  0.2336,  0.5476, -0.8831,\n",
              "        -0.3143,  0.1056, -0.4707,  0.2288, -0.4611,  0.7963, -0.5427, -0.0820,\n",
              "        -0.3374, -0.0419,  0.1561,  0.4494], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koMFwUdMZvxZ",
        "outputId": "2b1ff2b3-4701-4c5e-94df-a06ed7014ccc"
      },
      "source": [
        "SUM.vocab.vectors[456]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1445, -0.0528, -0.0545,  1.1310,  0.4758, -1.0285,  0.2467, -0.0737,\n",
              "        -0.0886,  0.3821,  0.5470, -0.2648,  0.3177, -0.1480, -0.2948, -0.7081,\n",
              "        -0.1925,  0.2585, -0.2926,  0.1868,  0.3139, -0.0207, -0.1016, -0.2646,\n",
              "        -0.0816, -0.1146,  0.0933, -0.5261,  0.3618, -0.8518, -0.3467,  0.4525,\n",
              "        -0.2537,  0.2612,  0.7651, -0.2433, -0.0700,  0.3619, -1.2979, -0.0151,\n",
              "        -0.1497,  0.3810,  0.3105,  0.1845,  0.2202, -0.4393,  1.0478, -0.3870,\n",
              "        -0.1594, -1.2090, -0.2850, -0.4175, -0.1810,  1.0614,  0.3273, -1.8847,\n",
              "         0.0398,  0.1253,  0.4937,  0.1528, -0.1738,  0.1407, -1.0588,  0.1461,\n",
              "         0.3045, -0.0489, -0.2328, -0.3068,  0.6500, -0.1928,  0.4154,  0.3495,\n",
              "         0.1158,  0.2605,  0.5483,  0.0817, -0.4587, -0.7336, -0.5350, -0.3111,\n",
              "         0.1220,  0.4506, -0.0988, -0.0154, -0.7591,  0.2336,  0.5476, -0.8831,\n",
              "        -0.3143,  0.1056, -0.4707,  0.2288, -0.4611,  0.7963, -0.5427, -0.0820,\n",
              "        -0.3374, -0.0419,  0.1561,  0.4494])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMmtgXjlaBEl",
        "outputId": "725f9181-768b-4285-9284-f802c0aca5fb"
      },
      "source": [
        "#To be used to pass inputs to control layer\n",
        "enc.eval()\n",
        "sum = train_data.fields\n",
        "for i,batch in enumerate(train_iterator):\n",
        "  sum1=batch.sum1\n",
        "  sum2=batch.sum2\n",
        "  sum3=batch.sum3\n",
        "  sum4=batch.sum4\n",
        "  sum5=batch.sum5\n",
        "  sum6=batch.sum6\n",
        "  sum7=batch.sum7\n",
        "  sum=[sum1,sum2,sum3,sum4,sum5,sum6,sum7]\n",
        "  control_input=torch.zeros((7,64,512))\n",
        "  for s in range(7):\n",
        "    o,h,c=enc(sum[s])\n",
        "    print(h[-1].size())\n",
        "    control_input[s]=h[-1]\n",
        "  break;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n",
            "torch.Size([64, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfUoW0YOmGI9",
        "outputId": "98807675-2327-4754-f3ad-1b568db54330"
      },
      "source": [
        "print(control_input[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0834,  0.0189,  0.0765,  ..., -0.0174,  0.0009, -0.0084],\n",
            "        [-0.0895,  0.0514,  0.0244,  ..., -0.0415,  0.0057,  0.0272],\n",
            "        [-0.0050,  0.1141,  0.0455,  ..., -0.0509,  0.0232, -0.0133],\n",
            "        ...,\n",
            "        [-0.0277,  0.0447,  0.0456,  ..., -0.0098,  0.0120, -0.0170],\n",
            "        [-0.1194,  0.0710,  0.0903,  ..., -0.0478,  0.0130, -0.0159],\n",
            "        [-0.0394,  0.0713,  0.0786,  ..., -0.0637,  0.0046,  0.0357]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEOlyNZxiQEF"
      },
      "source": [
        "## Control layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjdf2BQ6rjSM"
      },
      "source": [
        "class ControlLayer(nn.Module):\n",
        "    def __init__(self, input_dim,hid_dim): \n",
        "        super().__init__()   \n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        #self.embedding = nn.Embedding(input_dim, emb_dim)  \n",
        "        self.lstm = nn.LSTM(input_dim, hid_dim)    \n",
        "             \n",
        "    def forward(self, sum_hidden):\n",
        "        #print(input_idx)\n",
        "        #sum_hidden = seq_len(=7),batch_size,embed_dim(=encoder_hidden_dimension)\n",
        "        outputs, (hidden, cell) = self.lstm(sum_hidden)\n",
        "        #embedded = seq_len,batch_size,embed_dim\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        #outputs are always from the top hidden layer\n",
        "        return outputs,hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYiU10INtO1g"
      },
      "source": [
        "##checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbotSIuQZ5tW"
      },
      "source": [
        "cl = ControlLayer(512,512)\n",
        "i=torch.randn(7,64,512)\n",
        "o,h,c = cl(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvxUPqUfabPw",
        "outputId": "1a2675f6-4c05-4261-cead-f0689643d64d"
      },
      "source": [
        "h.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4b7-0diabA"
      },
      "source": [
        "##Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfPmC8aGtaOu"
      },
      "source": [
        "class ComplexAttention(nn.Module):\n",
        "   def __init__(self,dec_hid_dim,cnt_hid_dim,enc_hid_dim):\n",
        "    super().__init__() \n",
        "    self.cnt_hid_dim=cnt_hid_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "   def forward(self,cnt_hid_states,enc_hid_states,dec_hid_states):\n",
        "     #cnt_hid_states = [7,batch_size,cnt_hid_dim]\n",
        "     #enc_hid_states = [7,seq_len*,batch_size,enc_hid_dim], list of hidden states for every summary\n",
        "     #dec_hid_states = [1,batch_size,dec_hid_dim]\n",
        "     '''Calculate summary level attention'''\n",
        "     cnt_hid_states=cnt_hid_states.permute(1,0,2)\n",
        "     dec_hid_states=dec_hid_states.permute(1,2,0)\n",
        "     #dec_hid_states=[batch_size,dec_hid_dim,1]\n",
        "     alpha = torch.bmm(cnt_hid_states,dec_hid_states)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     #alpha=alpha.squeeze(2)\n",
        "     alpha=F.softmax(alpha,dim=1)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     '''Calculate word level attention'''\n",
        "     batch_size = alpha.size()[0]\n",
        "     context_vec=torch.zeros(batch_size,1,self.enc_hid_dim).to(device)\n",
        "     context_vec_k=torch.zeros(7,batch_size,self.enc_hid_dim).to(device)\n",
        "     for k,sum_hid_states in enumerate(enc_hid_states):\n",
        "       #sum_hid_states = [seq_len_k,batch_size,enc_hid_dim]\n",
        "       sum_hid_states=sum_hid_states.permute(1,0,2)\n",
        "       beta = torch.bmm(sum_hid_states,dec_hid_states)\n",
        "       #beta = [batch_size,seq_len_1,1]\n",
        "       #beta=beta.squeeze(2)\n",
        "       beta=F.softmax(beta,dim=1)\n",
        "       beta=beta.permute(0,2,1)\n",
        "       #beta = [batch_size,1,seq_len]\n",
        "       #sum_hid_states = [batch_size,seq_len_size,enc_hid_dim]\n",
        "       context_vec_k[k] = torch.bmm(beta,sum_hid_states).squeeze(1)\n",
        "       #context_vec_k = [batch_size,1,enc_hid_dim].squeeze(1)\n",
        "     '''Combining both and returning context_vector'''\n",
        "     context_vec_k=context_vec_k.permute(1,0,2)\n",
        "     alpha=alpha.permute(0,2,1)\n",
        "     context_vec = torch.bmm(alpha,context_vec_k)\n",
        "     del context_vec_k\n",
        "     torch.cuda.empty_cache()\n",
        "     return alpha,beta,context_vec\n",
        "\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0JC9VKMQ79t"
      },
      "source": [
        "class SimpleAttention(nn.Module):\n",
        "   def __init__(self,dec_hid_dim,cnt_hid_dim,enc_hid_dim,split):\n",
        "    super().__init__() \n",
        "    self.cnt_hid_dim=cnt_hid_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.split = split\n",
        "   def forward(self,cnt_hid_states,enc_hid_states,dec_hid_states):\n",
        "     #cnt_hid_states = [7,batch_size,cnt_hid_dim]\n",
        "     #enc_hid_states = [7,seq_len*,batch_size,enc_hid_dim], list of hidden states for every summary\n",
        "     #dec_hid_states = [num_layers(=1),batch_size,dec_hid_dim]\n",
        "     '''Calculate summary level attention'''\n",
        "     cnt_hid_states_context=cnt_hid_states.permute(1,0,2)[:,:,:self.split]\n",
        "     dec_hid_states_context=dec_hid_states.permute(1,2,0)[:,:self.split,:]\n",
        "     cnt_hid_states_wgt=cnt_hid_states.permute(1,0,2)[:,:,self.split:]\n",
        "     dec_hid_states_wgt=dec_hid_states.permute(1,2,0)[:,self.split:,:]\n",
        "     #dec_hid_states_wgt=[batch_size,dec_hid_dim,1]\n",
        "     alpha = torch.bmm(cnt_hid_states_wgt,dec_hid_states_wgt)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     #alpha=alpha.squeeze(2)\n",
        "     alpha=F.softmax(alpha,dim=1)\n",
        "     #alpha=[batch_size,7,1]\n",
        "     '''Calculate word level attention'''\n",
        "     batch_size = alpha.size()[0]\n",
        "     context_vec=torch.zeros(batch_size,1,self.split).to(device)\n",
        "     context_vec_k=torch.zeros(7,batch_size,self.split).to(device)\n",
        "     for k,sum_hid_states in enumerate(enc_hid_states):\n",
        "       #sum_hid_states = [seq_len_k,batch_size,enc_hid_dim]\n",
        "       sum_hid_states_wgt=sum_hid_states.permute(1,0,2)[:,:,self.split:]\n",
        "       sum_hid_states_context=sum_hid_states.permute(1,0,2)[:,:,:self.split]\n",
        "       beta = torch.bmm(sum_hid_states_wgt,dec_hid_states_wgt)\n",
        "       #beta = [batch_size,seq_len_1,1]\n",
        "       #beta=beta.squeeze(2)\n",
        "       beta=F.softmax(beta,dim=1)\n",
        "       beta=beta.permute(0,2,1)\n",
        "       #beta = [batch_size,1,seq_len]\n",
        "       #sum_hid_states = [batch_size,seq_len_size,enc_hid_dim]\n",
        "       context_vec_k[k] = torch.bmm(beta,sum_hid_states_context).squeeze(1)\n",
        "       #context_vec_k = [batch_size,1,enc_hid_dim].squeeze(1)\n",
        "     '''Combining both and returning context_vector'''\n",
        "     context_vec_k=context_vec_k.permute(1,0,2)\n",
        "     alpha=alpha.permute(0,2,1)\n",
        "     context_vec = torch.bmm(alpha,context_vec_k)\n",
        "     del context_vec_k\n",
        "     torch.cuda.empty_cache()\n",
        "     return alpha,beta,context_vec\n",
        "\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGicM78iI2Yc"
      },
      "source": [
        "#### Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hOm805PI4Bm"
      },
      "source": [
        "at = ComplexAttention(512,512,512)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512) \n",
        "alpha,beta,con=at(cnt_hid_states,enc_hid_states,dec_hid_states)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELoNPTC8Kqmz"
      },
      "source": [
        "assert(con.size()==torch.Size([64, 1, 512])) #checking if correct size is returned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNAZHtTMK9OO"
      },
      "source": [
        "assert(beta[45][0].sum().item()==1) ##Checking if attention wgts have calculated succesfully"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS_ElS94UHCL"
      },
      "source": [
        "at = SimpleAttention(512,512,512,472)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512) \n",
        "alpha,beta,con=at(cnt_hid_states,enc_hid_states,dec_hid_states)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_n5d_fDUMav"
      },
      "source": [
        "assert(con.size()==torch.Size([64, 1,472])) #checking if correct size is returned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_cQkhzksUPX"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F             # importing functions -Functional interface\n",
        "a = torch.randn(5,2,3)\n",
        "b=torch.randn(5,2,3)\n",
        "c= a+b\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxI-sfXuV2Nf",
        "outputId": "427ea76a-8144-4093-f302-59a3ff3fe980"
      },
      "source": [
        "con.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 472])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unRcNmAoV4eX",
        "outputId": "b90fc5e0-4b79-446d-99f7-4597204a7024"
      },
      "source": [
        "con=con.permute(1,0,2)\n",
        "print(con.size())\n",
        "input = torch.randn(1,64,100)\n",
        "c = torch.cat((input, con), dim = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 472])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju9hl7nDWykk",
        "outputId": "9ae74a03-31c3-443c-8056-5561224ae7ba"
      },
      "source": [
        "c.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 572])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3fLV-xHVtKr"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbbagtapVxkt"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim,con_hid_dim,attention,attention_type):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.con_hid_dim = con_hid_dim\n",
        "        self.attention = attention      \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        if attention_type=='complex':      \n",
        "          self.lstm = nn.LSTM(input_size=(enc_hid_dim + emb_dim),hidden_size= dec_hid_dim)\n",
        "          self.fc_out = nn.Linear( enc_hid_dim + dec_hid_dim + emb_dim, output_dim)\n",
        "        else:\n",
        "          self.lstm = nn.LSTM((attention.split+emb_dim), dec_hid_dim)\n",
        "          self.fc_out = nn.Linear( (2*attention.split)  + emb_dim, output_dim)    \n",
        "        #self.dropout = nn.Dropout(dropout)\n",
        "        self.attention_type=attention_type\n",
        "    def forward(self, input_idx,cnt_hid_states,enc_hid_states,dec_hid_states,cell_state):\n",
        "      #input = [batch_size]\n",
        "      input_idx = input_idx.unsqueeze(0)#Adding a dimenstion at the the first = 1 = seq_len as we are sending word by word\n",
        "      #input = [1,batch_size] \n",
        "      embedded = self.embedding(input_idx)\n",
        "      #embedded = [1,batch_size,embed_size]\n",
        "      '''Getting the context vector'''\n",
        "      _,_,context_vector=self.attention(cnt_hid_states,enc_hid_states,dec_hid_states)\n",
        "      #context_vector=[batch_size,1,hid_state]\n",
        "      context_vector=context_vector.permute(1,0,2)\n",
        "      #context_vector=[1,batch_size,hid_state]\n",
        "      lstm_in = torch.cat((embedded,context_vector),dim=2)\n",
        "      #lstm_in = [1,batch_size,context_vector_size+embed_size]\n",
        "      #print(lstm_in.size())\n",
        "      outputs, (hidden, cell) = self.lstm(lstm_in,(dec_hid_states,cell_state))\n",
        "      #output=[seq_len(=1),batch_size,hid_dim]\n",
        "      #hidden=[num_layers(=1),batch_size,hid_dim]\n",
        "      assert(outputs==hidden).all()\n",
        "\n",
        "      embedded=embedded.squeeze(0)\n",
        "      context_vector=context_vector.squeeze(0)\n",
        "      outputs = outputs.squeeze(0)\n",
        "      if self.attention_type=='complex':\n",
        "        prediction = self.fc_out(torch.cat((outputs,context_vector,embedded),dim=1))\n",
        "      else:\n",
        "        prediction = self.fc_out(torch.cat((outputs[:,:self.attention.split],context_vector,embedded),dim=1))\n",
        "      #prediction_size = (batch_size,out_dim)\n",
        "      return prediction,hidden,cell\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8HFRmdgv2r"
      },
      "source": [
        "### checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtvNlSJ2jpCF",
        "outputId": "20c24fe5-ef8c-4e8a-b0ce-d0edc4374b11"
      },
      "source": [
        "at = SimpleAttention(512,512,512,472)\n",
        "\n",
        "dec =  Decoder(40000,100,512,512,512,at,'simple')\n",
        "input = random.sample(range(10, 1000), 64)\n",
        "enc_hid_states = []\n",
        "for i in range(7):\n",
        "  enc_hid_states.append(torch.randn(33,64,512))\n",
        "cnt_hid_states=torch.randn(7,64,512)      \n",
        "dec_hid_states=torch.randn(1,64,512)\n",
        "cell_state=torch.randn(1,64,512)\n",
        "pred,hid,cell = dec(torch.LongTensor(input),cnt_hid_states,enc_hid_states,dec_hid_states,cell_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 64, 572])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXZecrcEMa6z",
        "outputId": "0c060b44-522e-4342-c073-c1edb56daa48"
      },
      "source": [
        "pred.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 40000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7w-CoTWgqMo"
      },
      "source": [
        "##Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OidIY-BVW4OB"
      },
      "source": [
        "class Seq2Seq(nn.Module): #Combining the encoder,control_layer & decoder\n",
        "  def __init__(self,encoder,control_layer,decoder,device):\n",
        "    super().__init__()\n",
        "    self.encoder=encoder\n",
        "    self.control_layer = control_layer\n",
        "    self.decoder=decoder\n",
        "    self.device =  device\n",
        "  def forward(self,input_batches,output_batches,tfr=0.5):\n",
        "    #input_batches dimension - NOT A TENSOR. ENTIRE BATCH OBJECT IS SENT. \n",
        "    #output_batches_dimension - (seq_len,batch_size)\n",
        "    \n",
        "    batch_size = output_batches.shape[1]\n",
        "    title_len = output_batches.shape[0]\n",
        "    title_vocab_size = self.decoder.output_dim\n",
        "    predictions = torch.zeros(title_len, batch_size, title_vocab_size).to(device)\n",
        "    #print(input_batches.size())\n",
        "    '''Pass each summary through the encoder'''\n",
        "    sum1=input_batches.sum1\n",
        "    sum2=input_batches.sum2\n",
        "    sum3=input_batches.sum3\n",
        "    sum4=input_batches.sum4\n",
        "    sum5=input_batches.sum5\n",
        "    sum6=input_batches.sum6\n",
        "    sum7=input_batches.sum7\n",
        "    sum=[sum1,sum2,sum3,sum4,sum5,sum6,sum7]\n",
        "    control_input=torch.zeros((7,batch_size,self.control_layer.hid_dim)).to(device)\n",
        "    encoder_hidden_states = []\n",
        "    for s in range(7):\n",
        "      output,hidden=self.encoder(sum[s])\n",
        "      #output = [s.length,batch_size,hid_dim]\n",
        "      #hidden=[num_layers,batch_size,hid_dim]\n",
        "      #print(\"enc_output device\",output.device)\n",
        "      encoder_hidden_states.append(output)\n",
        "      control_input[s]=hidden[-1]\n",
        "    \n",
        "    '''Pass the last hidden state to control layer for each summary'''\n",
        "    output,hidden_state,cell_state = self.control_layer(control_input)\n",
        "    control_hidden_states = output\n",
        "    #prprint(\"S_c\")\n",
        "    '''Pass the merged representation to decoder along with encoder and control layer hidden states for implementing attention'''\n",
        "    \n",
        "    \n",
        "    x = output_batches[0,:] # Trigger token <SOS>\n",
        "\n",
        "    for i in range(1, title_len):\n",
        "      pred, hidden_state, cell_state = self.decoder(x,control_hidden_states,encoder_hidden_states,hidden_state, cell_state)\n",
        "      #pred = [batch_size,output_dim(vocab_size)]\n",
        "      predictions[i] = pred\n",
        "      best_guess = pred.argmax(1) \n",
        "      x = output_batches[i,:] if random.random() < tfr else best_guess\n",
        "    return predictions  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io0fzS1YNo_-"
      },
      "source": [
        "## Set Model hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O0ftuZEN5PK"
      },
      "source": [
        "## Initialise weights (Embeddings are initialised with glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3vYL04BOAgk"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrgYtkNKOdUR"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i,batch in enumerate(iterator):\n",
        "        \n",
        "        #abstract = batch.Abstract\n",
        "        title = batch.Title\n",
        "        #abstract,title = [seq_len,batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        #print(\"batch device \",batch.device)\n",
        "        predictions = model(batch, title,0.5)\n",
        "        \n",
        "        #predictions = [seq_len_title,batch_size,title_vocab]\n",
        "        output_dim = predictions.shape[-1]\n",
        "        \n",
        "        predictions = predictions[1:].view(-1, output_dim)#ignoring the first value is the <sos> token\n",
        "        title = title[1:].view(-1)\n",
        "        \n",
        "        loss = criterion(predictions, title)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W52SADa2OQij"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUeVTA61Odl5"
      },
      "source": [
        "def test(model, iterator, criterion):    \n",
        "    model.eval() \n",
        "    epoch_loss = 0 \n",
        "    with torch.no_grad():   \n",
        "        for i, batch in enumerate(iterator):\n",
        "          #abstract = batch.Abstract\n",
        "          title = batch.Title\n",
        "          #abstract,title = [seq_len,batch_size]\n",
        "          predictions = model(batch, title,0)\n",
        "          #predictions = [seq_len_title,batch_size,title_vocab]\n",
        "          output_dim = predictions.shape[-1]\n",
        "          predictions = predictions[1:].view(-1, output_dim)#ignoring the first value is the <sos> token\n",
        "          title = title[1:].view(-1)\n",
        "          loss = criterion(predictions, title)  \n",
        "          epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPORcxCzOZEi"
      },
      "source": [
        "##Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaIcc_hIOe_i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boOqkDtIOhPS"
      },
      "source": [
        "##Start training and testing!\n",
        "### Experiement 0 - Complex Attention, ADAM optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1U8noU9OcZ4"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = ComplexAttention(HID_DIM,HID_DIM,HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'complex')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpq0dBD1Ocrh",
        "outputId": "e9d487fc-7bbf-40d3-e378-2bce628baa75"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-fJZPAwfNVF"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1vltVXHj2Oz"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiO38agbOn-k",
        "outputId": "bfe836e0-0bd3-4cf1-e7cc-260158f395ca"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 6.402\n",
            "\tTest Loss: 6.523\n",
            "Time taken : 7.524mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.931\n",
            "\tTest Loss: 6.506\n",
            "Time taken : 7.692mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.748\n",
            "\tTest Loss: 6.520\n",
            "Time taken : 7.695mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.573\n",
            "\tTest Loss: 6.534\n",
            "Time taken : 7.702mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.455\n",
            "\tTest Loss: 6.547\n",
            "Time taken : 7.697mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.370\n",
            "\tTest Loss: 6.550\n",
            "Time taken : 7.683mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.274\n",
            "\tTest Loss: 6.594\n",
            "Time taken : 7.713mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.164\n",
            "\tTest Loss: 6.586\n",
            "Time taken : 7.722mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.100\n",
            "\tTest Loss: 6.594\n",
            "Time taken : 7.707mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.023\n",
            "\tTest Loss: 6.603\n",
            "Time taken : 7.705mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.964\n",
            "\tTest Loss: 6.613\n",
            "Time taken : 7.759mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.868\n",
            "\tTest Loss: 6.607\n",
            "Time taken : 7.721mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.807\n",
            "\tTest Loss: 6.611\n",
            "Time taken : 7.710mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.700\n",
            "\tTest Loss: 6.680\n",
            "Time taken : 7.735mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.602\n",
            "\tTest Loss: 6.513\n",
            "Time taken : 7.749mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.509\n",
            "\tTest Loss: 6.483\n",
            "Time taken : 7.751mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.356\n",
            "\tTest Loss: 6.472\n",
            "Time taken : 7.750mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.189\n",
            "\tTest Loss: 6.462\n",
            "Time taken : 7.759mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.059\n",
            "\tTest Loss: 6.404\n",
            "Time taken : 7.760mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 3.915\n",
            "\tTest Loss: 6.480\n",
            "Time taken : 7.769mins\n",
            "Saving the new checkpoint....\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Dbh7P-OyMN"
      },
      "source": [
        "## Train & test loss graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YTimOXk_iYV"
      },
      "source": [
        "##Start training and testing!\n",
        "### Experiement 1 - Complex Attention, RMSprop optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSl4tWb_wFc"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = ComplexAttention(HID_DIM,HID_DIM,HID_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'complex')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJUEKhOW_wFh",
        "outputId": "2df4cf03-41e0-4284-af3b-5a6fb0209581"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Yy1Hmx_wFv"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net_1.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKC_9iAJ_wFx"
      },
      "source": [
        "optimizer = optim.RMSprop(model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.9)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "q3dAlHWWAhCQ",
        "outputId": "224c8cac-6345-4314-9fa1-188d07367daf"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.581\n",
            "Time taken : 7.652mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.579\n",
            "Time taken : 7.694mins\n",
            "\tTrain Loss: 10.580\n",
            "\tTest Loss: 10.579\n",
            "Time taken : 7.691mins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3e9da7c55bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tTrain Loss: {train_loss:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-534606c595b7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(\"batch device \",batch.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#predictions = [seq_len_title,batch_size,title_vocab]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5efeac973e11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batches, output_batches, tfr)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontrol_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0;31m#pred = [batch_size,output_dim(vocab_size)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-abe71fbcb43c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_idx, cnt_hid_states, enc_hid_states, dec_hid_states, cell_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#embedded = [1,batch_size,embed_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;34m'''Getting the context vector'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_hid_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menc_hid_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdec_hid_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m#context_vector=[batch_size,1,hid_state]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mcontext_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-6cc33b888c50>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cnt_hid_states, enc_hid_states, dec_hid_states)\u001b[0m\n\u001b[1;32m     20\u001b[0m      \u001b[0;34m'''Calculate word level attention'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m      \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m      \u001b[0mcontext_vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m      \u001b[0mcontext_vec_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_hid_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m      \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum_hid_states\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_hid_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFEtwItAmcH"
      },
      "source": [
        "### Start training and testing!\n",
        "### Experiement 2 - Simple Attention,Adam optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBs4tvMcA53a"
      },
      "source": [
        "INPUT_DIM = len(SUM.vocab)\n",
        "OUTPUT_DIM = len(TITLE.vocab)\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 100\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 3\n",
        "ENC_DROPOUT = 0\n",
        "DEC_DROPOUT = 0\n",
        "SPLIT = 472\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "con = ControlLayer(HID_DIM,HID_DIM)\n",
        "'''trying with complex attention first'''\n",
        "attention = SimpleAttention(HID_DIM,HID_DIM,HID_DIM,SPLIT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM,HID_DIM,HID_DIM,attention,'simple')\n",
        "\n",
        "model = Seq2Seq(enc,con, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0U2HVi5A53c",
        "outputId": "ed4214f6-72ee-4276-a3d2-7155afa96bdf"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "      #print(name)\n",
        "      nn.init.uniform_(param.data, -0.1, 0.1)  \n",
        "model.apply(init_weights)\n",
        "pretrained_embeddings = SUM.vocab.vectors\n",
        "model.encoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model.decoder.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0eBrsz2A53f"
      },
      "source": [
        "def checkpoint_and_save(model, min_loss, epoch, optimizer):\n",
        "    print()\n",
        "    state = {'model': model,'min_loss': min_loss,'epoch': epoch,'model_state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),}\n",
        "    path =  './drive/MyDrive/Colab Notebooks/final_net_2.pt'\n",
        "    torch.save(state, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kdefe9PA53h"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "PAD_IDX = TITLE.vocab.stoi[TITLE.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkBlstVXA53i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721854c3-9978-485e-a1cf-1ed2e834ef5d"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "min_loss = 1000000\n",
        "min_epoch = -1\n",
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = test(model,valid_iterator,criterion)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
        "    #print(\"After epoch {} , generated title is {}\".format(epoch,translate(model,demo_sentence,10)))\n",
        "    end_time = time.time()\n",
        "    print(f'Time taken : {(end_time-start_time)/60:.3f}mins')\n",
        "    if(train_loss < min_loss):\n",
        "      min_loss=train_loss\n",
        "      min_epoch = epoch\n",
        "      print(\"Saving the new checkpoint....\")\n",
        "      checkpoint_and_save(model,min_loss,epoch,optimizer)\n",
        "    if(epoch-min_epoch >= 10):\n",
        "      print(\"NO further improvement over 10 epochs. Terminating...\")\n",
        "      break\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 6.407\n",
            "\tTest Loss: 6.517\n",
            "Time taken : 16.629mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.938\n",
            "\tTest Loss: 6.500\n",
            "Time taken : 16.604mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.753\n",
            "\tTest Loss: 6.520\n",
            "Time taken : 16.590mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.578\n",
            "\tTest Loss: 6.545\n",
            "Time taken : 16.602mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.470\n",
            "\tTest Loss: 6.540\n",
            "Time taken : 16.604mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.382\n",
            "\tTest Loss: 6.551\n",
            "Time taken : 16.561mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.284\n",
            "\tTest Loss: 6.566\n",
            "Time taken : 16.559mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 5.102\n",
            "\tTest Loss: 6.394\n",
            "Time taken : 16.630mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.877\n",
            "\tTest Loss: 6.251\n",
            "Time taken : 16.620mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.641\n",
            "\tTest Loss: 6.172\n",
            "Time taken : 16.610mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.395\n",
            "\tTest Loss: 6.190\n",
            "Time taken : 16.839mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 4.131\n",
            "\tTest Loss: 6.212\n",
            "Time taken : 16.855mins\n",
            "Saving the new checkpoint....\n",
            "\n",
            "\tTrain Loss: 3.860\n",
            "\tTest Loss: 6.249\n",
            "Time taken : 16.868mins\n",
            "Saving the new checkpoint....\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF03zOQmdanb"
      },
      "source": [
        "## Translate\n",
        "<Br> Randomly select some abstracts from the dataset and generate the title using the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myOBwWBpd8Fm"
      },
      "source": [
        "df = pd.read_csv('./drive/MyDrive/data_summaries.csv')\n",
        "idx = np.random.randint(0,df.shape[0],100)\n",
        "df1 = df.loc[idx]\n",
        "df1.to_csv('./drive/MyDrive/test_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D66kuesVeZnv"
      },
      "source": [
        "ran_dataset = data.TabularDataset(path='./drive/MyDrive/test_data.csv',format='csv', fields=fields,skip_header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI6rLEhhefgR"
      },
      "source": [
        "def cal_length(x):\n",
        "  return len(x.sum1)+len(x.sum2)+len(x.sum3)+len(x.sum4)+len(x.sum5)+len(x.sum6)+len(x.sum7)+len(x.Title)\n",
        "from torchtext.legacy import data\n",
        "BATCH_SIZE =1\n",
        "iterator=data.BucketIterator.splits(\n",
        "    ran_dataset,\n",
        "    batch_size = BATCH_SIZE, sort_key = lambda x: cal_length(x), sort_within_batch = True,shuffle=True,sort=False,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVgbpP61eNVR"
      },
      "source": [
        "path =  './drive/MyDrive/Colab Notebooks/net.pt'\n",
        "checkpoint = torch.load(path)\n",
        "#print(checkpoint)\n",
        "model1 = checkpoint['model']\n",
        "model1.load_state_dict( checkpoint['model_state_dict'])\n",
        "min_loss = checkpoint['min_loss']\n",
        "epoch = checkpoint['epoch']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB_sluDWeSGh"
      },
      "source": [
        "#to generate title for one abstract\n",
        "def translate(model,iterator,max_length):\n",
        "  pred=[]\n",
        "  with torch.no_grad():\n",
        "    for i,batch in enumerate(iterator):\n",
        "      \n",
        "        predictions = model(batch,batch.Title,0)\n",
        "        predictions = predictions.squeeze(0)\n",
        "        best_guess = predictions.argmax(0).item()\n",
        "\n",
        "        pred.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if best_guess == SUM.vocab.stoi[\"<eos>\"]:\n",
        "          break\n",
        "\n",
        "        translated_sentence = [SUM.vocab.itos[idx] for idx in pred]\n",
        "  return translated_sentence[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b5dMFSefD6K"
      },
      "source": [
        "print(translate(model,iterator,10))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}